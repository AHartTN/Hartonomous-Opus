=== Universal Safetensor Ingester ===
Directory: D:\Models\detection_models\Conditional-DETR-R50
Model: Conditional-DETR-R50
Threshold: 0.5

[3] Parsing 1 safetensor files...
  Parsing: "D:\\Models\\detection_models\\Conditional-DETR-R50\\model.safetensors"
[INFO] Found 592 tensors

[4] Building tensor name hierarchy...
[HIER] Building tensor hierarchy from 592 tensors
[HIER] Found 928 unique hierarchy nodes
[HIER] Built 928 compositions with atom children
[HIER] Built 925 composition->composition edges
[HIER] Inserted/updated 928 hierarchy compositions
[HIER] Inserted 41824 atom children
[HIER] Inserted 925 composition->composition edges

[6] Computing composition centroids hierarchically...
[CENTROID] Updated 928 composition centroids from atoms

[7] Extracting embedding k-NN similarity as relations...
[EMBED] Found 1 embedding tensor(s)
[EMBED] Processing model.query_position_embeddings.weight [position, thresh=0.02]: 300 x 256 dims
[EMBED] Read embeddings in 1ms
[EMBED] Built k-NN graph: 2249 edges in 4ms
[EMBED] Processed all tensors in 26ms, 2249 edges
[EMBED] Bulk inserted 2249 relations in 25ms
[EMBED] Total: 2249 embedding similarity relations

[8] Extracting weight-based relations (router, attention, MLP)...
[ROUTER] No router tensors found (not an MoE model)

[ATTN] Extracting attention projection similarities...
[ATTN] Processing 6 q_proj tensors
  model.encoder.layers.3.self_attn.q_proj.weight [256 x 256] layer=3
    -> 1129 weight similarity edges
  model.encoder.layers.2.self_attn.q_proj.weight [256 x 256] layer=2
    -> 1044 weight similarity edges
  model.encoder.layers.4.self_attn.q_proj.weight [256 x 256] layer=4
    -> 1325 weight similarity edges
  model.encoder.layers.5.self_attn.q_proj.weight [256 x 256] layer=5
    -> 1313 weight similarity edges
  model.encoder.layers.0.self_attn.q_proj.weight [256 x 256] layer=0
    -> 977 weight similarity edges
  model.encoder.layers.1.self_attn.q_proj.weight [256 x 256] layer=1
    -> 1144 weight similarity edges
[ATTN] Processing 6 k_proj tensors
  model.encoder.layers.2.self_attn.k_proj.weight [256 x 256] layer=2
    -> 882 weight similarity edges
  model.encoder.layers.5.self_attn.k_proj.weight [256 x 256] layer=5
    -> 1188 weight similarity edges
  model.encoder.layers.4.self_attn.k_proj.weight [256 x 256] layer=4
    -> 1174 weight similarity edges
  model.encoder.layers.0.self_attn.k_proj.weight [256 x 256] layer=0
    -> 1037 weight similarity edges
  model.encoder.layers.1.self_attn.k_proj.weight [256 x 256] layer=1
    -> 948 weight similarity edges
  model.encoder.layers.3.self_attn.k_proj.weight [256 x 256] layer=3
    -> 921 weight similarity edges
[ATTN] Processing 18 v_proj tensors
  model.decoder.layers.2.ca_v_proj.weight [256 x 256] layer=2
    -> 852 weight similarity edges
  model.decoder.layers.0.ca_v_proj.weight [256 x 256] layer=0
    -> 1113 weight similarity edges
  model.decoder.layers.3.ca_v_proj.weight [256 x 256] layer=3
    -> 546 weight similarity edges
  model.decoder.layers.5.ca_v_proj.weight [256 x 256] layer=5
    -> 405 weight similarity edges
  model.decoder.layers.1.ca_v_proj.weight [256 x 256] layer=1
    -> 1089 weight similarity edges
  model.encoder.layers.4.self_attn.v_proj.weight [256 x 256] layer=4
    -> 825 weight similarity edges
  model.decoder.layers.0.sa_v_proj.weight [256 x 256] layer=0
    -> 238 weight similarity edges
  model.encoder.layers.3.self_attn.v_proj.weight [256 x 256] layer=3
    -> 572 weight similarity edges
  model.encoder.layers.2.self_attn.v_proj.weight [256 x 256] layer=2
    -> 480 weight similarity edges
  model.decoder.layers.1.sa_v_proj.weight [256 x 256] layer=1
    -> 361 weight similarity edges
  model.decoder.layers.2.sa_v_proj.weight [256 x 256] layer=2
    -> 417 weight similarity edges
  model.decoder.layers.4.sa_v_proj.weight [256 x 256] layer=4
    -> 459 weight similarity edges
  model.encoder.layers.0.self_attn.v_proj.weight [256 x 256] layer=0
    -> 700 weight similarity edges
  model.decoder.layers.3.sa_v_proj.weight [256 x 256] layer=3
    -> 451 weight similarity edges
  model.decoder.layers.4.ca_v_proj.weight [256 x 256] layer=4
    -> 438 weight similarity edges
  model.decoder.layers.5.sa_v_proj.weight [256 x 256] layer=5
    -> 546 weight similarity edges
  model.encoder.layers.1.self_attn.v_proj.weight [256 x 256] layer=1
    -> 447 weight similarity edges
  model.encoder.layers.5.self_attn.v_proj.weight [256 x 256] layer=5
    -> 863 weight similarity edges
[ATTN] Processing 12 fc1 tensors
  model.decoder.layers.1.fc1.weight [2048 x 256] layer=1
    -> 10162 weight similarity edges
  model.encoder.layers.0.fc1.weight [2048 x 256] layer=0
    -> 10215 weight similarity edges
  model.decoder.layers.5.fc1.weight [2048 x 256] layer=5
    -> 10204 weight similarity edges
  model.encoder.layers.5.fc1.weight [2048 x 256] layer=5
    -> 10161 weight similarity edges
  model.decoder.layers.0.fc1.weight [2048 x 256] layer=0
    -> 10122 weight similarity edges
  model.encoder.layers.4.fc1.weight [2048 x 256] layer=4
    -> 10309 weight similarity edges
  model.decoder.layers.2.fc1.weight [2048 x 256] layer=2
    -> 10277 weight similarity edges
  model.decoder.layers.3.fc1.weight [2048 x 256] layer=3
    -> 10214 weight similarity edges
  model.decoder.layers.4.fc1.weight [2048 x 256] layer=4
    -> 10403 weight similarity edges
  model.encoder.layers.1.fc1.weight [2048 x 256] layer=1
    -> 10286 weight similarity edges
  model.encoder.layers.2.fc1.weight [2048 x 256] layer=2
    -> 10319 weight similarity edges
  model.encoder.layers.3.fc1.weight [2048 x 256] layer=3
    -> 10291 weight similarity edges
[ATTN] Processing 12 fc2 tensors
  model.encoder.layers.2.fc2.weight [256 x 2048] layer=2
    -> 321 weight similarity edges
  model.decoder.layers.0.fc2.weight [256 x 2048] layer=0
    -> 888 weight similarity edges
  model.decoder.layers.1.fc2.weight [256 x 2048] layer=1
    -> 781 weight similarity edges
  model.decoder.layers.5.fc2.weight [256 x 2048] layer=5
    -> 398 weight similarity edges
  model.encoder.layers.5.fc2.weight [256 x 2048] layer=5
    -> 231 weight similarity edges
  model.decoder.layers.3.fc2.weight [256 x 2048] layer=3
    -> 656 weight similarity edges
  model.decoder.layers.2.fc2.weight [256 x 2048] layer=2
    -> 734 weight similarity edges
  model.decoder.layers.4.fc2.weight [256 x 2048] layer=4
    -> 578 weight similarity edges
  model.encoder.layers.0.fc2.weight [256 x 2048] layer=0
    -> 65 weight similarity edges
  model.encoder.layers.1.fc2.weight [256 x 2048] layer=1
    -> 183 weight similarity edges
  model.encoder.layers.3.fc2.weight [256 x 2048] layer=3
    -> 271 weight similarity edges
  model.encoder.layers.4.fc2.weight [256 x 2048] layer=4
    -> 203 weight similarity edges
[ATTN] Processing 1 classifier tensors
  class_labels_classifier.weight [91 x 256] layer=-1
    -> 460 weight similarity edges

[TOKEN-DIM] Extracting token->dimension activation patterns...

[EXTRACT] Total: 152616 relation edges from model weights

=== Complete ===
Total time: 4 seconds
Tensors: 592
BPE merges: 0
Vocab: 0 tokens
=== Universal Safetensor Ingester ===
Directory: D:\Models\detection_models\DETR-ResNet-101
Model: DETR-ResNet-101
Threshold: 0.5

[3] Parsing 1 safetensor files...
  Parsing: "D:\\Models\\detection_models\\DETR-ResNet-101\\model.safetensors"
[INFO] Found 789 tensors

[4] Building tensor name hierarchy...
[HIER] Building tensor hierarchy from 789 tensors
[HIER] Found 1211 unique hierarchy nodes
[HIER] Built 1211 compositions with atom children
[HIER] Built 1208 composition->composition edges
[HIER] Inserted/updated 1211 hierarchy compositions
[HIER] Inserted 24676 atom children
[HIER] Inserted 482 composition->composition edges

[6] Computing composition centroids hierarchically...
[CENTROID] Updated 1410 composition centroids from atoms

[7] Extracting embedding k-NN similarity as relations...
[EMBED] Found 1 embedding tensor(s)
[EMBED] Processing model.query_position_embeddings.weight [position, thresh=0.02]: 100 x 256 dims
[EMBED] Read embeddings in 1ms
[EMBED] Built k-NN graph: 759 edges in 2ms
[EMBED] Processed all tensors in 9ms, 759 edges
[EMBED] Bulk inserted 759 relations in 18ms
[EMBED] Total: 759 embedding similarity relations

[8] Extracting weight-based relations (router, attention, MLP)...
[ROUTER] No router tensors found (not an MoE model)

[ATTN] Extracting attention projection similarities...
[ATTN] Processing 18 q_proj tensors
  model.decoder.layers.4.self_attn.q_proj.weight [256 x 256] layer=4
    -> 1363 weight similarity edges
  model.decoder.layers.1.encoder_attn.q_proj.weight [256 x 256] layer=1
    -> 1182 weight similarity edges
  model.encoder.layers.3.self_attn.q_proj.weight [256 x 256] layer=3
    -> 1278 weight similarity edges
  model.encoder.layers.2.self_attn.q_proj.weight [256 x 256] layer=2
    -> 1219 weight similarity edges
  model.encoder.layers.1.self_attn.q_proj.weight [256 x 256] layer=1
    -> 1214 weight similarity edges
  model.encoder.layers.4.self_attn.q_proj.weight [256 x 256] layer=4
    -> 1124 weight similarity edges
  model.decoder.layers.5.self_attn.q_proj.weight [256 x 256] layer=5
    -> 954 weight similarity edges
  model.decoder.layers.2.self_attn.q_proj.weight [256 x 256] layer=2
    -> 1243 weight similarity edges
  model.decoder.layers.1.self_attn.q_proj.weight [256 x 256] layer=1
    -> 1200 weight similarity edges
  model.decoder.layers.2.encoder_attn.q_proj.weight [256 x 256] layer=2
    -> 1345 weight similarity edges
  model.decoder.layers.0.encoder_attn.q_proj.weight [256 x 256] layer=0
    -> 1373 weight similarity edges
  model.encoder.layers.5.self_attn.q_proj.weight [256 x 256] layer=5
    -> 1360 weight similarity edges
  model.decoder.layers.0.self_attn.q_proj.weight [256 x 256] layer=0
    -> 1099 weight similarity edges
  model.decoder.layers.3.encoder_attn.q_proj.weight [256 x 256] layer=3
    -> 1320 weight similarity edges
  model.decoder.layers.3.self_attn.q_proj.weight [256 x 256] layer=3
    -> 1254 weight similarity edges
  model.decoder.layers.4.encoder_attn.q_proj.weight [256 x 256] layer=4
    -> 1392 weight similarity edges
  model.decoder.layers.5.encoder_attn.q_proj.weight [256 x 256] layer=5
    -> 1311 weight similarity edges
  model.encoder.layers.0.self_attn.q_proj.weight [256 x 256] layer=0
    -> 956 weight similarity edges
[ATTN] Processing 18 k_proj tensors
  model.encoder.layers.2.self_attn.k_proj.weight [256 x 256] layer=2
    -> 1067 weight similarity edges
  model.decoder.layers.3.self_attn.k_proj.weight [256 x 256] layer=3
    -> 1054 weight similarity edges
  model.decoder.layers.4.self_attn.k_proj.weight [256 x 256] layer=4
    -> 1122 weight similarity edges
  model.encoder.layers.5.self_attn.k_proj.weight [256 x 256] layer=5
    -> 1253 weight similarity edges
  model.decoder.layers.5.self_attn.k_proj.weight [256 x 256] layer=5
    -> 1059 weight similarity edges
  model.decoder.layers.2.encoder_attn.k_proj.weight [256 x 256] layer=2
    -> 1220 weight similarity edges
  model.decoder.layers.0.self_attn.k_proj.weight [256 x 256] layer=0
    -> 915 weight similarity edges
  model.decoder.layers.4.encoder_attn.k_proj.weight [256 x 256] layer=4
    -> 1146 weight similarity edges
  model.decoder.layers.0.encoder_attn.k_proj.weight [256 x 256] layer=0
    -> 1298 weight similarity edges
  model.encoder.layers.4.self_attn.k_proj.weight [256 x 256] layer=4
    -> 1143 weight similarity edges
  model.decoder.layers.1.encoder_attn.k_proj.weight [256 x 256] layer=1
    -> 1342 weight similarity edges
  model.decoder.layers.1.self_attn.k_proj.weight [256 x 256] layer=1
    -> 1012 weight similarity edges
  model.decoder.layers.2.self_attn.k_proj.weight [256 x 256] layer=2
    -> 1095 weight similarity edges
  model.decoder.layers.3.encoder_attn.k_proj.weight [256 x 256] layer=3
    -> 1186 weight similarity edges
  model.decoder.layers.5.encoder_attn.k_proj.weight [256 x 256] layer=5
    -> 1119 weight similarity edges
  model.encoder.layers.0.self_attn.k_proj.weight [256 x 256] layer=0
    -> 1074 weight similarity edges
  model.encoder.layers.1.self_attn.k_proj.weight [256 x 256] layer=1
    -> 1007 weight similarity edges
  model.encoder.layers.3.self_attn.k_proj.weight [256 x 256] layer=3
    -> 1303 weight similarity edges
[ATTN] Processing 18 v_proj tensors
  model.decoder.layers.3.self_attn.v_proj.weight [256 x 256] layer=3
    -> 983 weight similarity edges
  model.decoder.layers.4.encoder_attn.v_proj.weight [256 x 256] layer=4
    -> 1059 weight similarity edges
  model.encoder.layers.4.self_attn.v_proj.weight [256 x 256] layer=4
    -> 1084 weight similarity edges
  model.decoder.layers.0.encoder_attn.v_proj.weight [256 x 256] layer=0
    -> 1297 weight similarity edges
  model.decoder.layers.1.encoder_attn.v_proj.weight [256 x 256] layer=1
    -> 1268 weight similarity edges
  model.decoder.layers.1.self_attn.v_proj.weight [256 x 256] layer=1
    -> 722 weight similarity edges
  model.decoder.layers.3.encoder_attn.v_proj.weight [256 x 256] layer=3
    -> 1125 weight similarity edges
  model.encoder.layers.3.self_attn.v_proj.weight [256 x 256] layer=3
    -> 1100 weight similarity edges
  model.decoder.layers.2.self_attn.v_proj.weight [256 x 256] layer=2
    -> 866 weight similarity edges
  model.decoder.layers.0.self_attn.v_proj.weight [256 x 256] layer=0
    -> 279 weight similarity edges
  model.decoder.layers.2.encoder_attn.v_proj.weight [256 x 256] layer=2
    -> 1190 weight similarity edges
  model.decoder.layers.5.encoder_attn.v_proj.weight [256 x 256] layer=5
    -> 984 weight similarity edges
  model.decoder.layers.5.self_attn.v_proj.weight [256 x 256] layer=5
    -> 1143 weight similarity edges
  model.decoder.layers.4.self_attn.v_proj.weight [256 x 256] layer=4
    -> 1087 weight similarity edges
  model.encoder.layers.0.self_attn.v_proj.weight [256 x 256] layer=0
    -> 584 weight similarity edges
  model.encoder.layers.1.self_attn.v_proj.weight [256 x 256] layer=1
    -> 698 weight similarity edges
  model.encoder.layers.2.self_attn.v_proj.weight [256 x 256] layer=2
    -> 779 weight similarity edges
  model.encoder.layers.5.self_attn.v_proj.weight [256 x 256] layer=5
    -> 1244 weight similarity edges
[ATTN] Processing 12 fc1 tensors
  model.decoder.layers.1.fc1.weight [2048 x 256] layer=1
    -> 10401 weight similarity edges
  model.decoder.layers.5.fc1.weight [2048 x 256] layer=5
    -> 10253 weight similarity edges
  model.encoder.layers.4.fc1.weight [2048 x 256] layer=4
    -> 10228 weight similarity edges
  model.encoder.layers.5.fc1.weight [2048 x 256] layer=5
    -> 10170 weight similarity edges
  model.encoder.layers.3.fc1.weight [2048 x 256] layer=3
    -> 10104 weight similarity edges
  model.decoder.layers.0.fc1.weight [2048 x 256] layer=0
    -> 10092 weight similarity edges
  model.decoder.layers.2.fc1.weight [2048 x 256] layer=2
    -> 10259 weight similarity edges
  model.decoder.layers.3.fc1.weight [2048 x 256] layer=3
    -> 10340 weight similarity edges
  model.decoder.layers.4.fc1.weight [2048 x 256] layer=4
    -> 10148 weight similarity edges
  model.encoder.layers.0.fc1.weight [2048 x 256] layer=0
    -> 10095 weight similarity edges
  model.encoder.layers.1.fc1.weight [2048 x 256] layer=1
    -> 10227 weight similarity edges
  model.encoder.layers.2.fc1.weight [2048 x 256] layer=2
    -> 10224 weight similarity edges
[ATTN] Processing 12 fc2 tensors
  model.encoder.layers.2.fc2.weight [256 x 2048] layer=2
    -> 417 weight similarity edges
  model.decoder.layers.1.fc2.weight [256 x 2048] layer=1
    -> 536 weight similarity edges
  model.decoder.layers.5.fc2.weight [256 x 2048] layer=5
    -> 498 weight similarity edges
  model.encoder.layers.5.fc2.weight [256 x 2048] layer=5
    -> 275 weight similarity edges
  model.encoder.layers.3.fc2.weight [256 x 2048] layer=3
    -> 299 weight similarity edges
  model.decoder.layers.3.fc2.weight [256 x 2048] layer=3
    -> 535 weight similarity edges
  model.decoder.layers.0.fc2.weight [256 x 2048] layer=0
    -> 569 weight similarity edges
  model.decoder.layers.2.fc2.weight [256 x 2048] layer=2
    -> 463 weight similarity edges
  model.decoder.layers.4.fc2.weight [256 x 2048] layer=4
    -> 585 weight similarity edges
  model.encoder.layers.0.fc2.weight [256 x 2048] layer=0
    -> 94 weight similarity edges
  model.encoder.layers.1.fc2.weight [256 x 2048] layer=1
    -> 230 weight similarity edges
  model.encoder.layers.4.fc2.weight [256 x 2048] layer=4
    -> 270 weight similarity edges
[ATTN] Processing 1 classifier tensors
  class_labels_classifier.weight [92 x 256] layer=-1
    -> 468 weight similarity edges

[TOKEN-DIM] Extracting token->dimension activation patterns...

[EXTRACT] Total: 187874 relation edges from model weights

=== Complete ===
Total time: 5 seconds
Tensors: 789
BPE merges: 0
Vocab: 0 tokens
=== Universal Safetensor Ingester ===
Directory: D:\Models\detection_models\Florence-2-base
Model: Florence-2-base
Threshold: 0.5

[1] Parsing tokenizer: "D:\\Models\\detection_models\\Florence-2-base\\tokenizer.json"
=== Universal Safetensor Ingester ===
Directory: D:\Models\detection_models\Florence-2-large
Model: Florence-2-large
Threshold: 0.5

[1] Parsing tokenizer: "D:\\Models\\detection_models\\Florence-2-large\\tokenizer.json"
=== Universal Safetensor Ingester ===
Directory: D:\Models\detection_models\Grounding-DINO-Base
Model: Grounding-DINO-Base
Threshold: 0.5

[1] Parsing tokenizer: "D:\\Models\\detection_models\\Grounding-DINO-Base\\tokenizer.json"
[TOKENIZER] Loaded 0 BPE merges, 30522 vocab entries
[2] Parsing vocab: "D:\\Models\\detection_models\\Grounding-DINO-Base\\vocab.txt"

[VOCAB] Loaded 30522 tokens in 523ms using 16 threads
[3] Parsing 1 safetensor files...
  Parsing: "D:\\Models\\detection_models\\Grounding-DINO-Base\\model.safetensors"
[INFO] Found 1206 tensors

[4] Building tensor name hierarchy...
[HIER] Building tensor hierarchy from 1206 tensors
[HIER] Found 2104 unique hierarchy nodes
[HIER] Built 2104 compositions with atom children
[HIER] Built 2103 composition->composition edges
[HIER] Inserted/updated 2104 hierarchy compositions
[HIER] Inserted 127036 atom children
[HIER] Inserted 1883 composition->composition edges

[5] Inserting token compositions...
[COMP] Inserting 30522 token compositions...
[COMP] 29525 multi-char compositions to insert
[COMP] Building batch strings with 16 threads...
  [BUILD] 30522/30522 tokens (60320/s)

[COMP] Built 18997KB compositions + 26895KB children in 507ms
[COMP] Streaming to database...
[COMP] Creating temp tables...
[COMP] Copying compositions to temp table...
  [COPY] Batch 1/16 (2216KB)
  [COPY] Batch 2/16 (2291KB)
  [COPY] Batch 3/16 (8KB)
  [COPY] Batch 4/16 (2073KB)
  [COPY] Batch 5/16 (2266KB)
  [COPY] Batch 6/16 (1946KB)
  [COPY] Batch 7/16 (1167KB)
  [COPY] Batch 8/16 (1024KB)
  [COPY] Batch 9/16 (2006KB)
  [COPY] Batch 10/16 (1236KB)
  [COPY] Batch 11/16 (588KB)
  [COPY] Batch 12/16 (14KB)
  [COPY] Batch 15/16 (2156KB)

[COMP] Copying composition children to temp table...
  [COPY] Batch 1/16 (3137KB)
  [COPY] Batch 2/16 (3240KB)
  [COPY] Batch 3/16 (8KB)
  [COPY] Batch 4/16 (2958KB)
  [COPY] Batch 5/16 (3222KB)
  [COPY] Batch 6/16 (2763KB)
  [COPY] Batch 7/16 (1644KB)
  [COPY] Batch 8/16 (1437KB)
  [COPY] Batch 9/16 (2826KB)
  [COPY] Batch 10/16 (1751KB)
  [COPY] Batch 11/16 (829KB)
  [COPY] Batch 12/16 (14KB)
  [COPY] Batch 15/16 (3062KB)

[COMP] Inserting into composition table...
[COMP] Inserted 29524 compositions
[COMP] Inserting into composition_child table...
[COMP] Inserted 196685 children
[COMP] Inserted 29524 compositions, 196685 children in 2289ms

[6] Computing composition centroids hierarchically...
[CENTROID] Updated 32896 composition centroids from atoms

[7] Extracting embedding k-NN similarity as relations...
[EMBED] Found 7 embedding tensor(s)
[EMBED] Processing model.backbone.conv_encoder.model.embeddings.patch_embeddings.projection.weight [patch, thresh=0]: 128 x 3 dims
[EMBED] Read embeddings in 1ms
[EMBED] Built k-NN graph: 965 edges in 2ms
[EMBED] Processing model.text_backbone.embeddings.word_embeddings.weight [token, thresh=0]: 30522 x 768 dims
[EMBED] Read embeddings in 28ms
[EMBED] Built k-NN graph: 17878 edges in 4535ms
[EMBED] Processing model.text_projection.weight [projection, thresh=0]: 256 x 768 dims
[EMBED] Read embeddings in 0ms
[EMBED] Built k-NN graph: 470 edges in 4ms
[EMBED] Processing model.query_position_embeddings.weight [position, thresh=0]: 900 x 256 dims
[EMBED] Read embeddings in 0ms
[EMBED] Built k-NN graph: 6916 edges in 7ms
[EMBED] Processing model.text_backbone.embeddings.position_embeddings.weight [position, thresh=0]: 512 x 768 dims
[EMBED] Read embeddings in 1ms
[EMBED] Built k-NN graph: 2491 edges in 9ms
[EMBED] Processed all tensors in 4717ms, 28720 edges
[EMBED] Bulk inserted 0 relations in 294ms
[EMBED] Total: 28720 embedding similarity relations

[8] Extracting weight-based relations (router, attention, MLP)...
[ROUTER] No router tensors found (not an MoE model)

[ATTN] Extracting attention projection similarities...
[ATTN] Processing 54 query tensors
  model.decoder.layers.2.self_attn.query.weight [256 x 256] layer=2
    -> 1123 weight similarity edges
  model.backbone.conv_encoder.model.encoder.layers.1.blocks.0.attention.self.query.weight [256 x 256] layer=1
    -> 1252 weight similarity edges
  model.backbone.conv_encoder.model.encoder.layers.2.blocks.17.attention.self.query.weight [512 x 512] layer=2
    -> 2315 weight similarity edges
  model.text_backbone.encoder.layer.2.attention.self.query.weight [768 x 768] layer=-1
    -> 12 weight similarity edges
  model.backbone.conv_encoder.model.encoder.layers.0.blocks.0.attention.self.query.weight [128 x 128] layer=0
    -> 501 weight similarity edges
  model.backbone.conv_encoder.model.encoder.layers.0.blocks.1.attention.self.query.weight [128 x 128] layer=0
    -> 687 weight similarity edges
  model.backbone.conv_encoder.model.encoder.layers.2.blocks.14.attention.self.query.weight [512 x 512] layer=2
    -> 2225 weight similarity edges
  model.decoder.layers.4.self_attn.query.weight [256 x 256] layer=4
    -> 1102 weight similarity edges
  model.backbone.conv_encoder.model.encoder.layers.2.blocks.13.attention.self.query.weight [512 x 512] layer=2
    -> 2159 weight similarity edges
  model.decoder.layers.0.encoder_attn_text.query.weight [256 x 256] layer=0
    -> 1224 weight similarity edges
  model.backbone.conv_encoder.model.encoder.layers.2.blocks.1.attention.self.query.weight [512 x 512] layer=2
    -> 2347 weight similarity edges
  model.backbone.conv_encoder.model.encoder.layers.2.blocks.16.attention.self.query.weight [512 x 512] layer=2
    -> 2386 weight similarity edges
  model.backbone.conv_encoder.model.encoder.layers.1.blocks.1.attention.self.query.weight [256 x 256] layer=1
    -> 1216 weight similarity edges
  model.backbone.conv_encoder.model.encoder.layers.2.blocks.5.attention.self.query.weight [512 x 512] layer=2
    -> 2478 weight similarity edges
  model.backbone.conv_encoder.model.encoder.layers.2.blocks.0.attention.self.query.weight [512 x 512] layer=2
    -> 2649 weight similarity edges
  model.text_backbone.encoder.layer.10.attention.self.query.weight [768 x 768] layer=-1
    -> 33 weight similarity edges
  model.decoder.layers.5.encoder_attn_text.query.weight [256 x 256] layer=5
    -> 1310 weight similarity edges
  model.backbone.conv_encoder.model.encoder.layers.2.blocks.10.attention.self.query.weight [512 x 512] layer=2
    -> 2318 weight similarity edges
  model.backbone.conv_encoder.model.encoder.layers.3.blocks.0.attention.self.query.weight [1024 x 1024] layer=3
    -> 4913 weight similarity edges
  model.decoder.layers.3.encoder_attn_text.query.weight [256 x 256] layer=3
    -> 1224 weight similarity edges
  model.backbone.conv_encoder.model.encoder.layers.2.blocks.11.attention.self.query.weight [512 x 512] layer=2
    -> 2325 weight similarity edges
  model.backbone.conv_encoder.model.encoder.layers.2.blocks.15.attention.self.query.weight [512 x 512] layer=2
    -> 2339 weight similarity edges
  model.backbone.conv_encoder.model.encoder.layers.2.blocks.12.attention.self.query.weight [512 x 512] layer=2
    -> 2268 weight similarity edges
  model.text_backbone.encoder.layer.11.attention.self.query.weight [768 x 768] layer=-1
    -> 30 weight similarity edges
  model.decoder.layers.0.self_attn.query.weight [256 x 256] layer=0
    -> 1246 weight similarity edges
  model.backbone.conv_encoder.model.encoder.layers.2.blocks.2.attention.self.query.weight [512 x 512] layer=2
    -> 2482 weight similarity edges
  model.backbone.conv_encoder.model.encoder.layers.2.blocks.3.attention.self.query.weight [512 x 512] layer=2
    -> 2558 weight similarity edges
  model.backbone.conv_encoder.model.encoder.layers.2.blocks.7.attention.self.query.weight [512 x 512] layer=2
    -> 2200 weight similarity edges
  model.backbone.conv_encoder.model.encoder.layers.2.blocks.4.attention.self.query.weight [512 x 512] layer=2
    -> 2495 weight similarity edges
  model.text_backbone.encoder.layer.7.attention.self.query.weight [768 x 768] layer=-1
    -> 82 weight similarity edges
  model.backbone.conv_encoder.model.encoder.layers.2.blocks.6.attention.self.query.weight [512 x 512] layer=2
    -> 2352 weight similarity edges
  model.backbone.conv_encoder.model.encoder.layers.2.blocks.9.attention.self.query.weight [512 x 512] layer=2
    -> 2233 weight similarity edges
  model.backbone.conv_encoder.model.encoder.layers.2.blocks.8.attention.self.query.weight [512 x 512] layer=2
    -> 2312 weight similarity edges
  model.encoder.layers.5.text_enhancer_layer.self_attn.query.weight [256 x 256] layer=5
    -> 1301 weight similarity edges
  model.encoder.layers.1.text_enhancer_layer.self_attn.query.weight [256 x 256] layer=1
    -> 1300 weight similarity edges
  model.backbone.conv_encoder.model.encoder.layers.3.blocks.1.attention.self.query.weight [1024 x 1024] layer=3
    -> 1877 weight similarity edges
  model.decoder.layers.3.self_attn.query.weight [256 x 256] layer=3
    -> 1061 weight similarity edges
  model.decoder.layers.1.encoder_attn_text.query.weight [256 x 256] layer=1
    -> 1398 weight similarity edges
  model.text_backbone.encoder.layer.0.attention.self.query.weight [768 x 768] layer=-1
    -> 27 weight similarity edges
  model.decoder.layers.1.self_attn.query.weight [256 x 256] layer=1
    -> 1056 weight similarity edges
  model.decoder.layers.2.encoder_attn_text.query.weight [256 x 256] layer=2
    -> 1274 weight similarity edges
  model.decoder.layers.4.encoder_attn_text.query.weight [256 x 256] layer=4
    -> 1267 weight similarity edges
  model.encoder.layers.3.text_enhancer_layer.self_attn.query.weight [256 x 256] layer=3
    -> 1116 weight similarity edges
  model.text_backbone.encoder.layer.5.attention.self.query.weight [768 x 768] layer=-1
    -> 50 weight similarity edges
  model.decoder.layers.5.self_attn.query.weight [256 x 256] layer=5
    -> 1120 weight similarity edges
  model.text_backbone.encoder.layer.4.attention.self.query.weight [768 x 768] layer=-1
    -> 23 weight similarity edges
  model.encoder.layers.0.text_enhancer_layer.self_attn.query.weight [256 x 256] layer=0
    -> 1335 weight similarity edges
  model.encoder.layers.2.text_enhancer_layer.self_attn.query.weight [256 x 256] layer=2
    -> 1294 weight similarity edges
  model.encoder.layers.4.text_enhancer_layer.self_attn.query.weight [256 x 256] layer=4
    -> 1240 weight similarity edges
  model.text_backbone.encoder.layer.1.attention.self.query.weight [768 x 768] layer=-1
    -> 30 weight similarity edges
  model.text_backbone.encoder.layer.3.attention.self.query.weight [768 x 768] layer=-1
    -> 31 weight similarity edges
  model.text_backbone.encoder.layer.6.attention.self.query.weight [768 x 768] layer=-1
    -> 69 weight similarity edges
  model.text_backbone.encoder.layer.8.attention.self.query.weight [768 x 768] layer=-1
    -> 73 weight similarity edges
  model.text_backbone.encoder.layer.9.attention.self.query.weight [768 x 768] layer=-1
    -> 30 weight similarity edges
[ATTN] Processing 54 key tensors
  model.text_backbone.encoder.layer.10.attention.self.key.weight [768 x 768] layer=-1
    -> 87 weight similarity edges
  model.backbone.conv_encoder.model.encoder.layers.2.blocks.3.attention.self.key.weight [512 x 512] layer=2
    -> 2302 weight similarity edges
  model.text_backbone.encoder.layer.5.attention.self.key.weight [768 x 768] layer=-1
    -> 33 weight similarity edges
  model.decoder.layers.5.self_attn.key.weight [256 x 256] layer=5
    -> 1164 weight similarity edges
  model.text_backbone.encoder.layer.4.attention.self.key.weight [768 x 768] layer=-1
    -> 25 weight similarity edges
  model.backbone.conv_encoder.model.encoder.layers.2.blocks.2.attention.self.key.weight [512 x 512] layer=2
    -> 2165 weight similarity edges
  model.backbone.conv_encoder.model.encoder.layers.0.blocks.1.attention.self.key.weight [128 x 128] layer=0
    -> 693 weight similarity edges
  model.backbone.conv_encoder.model.encoder.layers.0.blocks.0.attention.self.key.weight [128 x 128] layer=0
    -> 578 weight similarity edges
  model.encoder.layers.5.text_enhancer_layer.self_attn.key.weight [256 x 256] layer=5
    -> 1252 weight similarity edges
  model.backbone.conv_encoder.model.encoder.layers.1.blocks.0.attention.self.key.weight [256 x 256] layer=1
    -> 1251 weight similarity edges
  model.backbone.conv_encoder.model.encoder.layers.1.blocks.1.attention.self.key.weight [256 x 256] layer=1
    -> 1226 weight similarity edges
  model.backbone.conv_encoder.model.encoder.layers.2.blocks.0.attention.self.key.weight [512 x 512] layer=2
    -> 2690 weight similarity edges
  model.backbone.conv_encoder.model.encoder.layers.2.blocks.1.attention.self.key.weight [512 x 512] layer=2
    -> 2526 weight similarity edges
  model.decoder.layers.0.encoder_attn_text.key.weight [256 x 256] layer=0
    -> 1201 weight similarity edges
  model.backbone.conv_encoder.model.encoder.layers.2.blocks.10.attention.self.key.weight [512 x 512] layer=2
    -> 2355 weight similarity edges
  model.backbone.conv_encoder.model.encoder.layers.2.blocks.11.attention.self.key.weight [512 x 512] layer=2
    -> 2156 weight similarity edges
  model.backbone.conv_encoder.model.encoder.layers.3.blocks.0.attention.self.key.weight [1024 x 1024] layer=3
    -> 3650 weight similarity edges
  model.text_backbone.encoder.layer.0.attention.self.key.weight [768 x 768] layer=-1
    -> 27 weight similarity edges
  model.backbone.conv_encoder.model.encoder.layers.2.blocks.12.attention.self.key.weight [512 x 512] layer=2
    -> 2160 weight similarity edges
  model.decoder.layers.0.self_attn.key.weight [256 x 256] layer=0
    -> 1177 weight similarity edges
  model.backbone.conv_encoder.model.encoder.layers.2.blocks.13.attention.self.key.weight [512 x 512] layer=2
    -> 1832 weight similarity edges
  model.backbone.conv_encoder.model.encoder.layers.2.blocks.14.attention.self.key.weight [512 x 512] layer=2
    -> 1999 weight similarity edges
  model.decoder.layers.5.encoder_attn_text.key.weight [256 x 256] layer=5
    -> 1347 weight similarity edges
  model.encoder.layers.0.text_enhancer_layer.self_attn.key.weight [256 x 256] layer=0
    -> 1262 weight similarity edges
  model.backbone.conv_encoder.model.encoder.layers.2.blocks.15.attention.self.key.weight [512 x 512] layer=2
    -> 1728 weight similarity edges
  model.backbone.conv_encoder.model.encoder.layers.2.blocks.16.attention.self.key.weight [512 x 512] layer=2
    -> 1780 weight similarity edges
  model.backbone.conv_encoder.model.encoder.layers.2.blocks.17.attention.self.key.weight [512 x 512] layer=2
    -> 1580 weight similarity edges
  model.decoder.layers.1.encoder_attn_text.key.weight [256 x 256] layer=1
    -> 1309 weight similarity edges
  model.backbone.conv_encoder.model.encoder.layers.2.blocks.4.attention.self.key.weight [512 x 512] layer=2
    -> 2105 weight similarity edges
  model.backbone.conv_encoder.model.encoder.layers.2.blocks.8.attention.self.key.weight [512 x 512] layer=2
    -> 2406 weight similarity edges
  model.decoder.layers.4.self_attn.key.weight [256 x 256] layer=4
    -> 1074 weight similarity edges
  model.backbone.conv_encoder.model.encoder.layers.2.blocks.5.attention.self.key.weight [512 x 512] layer=2
    -> 2230 weight similarity edges
  model.backbone.conv_encoder.model.encoder.layers.2.blocks.6.attention.self.key.weight [512 x 512] layer=2
    -> 2072 weight similarity edges
  model.backbone.conv_encoder.model.encoder.layers.2.blocks.7.attention.self.key.weight [512 x 512] layer=2
    -> 2351 weight similarity edges
  model.backbone.conv_encoder.model.encoder.layers.2.blocks.9.attention.self.key.weight [512 x 512] layer=2
    -> 2286 weight similarity edges
  model.backbone.conv_encoder.model.encoder.layers.3.blocks.1.attention.self.key.weight [1024 x 1024] layer=3
    -> 1256 weight similarity edges
  model.decoder.layers.1.self_attn.key.weight [256 x 256] layer=1
    -> 1057 weight similarity edges
  model.decoder.layers.2.encoder_attn_text.key.weight [256 x 256] layer=2
    -> 1302 weight similarity edges
  model.decoder.layers.2.self_attn.key.weight [256 x 256] layer=2
    -> 1198 weight similarity edges
  model.decoder.layers.3.encoder_attn_text.key.weight [256 x 256] layer=3
    -> 1232 weight similarity edges
  model.decoder.layers.3.self_attn.key.weight [256 x 256] layer=3
    -> 1039 weight similarity edges
  model.decoder.layers.4.encoder_attn_text.key.weight [256 x 256] layer=4
    -> 1342 weight similarity edges
  model.text_backbone.encoder.layer.7.attention.self.key.weight [768 x 768] layer=-1
    -> 59 weight similarity edges
  model.encoder.layers.1.text_enhancer_layer.self_attn.key.weight [256 x 256] layer=1
    -> 1299 weight similarity edges
  model.text_backbone.encoder.layer.8.attention.self.key.weight [768 x 768] layer=-1
    -> 90 weight similarity edges
  model.encoder.layers.2.text_enhancer_layer.self_attn.key.weight [256 x 256] layer=2
    -> 1270 weight similarity edges
  model.encoder.layers.3.text_enhancer_layer.self_attn.key.weight [256 x 256] layer=3
    -> 1225 weight similarity edges
  model.encoder.layers.4.text_enhancer_layer.self_attn.key.weight [256 x 256] layer=4
    -> 1260 weight similarity edges
  model.text_backbone.encoder.layer.1.attention.self.key.weight [768 x 768] layer=-1
    -> 72 weight similarity edges
  model.text_backbone.encoder.layer.11.attention.self.key.weight [768 x 768] layer=-1
    -> 48 weight similarity edges
  model.text_backbone.encoder.layer.2.attention.self.key.weight [768 x 768] layer=-1
    -> 13 weight similarity edges
  model.text_backbone.encoder.layer.3.attention.self.key.weight [768 x 768] layer=-1
    -> 17 weight similarity edges
  model.text_backbone.encoder.layer.6.attention.self.key.weight [768 x 768] layer=-1
    -> 46 weight similarity edges
  model.text_backbone.encoder.layer.9.attention.self.key.weight [768 x 768] layer=-1
    -> 37 weight similarity edges
[ATTN] Processing 54 value tensors
  model.backbone.conv_encoder.model.encoder.layers.2.blocks.9.attention.self.value.weight [512 x 512] layer=2
    -> 1628 weight similarity edges
  model.encoder.layers.5.text_enhancer_layer.self_attn.value.weight [256 x 256] layer=5
    -> 897 weight similarity edges
  model.decoder.layers.0.self_attn.value.weight [256 x 256] layer=0
    -> 1212 weight similarity edges
  model.backbone.conv_encoder.model.encoder.layers.2.blocks.0.attention.self.value.weight [512 x 512] layer=2
    -> 2605 weight similarity edges
  model.backbone.conv_encoder.model.encoder.layers.0.blocks.0.attention.self.value.weight [128 x 128] layer=0
    -> 549 weight similarity edges
  model.backbone.conv_encoder.model.encoder.layers.0.blocks.1.attention.self.value.weight [128 x 128] layer=0
    -> 531 weight similarity edges
  model.backbone.conv_encoder.model.encoder.layers.2.blocks.17.attention.self.value.weight [512 x 512] layer=2
    -> 625 weight similarity edges
  model.backbone.conv_encoder.model.encoder.layers.2.blocks.14.attention.self.value.weight [512 x 512] layer=2
    -> 1197 weight similarity edges
  model.backbone.conv_encoder.model.encoder.layers.3.blocks.0.attention.self.value.weight [1024 x 1024] layer=3
    -> 2280 weight similarity edges
  model.backbone.conv_encoder.model.encoder.layers.1.blocks.0.attention.self.value.weight [256 x 256] layer=1
    -> 929 weight similarity edges
  model.backbone.conv_encoder.model.encoder.layers.2.blocks.6.attention.self.value.weight [512 x 512] layer=2
    -> 1680 weight similarity edges
  model.backbone.conv_encoder.model.encoder.layers.1.blocks.1.attention.self.value.weight [256 x 256] layer=1
    -> 833 weight similarity edges
  model.encoder.layers.0.text_enhancer_layer.self_attn.value.weight [256 x 256] layer=0
    -> 858 weight similarity edges
  model.decoder.layers.0.encoder_attn_text.value.weight [256 x 256] layer=0
    -> 1226 weight similarity edges
  model.backbone.conv_encoder.model.encoder.layers.2.blocks.1.attention.self.value.weight [512 x 512] layer=2
    -> 1592 weight similarity edges
  model.backbone.conv_encoder.model.encoder.layers.2.blocks.5.attention.self.value.weight [512 x 512] layer=2
    -> 1344 weight similarity edges
  model.backbone.conv_encoder.model.encoder.layers.2.blocks.10.attention.self.value.weight [512 x 512] layer=2
    -> 1767 weight similarity edges
  model.text_backbone.encoder.layer.4.attention.self.value.weight [768 x 768] layer=-1
    -> 5 weight similarity edges
  model.backbone.conv_encoder.model.encoder.layers.2.blocks.11.attention.self.value.weight [512 x 512] layer=2
    -> 1562 weight similarity edges
  model.backbone.conv_encoder.model.encoder.layers.2.blocks.12.attention.self.value.weight [512 x 512] layer=2
    -> 1367 weight similarity edges
  model.decoder.layers.2.self_attn.value.weight [256 x 256] layer=2
    -> 853 weight similarity edges
  model.backbone.conv_encoder.model.encoder.layers.2.blocks.13.attention.self.value.weight [512 x 512] layer=2
    -> 1522 weight similarity edges
  model.backbone.conv_encoder.model.encoder.layers.2.blocks.3.attention.self.value.weight [512 x 512] layer=2
    -> 1303 weight similarity edges
  model.backbone.conv_encoder.model.encoder.layers.2.blocks.15.attention.self.value.weight [512 x 512] layer=2
    -> 1040 weight similarity edges
  model.backbone.conv_encoder.model.encoder.layers.2.blocks.16.attention.self.value.weight [512 x 512] layer=2
    -> 678 weight similarity edges
  model.text_backbone.encoder.layer.1.attention.self.value.weight [768 x 768] layer=-1
    -> 6 weight similarity edges
  model.text_backbone.encoder.layer.3.attention.self.value.weight [768 x 768] layer=-1
    -> 4 weight similarity edges
  model.decoder.layers.2.encoder_attn_text.value.weight [256 x 256] layer=2
    -> 1294 weight similarity edges
  model.backbone.conv_encoder.model.encoder.layers.2.blocks.2.attention.self.value.weight [512 x 512] layer=2
    -> 1715 weight similarity edges
  model.backbone.conv_encoder.model.encoder.layers.2.blocks.4.attention.self.value.weight [512 x 512] layer=2
    -> 1714 weight similarity edges
  model.backbone.conv_encoder.model.encoder.layers.2.blocks.7.attention.self.value.weight [512 x 512] layer=2
    -> 1596 weight similarity edges
  model.backbone.conv_encoder.model.encoder.layers.2.blocks.8.attention.self.value.weight [512 x 512] layer=2
    -> 1727 weight similarity edges
  model.backbone.conv_encoder.model.encoder.layers.3.blocks.1.attention.self.value.weight [1024 x 1024] layer=3
    -> 916 weight similarity edges
  model.decoder.layers.1.encoder_attn_text.value.weight [256 x 256] layer=1
    -> 1306 weight similarity edges
  model.decoder.layers.1.self_attn.value.weight [256 x 256] layer=1
    -> 834 weight similarity edges
  model.decoder.layers.3.encoder_attn_text.value.weight [256 x 256] layer=3
    -> 1235 weight similarity edges
  model.decoder.layers.3.self_attn.value.weight [256 x 256] layer=3
    -> 797 weight similarity edges
  model.decoder.layers.4.encoder_attn_text.value.weight [256 x 256] layer=4
    -> 1261 weight similarity edges
  model.decoder.layers.4.self_attn.value.weight [256 x 256] layer=4
    -> 903 weight similarity edges
  model.decoder.layers.5.encoder_attn_text.value.weight [256 x 256] layer=5
    -> 1285 weight similarity edges
  model.text_backbone.encoder.layer.5.attention.self.value.weight [768 x 768] layer=-1
    -> 15 weight similarity edges
  model.decoder.layers.5.self_attn.value.weight [256 x 256] layer=5
    -> 1088 weight similarity edges
  model.encoder.layers.1.text_enhancer_layer.self_attn.value.weight [256 x 256] layer=1
    -> 1146 weight similarity edges
  model.text_backbone.encoder.layer.0.attention.self.value.weight [768 x 768] layer=-1
    -> 5 weight similarity edges
  model.encoder.layers.2.text_enhancer_layer.self_attn.value.weight [256 x 256] layer=2
    -> 1105 weight similarity edges
  model.encoder.layers.3.text_enhancer_layer.self_attn.value.weight [256 x 256] layer=3
    -> 843 weight similarity edges
  model.encoder.layers.4.text_enhancer_layer.self_attn.value.weight [256 x 256] layer=4
    -> 956 weight similarity edges
  model.text_backbone.encoder.layer.10.attention.self.value.weight [768 x 768] layer=-1
    -> 6 weight similarity edges
  model.text_backbone.encoder.layer.11.attention.self.value.weight [768 x 768] layer=-1
    -> 6 weight similarity edges
  model.text_backbone.encoder.layer.2.attention.self.value.weight [768 x 768] layer=-1
    -> 6 weight similarity edges
  model.text_backbone.encoder.layer.6.attention.self.value.weight [768 x 768] layer=-1
    -> 4 weight similarity edges
  model.text_backbone.encoder.layer.7.attention.self.value.weight [768 x 768] layer=-1
    -> 9 weight similarity edges
  model.text_backbone.encoder.layer.8.attention.self.value.weight [768 x 768] layer=-1
    -> 8 weight similarity edges
  model.text_backbone.encoder.layer.9.attention.self.value.weight [768 x 768] layer=-1
    -> 5 weight similarity edges
[ATTN] Processing 18 fc1 tensors
  model.encoder.layers.4.text_enhancer_layer.fc1.weight [1024 x 256] layer=4
    -> 5097 weight similarity edges
  model.encoder.layers.5.text_enhancer_layer.fc1.weight [1024 x 256] layer=5
    -> 5017 weight similarity edges
  model.encoder.layers.0.deformable_layer.fc1.weight [2048 x 256] layer=0
    -> 10244 weight similarity edges
  model.encoder.layers.3.text_enhancer_layer.fc1.weight [1024 x 256] layer=3
    -> 5162 weight similarity edges
  model.decoder.layers.0.fc1.weight [2048 x 256] layer=0
    -> 10354 weight similarity edges
  model.decoder.layers.1.fc1.weight [2048 x 256] layer=1
    -> 10294 weight similarity edges
  model.encoder.layers.1.deformable_layer.fc1.weight [2048 x 256] layer=1
    -> 10288 weight similarity edges
  model.decoder.layers.2.fc1.weight [2048 x 256] layer=2
    -> 10220 weight similarity edges
  model.decoder.layers.3.fc1.weight [2048 x 256] layer=3
    -> 10373 weight similarity edges
  model.decoder.layers.4.fc1.weight [2048 x 256] layer=4
    -> 10185 weight similarity edges
  model.decoder.layers.5.fc1.weight [2048 x 256] layer=5
    -> 10130 weight similarity edges
  model.encoder.layers.0.text_enhancer_layer.fc1.weight [1024 x 256] layer=0
    -> 5054 weight similarity edges
  model.encoder.layers.1.text_enhancer_layer.fc1.weight [1024 x 256] layer=1
    -> 5054 weight similarity edges
  model.encoder.layers.4.deformable_layer.fc1.weight [2048 x 256] layer=4
    -> 10265 weight similarity edges
  model.encoder.layers.2.deformable_layer.fc1.weight [2048 x 256] layer=2
    -> 10234 weight similarity edges
  model.encoder.layers.2.text_enhancer_layer.fc1.weight [1024 x 256] layer=2
    -> 5111 weight similarity edges
  model.encoder.layers.3.deformable_layer.fc1.weight [2048 x 256] layer=3
    -> 10187 weight similarity edges
  model.encoder.layers.5.deformable_layer.fc1.weight [2048 x 256] layer=5
    -> 10260 weight similarity edges
[ATTN] Processing 18 fc2 tensors
  model.encoder.layers.2.text_enhancer_layer.fc2.weight [256 x 1024] layer=2
    -> 351 weight similarity edges
  model.decoder.layers.2.fc2.weight [256 x 2048] layer=2
    -> 294 weight similarity edges
  model.decoder.layers.5.fc2.weight [256 x 2048] layer=5
    -> 696 weight similarity edges
  model.encoder.layers.5.text_enhancer_layer.fc2.weight [256 x 1024] layer=5
    -> 869 weight similarity edges
  model.decoder.layers.0.fc2.weight [256 x 2048] layer=0
    -> 506 weight similarity edges
  model.encoder.layers.5.deformable_layer.fc2.weight [256 x 2048] layer=5
    -> 94 weight similarity edges
  model.encoder.layers.3.text_enhancer_layer.fc2.weight [256 x 1024] layer=3
    -> 159 weight similarity edges
  model.encoder.layers.0.deformable_layer.fc2.weight [256 x 2048] layer=0
  model.encoder.layers.3.deformable_layer.fc2.weight [256 x 2048] layer=3
    -> 149 weight similarity edges
  model.decoder.layers.1.fc2.weight [256 x 2048] layer=1
    -> 385 weight similarity edges
  model.decoder.layers.3.fc2.weight [256 x 2048] layer=3
    -> 279 weight similarity edges
  model.decoder.layers.4.fc2.weight [256 x 2048] layer=4
    -> 423 weight similarity edges
  model.encoder.layers.0.text_enhancer_layer.fc2.weight [256 x 1024] layer=0
    -> 213 weight similarity edges
  model.encoder.layers.1.deformable_layer.fc2.weight [256 x 2048] layer=1
    -> 22 weight similarity edges
  model.encoder.layers.1.text_enhancer_layer.fc2.weight [256 x 1024] layer=1
    -> 233 weight similarity edges
  model.encoder.layers.2.deformable_layer.fc2.weight [256 x 2048] layer=2
    -> 62 weight similarity edges
  model.encoder.layers.4.deformable_layer.fc2.weight [256 x 2048] layer=4
    -> 155 weight similarity edges
  model.encoder.layers.4.text_enhancer_layer.fc2.weight [256 x 1024] layer=4
    -> 258 weight similarity edges
[ATTN] Processing 1 output tensors
  model.enc_output.weight [256 x 256] layer=-1
    -> 1219 weight similarity edges

[TOKEN-DIM] Extracting token->dimension activation patterns...
[TOKEN-DIM] Processing 30522 tokens x 768 dims
[TOKEN-DIM] Created 3 token->dimension edges

[EXTRACT] Total: 357086 relation edges from model weights

=== Complete ===
Total time: 19 seconds
Tensors: 1206
BPE merges: 0
Vocab: 30522 tokens
=== Universal Safetensor Ingester ===
Directory: D:\Models\detection_models\RT-DETR-v1-R101
Model: RT-DETR-v1-R101
Threshold: 0.5

[3] Parsing 1 safetensor files...
  Parsing: "D:\\Models\\detection_models\\RT-DETR-v1-R101\\model.safetensors"
[INFO] Found 1019 tensors

[4] Building tensor name hierarchy...
[HIER] Building tensor hierarchy from 1019 tensors
[HIER] Found 1737 unique hierarchy nodes
[HIER] Built 1737 compositions with atom children
[HIER] Built 1736 composition->composition edges
[HIER] Inserted/updated 1737 hierarchy compositions
[HIER] Inserted 89130 atom children
[HIER] Inserted 1456 composition->composition edges

[6] Computing composition centroids hierarchically...
[CENTROID] Updated 34363 composition centroids from atoms

[7] Extracting embedding k-NN similarity as relations...
[EMBED] No embedding tensors found

[8] Extracting weight-based relations (router, attention, MLP)...
[ROUTER] No router tensors found (not an MoE model)

[ATTN] Extracting attention projection similarities...
[ATTN] Processing 7 q_proj tensors
  model.encoder.encoder.0.layers.0.self_attn.q_proj.weight [384 x 384] layer=0
    -> 1876 weight similarity edges
  model.decoder.layers.5.self_attn.q_proj.weight [256 x 256] layer=5
    -> 1158 weight similarity edges
  model.decoder.layers.4.self_attn.q_proj.weight [256 x 256] layer=4
    -> 1135 weight similarity edges
  model.decoder.layers.2.self_attn.q_proj.weight [256 x 256] layer=2
    -> 1107 weight similarity edges
  model.decoder.layers.3.self_attn.q_proj.weight [256 x 256] layer=3
    -> 1099 weight similarity edges
  model.decoder.layers.0.self_attn.q_proj.weight [256 x 256] layer=0
    -> 1087 weight similarity edges
  model.decoder.layers.1.self_attn.q_proj.weight [256 x 256] layer=1
    -> 1103 weight similarity edges
[ATTN] Processing 7 k_proj tensors
  model.encoder.encoder.0.layers.0.self_attn.k_proj.weight [384 x 384] layer=0
    -> 1750 weight similarity edges
  model.decoder.layers.5.self_attn.k_proj.weight [256 x 256] layer=5
    -> 1131 weight similarity edges
  model.decoder.layers.0.self_attn.k_proj.weight [256 x 256] layer=0
    -> 1140 weight similarity edges
  model.decoder.layers.1.self_attn.k_proj.weight [256 x 256] layer=1
    -> 1230 weight similarity edges
  model.decoder.layers.2.self_attn.k_proj.weight [256 x 256] layer=2
    -> 1150 weight similarity edges
  model.decoder.layers.3.self_attn.k_proj.weight [256 x 256] layer=3
    -> 1066 weight similarity edges
  model.decoder.layers.4.self_attn.k_proj.weight [256 x 256] layer=4
    -> 1118 weight similarity edges
[ATTN] Processing 7 v_proj tensors
  model.decoder.layers.2.self_attn.v_proj.weight [256 x 256] layer=2
    -> 744 weight similarity edges
  model.decoder.layers.3.self_attn.v_proj.weight [256 x 256] layer=3
    -> 673 weight similarity edges
  model.decoder.layers.5.self_attn.v_proj.weight [256 x 256] layer=5
    -> 831 weight similarity edges
  model.decoder.layers.4.self_attn.v_proj.weight [256 x 256] layer=4
    -> 743 weight similarity edges
  model.decoder.layers.0.self_attn.v_proj.weight [256 x 256] layer=0
    -> 1251 weight similarity edges
  model.decoder.layers.1.self_attn.v_proj.weight [256 x 256] layer=1
    -> 899 weight similarity edges
  model.encoder.encoder.0.layers.0.self_attn.v_proj.weight [384 x 384] layer=0
    -> 1049 weight similarity edges
[ATTN] Processing 7 fc1 tensors
  model.decoder.layers.3.fc1.weight [1024 x 256] layer=3
    -> 5132 weight similarity edges
  model.decoder.layers.0.fc1.weight [1024 x 256] layer=0
    -> 5073 weight similarity edges
  model.decoder.layers.2.fc1.weight [1024 x 256] layer=2
    -> 5049 weight similarity edges
  model.decoder.layers.1.fc1.weight [1024 x 256] layer=1
    -> 5077 weight similarity edges
  model.decoder.layers.4.fc1.weight [1024 x 256] layer=4
    -> 5118 weight similarity edges
  model.decoder.layers.5.fc1.weight [1024 x 256] layer=5
    -> 5130 weight similarity edges
  model.encoder.encoder.0.layers.0.fc1.weight [2048 x 384] layer=0
    -> 10201 weight similarity edges
[ATTN] Processing 7 fc2 tensors
  model.decoder.layers.2.fc2.weight [256 x 1024] layer=2
    -> 594 weight similarity edges
  model.decoder.layers.4.fc2.weight [256 x 1024] layer=4
    -> 80 weight similarity edges
  model.decoder.layers.0.fc2.weight [256 x 1024] layer=0
    -> 708 weight similarity edges
  model.decoder.layers.1.fc2.weight [256 x 1024] layer=1
    -> 651 weight similarity edges
  model.decoder.layers.5.fc2.weight [256 x 1024] layer=5
    -> 59 weight similarity edges
  model.decoder.layers.3.fc2.weight [256 x 1024] layer=3
    -> 169 weight similarity edges
  model.encoder.encoder.0.layers.0.fc2.weight [384 x 2048] layer=0
    -> 781 weight similarity edges

[TOKEN-DIM] Extracting token->dimension activation patterns...

[EXTRACT] Total: 67162 relation edges from model weights

=== Complete ===
Total time: 4 seconds
Tensors: 1019
BPE merges: 0
Vocab: 0 tokens
=== Universal Safetensor Ingester ===
Directory: D:\Models\embedding_models\models--meta-llama--Llama-4-Maverick-17B-128E\snapshots\10751cb97a4d7c90f7ed89196b98eb8220cfa1c2
Model: meta-llama/Llama-4-Maverick-17B-128E
Threshold: 0.5

[1] Parsing tokenizer: "D:\\Models\\embedding_models\\models--meta-llama--Llama-4-Maverick-17B-128E\\snapshots\\10751cb97a4d7c90f7ed89196b98eb8220cfa1c2\\tokenizer.json"
[TOKENIZER] Loaded 0 BPE merges, 713 vocab entries
[3] Parsing sharded model index: "D:\\Models\\embedding_models\\models--meta-llama--Llama-4-Maverick-17B-128E\\snapshots\\10751cb97a4d7c90f7ed89196b98eb8220cfa1c2\\model.safetensors.index.json"
  Parsing shard: model-00006-of-00055.safetensors
  Parsing shard: model-00055-of-00055.safetensors
  Parsing shard: model-00029-of-00055.safetensors
  Parsing shard: model-00014-of-00055.safetensors
  Parsing shard: model-00050-of-00055.safetensors
  Parsing shard: model-00003-of-00055.safetensors
  Parsing shard: model-00051-of-00055.safetensors
  Parsing shard: model-00002-of-00055.safetensors
  Parsing shard: model-00052-of-00055.safetensors
  Parsing shard: model-00001-of-00055.safetensors
  Parsing shard: model-00013-of-00055.safetensors
  Parsing shard: model-00012-of-00055.safetensors
  Parsing shard: model-00018-of-00055.safetensors
  Parsing shard: model-00025-of-00055.safetensors
  Parsing shard: model-00016-of-00055.safetensors
  Parsing shard: model-00028-of-00055.safetensors
  Parsing shard: model-00015-of-00055.safetensors
  Parsing shard: model-00017-of-00055.safetensors
  Parsing shard: model-00020-of-00055.safetensors
  Parsing shard: model-00024-of-00055.safetensors
  Parsing shard: model-00019-of-00055.safetensors
  Parsing shard: model-00022-of-00055.safetensors
  Parsing shard: model-00021-of-00055.safetensors
  Parsing shard: model-00023-of-00055.safetensors
  Parsing shard: model-00036-of-00055.safetensors
  Parsing shard: model-00027-of-00055.safetensors
  Parsing shard: model-00026-of-00055.safetensors
  Parsing shard: model-00031-of-00055.safetensors
  Parsing shard: model-00030-of-00055.safetensors
  Parsing shard: model-00033-of-00055.safetensors
  Parsing shard: model-00032-of-00055.safetensors
  Parsing shard: model-00005-of-00055.safetensors
  Parsing shard: model-00004-of-00055.safetensors
  Parsing shard: model-00035-of-00055.safetensors
  Parsing shard: model-00034-of-00055.safetensors
  Parsing shard: model-00047-of-00055.safetensors
  Parsing shard: model-00038-of-00055.safetensors
  Parsing shard: model-00037-of-00055.safetensors
  Parsing shard: model-00040-of-00055.safetensors
  Parsing shard: model-00039-of-00055.safetensors
  Parsing shard: model-00042-of-00055.safetensors
  Parsing shard: model-00041-of-00055.safetensors
  Parsing shard: model-00044-of-00055.safetensors
  Parsing shard: model-00043-of-00055.safetensors
  Parsing shard: model-00046-of-00055.safetensors
  Parsing shard: model-00045-of-00055.safetensors
  Parsing shard: model-00007-of-00055.safetensors
  Parsing shard: model-00054-of-00055.safetensors
  Parsing shard: model-00049-of-00055.safetensors
  Parsing shard: model-00048-of-00055.safetensors
  Parsing shard: model-00053-of-00055.safetensors
  Parsing shard: model-00009-of-00055.safetensors
  Parsing shard: model-00008-of-00055.safetensors
  Parsing shard: model-00011-of-00055.safetensors
  Parsing shard: model-00010-of-00055.safetensors
[INDEX] Parsed 55 shards, 1061 tensors
[INFO] Found 1061 tensors

[4] Building tensor name hierarchy...
[HIER] Building tensor hierarchy from 1061 tensors
[HIER] Found 2102 unique hierarchy nodes
[HIER] Built 2102 compositions with atom children
[HIER] Built 2099 composition->composition edges
[HIER] Inserted/updated 2102 hierarchy compositions
[HIER] Inserted 104074 atom children
[HIER] Inserted 2099 composition->composition edges

[6] Computing composition centroids hierarchically...
[CENTROID] Updated 36465 composition centroids from atoms

[7] Extracting embedding k-NN similarity as relations...
[EMBED] Found 2 embedding tensor(s)
[EMBED] Processing language_model.model.embed_tokens.weight [token, thresh=0.45]: 202048 x 5120 dims
[EMBED] Read embeddings in 964ms
[EMBED] Built k-NN graph: 22703 edges in 667845ms
[EMBED] Processing vision_model.patch_embedding.linear.weight [patch, thresh=0.25]: 1408 x 588 dims
[EMBED] Read embeddings in 4ms
[EMBED] Built k-NN graph: 7409 edges in 21ms
[EMBED] Processed all tensors in 669962ms, 30112 edges
[EMBED] Bulk inserted 30112 relations in 498ms
[EMBED] Total: 30112 embedding similarity relations

[8] Extracting weight-based relations (router, attention, MLP)...
[ROUTER] Found 24 router tensors
[ROUTER] language_model.model.layers.39.feed_forward.router.weight [128 experts x 5120 dims] layer=39
  -> 0 routing edges
[ROUTER] language_model.model.layers.5.feed_forward.router.weight [128 experts x 5120 dims] layer=5
  -> 0 routing edges
[ROUTER] language_model.model.layers.11.feed_forward.router.weight [128 experts x 5120 dims] layer=11
  -> 0 routing edges
[ROUTER] language_model.model.layers.21.feed_forward.router.weight [128 experts x 5120 dims] layer=21
  -> 0 routing edges
[ROUTER] language_model.model.layers.3.feed_forward.router.weight [128 experts x 5120 dims] layer=3
  -> 0 routing edges
[ROUTER] language_model.model.layers.7.feed_forward.router.weight [128 experts x 5120 dims] layer=7
  -> 0 routing edges
[ROUTER] language_model.model.layers.9.feed_forward.router.weight [128 experts x 5120 dims] layer=9
  -> 0 routing edges
[ROUTER] language_model.model.layers.1.feed_forward.router.weight [128 experts x 5120 dims] layer=1
  -> 0 routing edges
[ROUTER] language_model.model.layers.25.feed_forward.router.weight [128 experts x 5120 dims] layer=25
  -> 0 routing edges
[ROUTER] language_model.model.layers.33.feed_forward.router.weight [128 experts x 5120 dims] layer=33
  -> 0 routing edges
[ROUTER] language_model.model.layers.43.feed_forward.router.weight [128 experts x 5120 dims] layer=43
  -> 0 routing edges
[ROUTER] language_model.model.layers.13.feed_forward.router.weight [128 experts x 5120 dims] layer=13
  -> 0 routing edges
[ROUTER] language_model.model.layers.45.feed_forward.router.weight [128 experts x 5120 dims] layer=45
  -> 0 routing edges
[ROUTER] language_model.model.layers.15.feed_forward.router.weight [128 experts x 5120 dims] layer=15
  -> 0 routing edges
[ROUTER] language_model.model.layers.17.feed_forward.router.weight [128 experts x 5120 dims] layer=17
  -> 0 routing edges
[ROUTER] language_model.model.layers.19.feed_forward.router.weight [128 experts x 5120 dims] layer=19
  -> 0 routing edges
[ROUTER] language_model.model.layers.23.feed_forward.router.weight [128 experts x 5120 dims] layer=23
  -> 0 routing edges
[ROUTER] language_model.model.layers.27.feed_forward.router.weight [128 experts x 5120 dims] layer=27
  -> 0 routing edges
[ROUTER] language_model.model.layers.29.feed_forward.router.weight [128 experts x 5120 dims] layer=29
  -> 0 routing edges
[ROUTER] language_model.model.layers.31.feed_forward.router.weight [128 experts x 5120 dims] layer=31
  -> 0 routing edges
[ROUTER] language_model.model.layers.35.feed_forward.router.weight [128 experts x 5120 dims] layer=35
  -> 0 routing edges
[ROUTER] language_model.model.layers.37.feed_forward.router.weight [128 experts x 5120 dims] layer=37
  -> 0 routing edges
[ROUTER] language_model.model.layers.41.feed_forward.router.weight [128 experts x 5120 dims] layer=41
  -> 0 routing edges
[ROUTER] language_model.model.layers.47.feed_forward.router.weight [128 experts x 5120 dims] layer=47
  -> 0 routing edges

[ATTN] Extracting attention projection similarities...
[ATTN] Processing 82 q_proj tensors
  language_model.model.layers.12.self_attn.q_proj.weight [5120 x 5120] layer=12 (sampling every 2 rows)
    -> 5380 weight similarity edges
  vision_model.model.layers.9.self_attn.q_proj.weight [1408 x 1408] layer=9
    -> 5719 weight similarity edges
  vision_model.model.layers.21.self_attn.q_proj.weight [1408 x 1408] layer=21
    -> 3728 weight similarity edges
  language_model.model.layers.5.self_attn.q_proj.weight [5120 x 5120] layer=5 (sampling every 2 rows)
    -> 8362 weight similarity edges
  language_model.model.layers.3.self_attn.q_proj.weight [5120 x 5120] layer=3 (sampling every 2 rows)
    -> 12819 weight similarity edges
  language_model.model.layers.10.self_attn.q_proj.weight [5120 x 5120] layer=10 (sampling every 2 rows)
    -> 6889 weight similarity edges
  vision_model.model.layers.24.self_attn.q_proj.weight [1408 x 1408] layer=24
    -> 3195 weight similarity edges
  language_model.model.layers.31.self_attn.q_proj.weight [5120 x 5120] layer=31 (sampling every 2 rows)
    -> 4985 weight similarity edges
  language_model.model.layers.33.self_attn.q_proj.weight [5120 x 5120] layer=33 (sampling every 2 rows)
    -> 6213 weight similarity edges
  language_model.model.layers.11.self_attn.q_proj.weight [5120 x 5120] layer=11 (sampling every 2 rows)
    -> 4440 weight similarity edges
  language_model.model.layers.19.self_attn.q_proj.weight [5120 x 5120] layer=19 (sampling every 2 rows)
    -> 3225 weight similarity edges
  language_model.model.layers.4.self_attn.q_proj.weight [5120 x 5120] layer=4 (sampling every 2 rows)
    -> 7936 weight similarity edges
  vision_model.model.layers.1.self_attn.q_proj.weight [1408 x 1408] layer=1
    -> 7199 weight similarity edges
  language_model.model.layers.36.self_attn.q_proj.weight [5120 x 5120] layer=36 (sampling every 2 rows)
    -> 6347 weight similarity edges
  vision_model.model.layers.2.self_attn.q_proj.weight [1408 x 1408] layer=2
    -> 7186 weight similarity edges
  language_model.model.layers.6.self_attn.q_proj.weight [5120 x 5120] layer=6 (sampling every 2 rows)
    -> 7140 weight similarity edges
  language_model.model.layers.7.self_attn.q_proj.weight [5120 x 5120] layer=7 (sampling every 2 rows)
    -> 12790 weight similarity edges
  language_model.model.layers.47.self_attn.q_proj.weight [5120 x 5120] layer=47 (sampling every 2 rows)
    -> 12591 weight similarity edges
  vision_model.model.layers.13.self_attn.q_proj.weight [1408 x 1408] layer=13
    -> 5906 weight similarity edges
  language_model.model.layers.8.self_attn.q_proj.weight [5120 x 5120] layer=8 (sampling every 2 rows)
    -> 6523 weight similarity edges
  vision_model.model.layers.22.self_attn.q_proj.weight [1408 x 1408] layer=22
    -> 2847 weight similarity edges
  vision_model.model.layers.5.self_attn.q_proj.weight [1408 x 1408] layer=5
    -> 6926 weight similarity edges
  language_model.model.layers.9.self_attn.q_proj.weight [5120 x 5120] layer=9 (sampling every 2 rows)
    -> 5920 weight similarity edges
  vision_model.model.layers.26.self_attn.q_proj.weight [1408 x 1408] layer=26
    -> 2783 weight similarity edges
  language_model.model.layers.37.self_attn.q_proj.weight [5120 x 5120] layer=37 (sampling every 2 rows)
    -> 8099 weight similarity edges
  language_model.model.layers.0.self_attn.q_proj.weight [5120 x 5120] layer=0 (sampling every 2 rows)
    -> 13658 weight similarity edges
  language_model.model.layers.1.self_attn.q_proj.weight [5120 x 5120] layer=1 (sampling every 2 rows)
    -> 12178 weight similarity edges
  language_model.model.layers.2.self_attn.q_proj.weight [5120 x 5120] layer=2 (sampling every 2 rows)
    -> 12185 weight similarity edges
  vision_model.model.layers.16.self_attn.q_proj.weight [1408 x 1408] layer=16
    -> 5751 weight similarity edges
  language_model.model.layers.32.self_attn.q_proj.weight [5120 x 5120] layer=32 (sampling every 2 rows)
    -> 7162 weight similarity edges
  vision_model.model.layers.0.self_attn.q_proj.weight [1408 x 1408] layer=0
    -> 7116 weight similarity edges
  vision_model.model.layers.25.self_attn.q_proj.weight [1408 x 1408] layer=25
    -> 2848 weight similarity edges
  vision_model.model.layers.17.self_attn.q_proj.weight [1408 x 1408] layer=17
    -> 4845 weight similarity edges
  vision_model.model.layers.10.self_attn.q_proj.weight [1408 x 1408] layer=10
    -> 5570 weight similarity edges
  language_model.model.layers.34.self_attn.q_proj.weight [5120 x 5120] layer=34 (sampling every 2 rows)
    -> 6968 weight similarity edges
  vision_model.model.layers.27.self_attn.q_proj.weight [1408 x 1408] layer=27
    -> 3226 weight similarity edges
  vision_model.model.layers.11.self_attn.q_proj.weight [1408 x 1408] layer=11
    -> 5603 weight similarity edges
  vision_model.model.layers.12.self_attn.q_proj.weight [1408 x 1408] layer=12
    -> 5352 weight similarity edges
  vision_model.model.layers.29.self_attn.q_proj.weight [1408 x 1408] layer=29
    -> 2647 weight similarity edges
  vision_model.model.layers.14.self_attn.q_proj.weight [1408 x 1408] layer=14
    -> 5667 weight similarity edges
  language_model.model.layers.30.self_attn.q_proj.weight [5120 x 5120] layer=30 (sampling every 2 rows)
    -> 7316 weight similarity edges
  vision_model.model.layers.15.self_attn.q_proj.weight [1408 x 1408] layer=15
    -> 5736 weight similarity edges
  language_model.model.layers.24.self_attn.q_proj.weight [5120 x 5120] layer=24 (sampling every 2 rows)
    -> 6506 weight similarity edges
  language_model.model.layers.27.self_attn.q_proj.weight [5120 x 5120] layer=27 (sampling every 2 rows)
    -> 5479 weight similarity edges
  vision_model.model.layers.8.self_attn.q_proj.weight [1408 x 1408] layer=8
    -> 6152 weight similarity edges
  vision_model.model.layers.18.self_attn.q_proj.weight [1408 x 1408] layer=18
    -> 4877 weight similarity edges
  vision_model.model.layers.19.self_attn.q_proj.weight [1408 x 1408] layer=19
    -> 4426 weight similarity edges
  vision_model.model.layers.20.self_attn.q_proj.weight [1408 x 1408] layer=20
    -> 3649 weight similarity edges
  language_model.model.layers.29.self_attn.q_proj.weight [5120 x 5120] layer=29 (sampling every 2 rows)
    -> 7262 weight similarity edges
  language_model.model.layers.23.self_attn.q_proj.weight [5120 x 5120] layer=23 (sampling every 2 rows)
    -> 4669 weight similarity edges
  vision_model.model.layers.23.self_attn.q_proj.weight [1408 x 1408] layer=23
    -> 3169 weight similarity edges
  language_model.model.layers.28.self_attn.q_proj.weight [5120 x 5120] layer=28 (sampling every 2 rows)
    -> 5855 weight similarity edges
  language_model.model.layers.45.self_attn.q_proj.weight [5120 x 5120] layer=45 (sampling every 2 rows)
    -> 8772 weight similarity edges
  vision_model.model.layers.28.self_attn.q_proj.weight [1408 x 1408] layer=28
    -> 3225 weight similarity edges
  vision_model.model.layers.3.self_attn.q_proj.weight [1408 x 1408] layer=3
    -> 6982 weight similarity edges
  language_model.model.layers.39.self_attn.q_proj.weight [5120 x 5120] layer=39 (sampling every 2 rows)
    -> 4484 weight similarity edges
  vision_model.model.layers.30.self_attn.q_proj.weight [1408 x 1408] layer=30
    -> 2411 weight similarity edges
  vision_model.model.layers.31.self_attn.q_proj.weight [1408 x 1408] layer=31
    -> 2731 weight similarity edges
  vision_model.model.layers.33.self_attn.q_proj.weight [1408 x 1408] layer=33
    -> 6647 weight similarity edges
  vision_model.model.layers.32.self_attn.q_proj.weight [1408 x 1408] layer=32
    -> 4659 weight similarity edges
  language_model.model.layers.14.self_attn.q_proj.weight [5120 x 5120] layer=14 (sampling every 2 rows)
    -> 5339 weight similarity edges
  vision_model.model.layers.4.self_attn.q_proj.weight [1408 x 1408] layer=4
    -> 7050 weight similarity edges
  vision_model.model.layers.6.self_attn.q_proj.weight [1408 x 1408] layer=6
    -> 6725 weight similarity edges
  vision_model.model.layers.7.self_attn.q_proj.weight [1408 x 1408] layer=7
    -> 6637 weight similarity edges
  language_model.model.layers.40.self_attn.q_proj.weight [5120 x 5120] layer=40 (sampling every 2 rows)
    -> 6678 weight similarity edges
  language_model.model.layers.13.self_attn.q_proj.weight [5120 x 5120] layer=13 (sampling every 2 rows)
    -> 7132 weight similarity edges
  language_model.model.layers.15.self_attn.q_proj.weight [5120 x 5120] layer=15 (sampling every 2 rows)
    -> 3176 weight similarity edges
  language_model.model.layers.16.self_attn.q_proj.weight [5120 x 5120] layer=16 (sampling every 2 rows)
    -> 4828 weight similarity edges
  language_model.model.layers.17.self_attn.q_proj.weight [5120 x 5120] layer=17 (sampling every 2 rows)
    -> 6165 weight similarity edges
  language_model.model.layers.18.self_attn.q_proj.weight [5120 x 5120] layer=18 (sampling every 2 rows)
    -> 5141 weight similarity edges
  language_model.model.layers.20.self_attn.q_proj.weight [5120 x 5120] layer=20 (sampling every 2 rows)
    -> 5016 weight similarity edges
  language_model.model.layers.21.self_attn.q_proj.weight [5120 x 5120] layer=21 (sampling every 2 rows)
    -> 6196 weight similarity edges
  language_model.model.layers.22.self_attn.q_proj.weight [5120 x 5120] layer=22 (sampling every 2 rows)
    -> 5247 weight similarity edges
  language_model.model.layers.25.self_attn.q_proj.weight [5120 x 5120] layer=25 (sampling every 2 rows)
    -> 8032 weight similarity edges
  language_model.model.layers.26.self_attn.q_proj.weight [5120 x 5120] layer=26 (sampling every 2 rows)
    -> 7162 weight similarity edges
  language_model.model.layers.35.self_attn.q_proj.weight [5120 x 5120] layer=35 (sampling every 2 rows)
    -> 4647 weight similarity edges
  language_model.model.layers.38.self_attn.q_proj.weight [5120 x 5120] layer=38 (sampling every 2 rows)
    -> 8183 weight similarity edges
  language_model.model.layers.41.self_attn.q_proj.weight [5120 x 5120] layer=41 (sampling every 2 rows)
    -> 7465 weight similarity edges
  language_model.model.layers.42.self_attn.q_proj.weight [5120 x 5120] layer=42 (sampling every 2 rows)
    -> 8135 weight similarity edges
  language_model.model.layers.43.self_attn.q_proj.weight [5120 x 5120] layer=43 (sampling every 2 rows)
    -> 6310 weight similarity edges
  language_model.model.layers.44.self_attn.q_proj.weight [5120 x 5120] layer=44 (sampling every 2 rows)
    -> 7265 weight similarity edges
  language_model.model.layers.46.self_attn.q_proj.weight [5120 x 5120] layer=46 (sampling every 2 rows)
    -> 7929 weight similarity edges
[ATTN] Processing 82 k_proj tensors
  language_model.model.layers.20.self_attn.k_proj.weight [1024 x 5120] layer=20
    -> 914 weight similarity edges
  language_model.model.layers.46.self_attn.k_proj.weight [1024 x 5120] layer=46
    -> 2984 weight similarity edges
  language_model.model.layers.3.self_attn.k_proj.weight [1024 x 5120] layer=3
    -> 5175 weight similarity edges
  language_model.model.layers.10.self_attn.k_proj.weight [1024 x 5120] layer=10
    -> 1859 weight similarity edges
  language_model.model.layers.36.self_attn.k_proj.weight [1024 x 5120] layer=36
    -> 1279 weight similarity edges
  language_model.model.layers.11.self_attn.k_proj.weight [1024 x 5120] layer=11
    -> 375 weight similarity edges
  vision_model.model.layers.17.self_attn.k_proj.weight [1408 x 1408] layer=17
    -> 4085 weight similarity edges
  vision_model.model.layers.24.self_attn.k_proj.weight [1408 x 1408] layer=24
    -> 2424 weight similarity edges
  language_model.model.layers.12.self_attn.k_proj.weight [1024 x 5120] layer=12
    -> 1357 weight similarity edges
  language_model.model.layers.4.self_attn.k_proj.weight [1024 x 5120] layer=4
    -> 2897 weight similarity edges
  language_model.model.layers.5.self_attn.k_proj.weight [1024 x 5120] layer=5
    -> 2304 weight similarity edges
  vision_model.model.layers.25.self_attn.k_proj.weight [1408 x 1408] layer=25
    -> 2420 weight similarity edges
  vision_model.model.layers.22.self_attn.k_proj.weight [1408 x 1408] layer=22
    -> 2268 weight similarity edges
  language_model.model.layers.6.self_attn.k_proj.weight [1024 x 5120] layer=6
    -> 1903 weight similarity edges
  language_model.model.layers.19.self_attn.k_proj.weight [1024 x 5120] layer=19
    -> 143 weight similarity edges
  language_model.model.layers.7.self_attn.k_proj.weight [1024 x 5120] layer=7
    -> 5181 weight similarity edges
  language_model.model.layers.8.self_attn.k_proj.weight [1024 x 5120] layer=8
    -> 1771 weight similarity edges
  vision_model.model.layers.2.self_attn.k_proj.weight [1408 x 1408] layer=2
    -> 7144 weight similarity edges
  language_model.model.layers.9.self_attn.k_proj.weight [1024 x 5120] layer=9
    -> 1602 weight similarity edges
  vision_model.model.layers.5.self_attn.k_proj.weight [1408 x 1408] layer=5
    -> 6911 weight similarity edges
  language_model.model.layers.0.self_attn.k_proj.weight [1024 x 5120] layer=0
    -> 5563 weight similarity edges
  vision_model.model.layers.26.self_attn.k_proj.weight [1408 x 1408] layer=26
    -> 2406 weight similarity edges
  vision_model.model.layers.20.self_attn.k_proj.weight [1408 x 1408] layer=20
    -> 2712 weight similarity edges
  language_model.model.layers.1.self_attn.k_proj.weight [1024 x 5120] layer=1
    -> 4754 weight similarity edges
  language_model.model.layers.2.self_attn.k_proj.weight [1024 x 5120] layer=2
    -> 5046 weight similarity edges
  vision_model.model.layers.12.self_attn.k_proj.weight [1408 x 1408] layer=12
    -> 5000 weight similarity edges
  language_model.model.layers.28.self_attn.k_proj.weight [1024 x 5120] layer=28
    -> 1186 weight similarity edges
  vision_model.model.layers.0.self_attn.k_proj.weight [1408 x 1408] layer=0
    -> 7210 weight similarity edges
  vision_model.model.layers.1.self_attn.k_proj.weight [1408 x 1408] layer=1
    -> 7119 weight similarity edges
  vision_model.model.layers.18.self_attn.k_proj.weight [1408 x 1408] layer=18
    -> 3998 weight similarity edges
  language_model.model.layers.23.self_attn.k_proj.weight [1024 x 5120] layer=23
    -> 354 weight similarity edges
  vision_model.model.layers.10.self_attn.k_proj.weight [1408 x 1408] layer=10
    -> 5330 weight similarity edges
  language_model.model.layers.26.self_attn.k_proj.weight [1024 x 5120] layer=26
    -> 1729 weight similarity edges
  vision_model.model.layers.11.self_attn.k_proj.weight [1408 x 1408] layer=11
    -> 5409 weight similarity edges
  vision_model.model.layers.13.self_attn.k_proj.weight [1408 x 1408] layer=13
    -> 5335 weight similarity edges
  vision_model.model.layers.14.self_attn.k_proj.weight [1408 x 1408] layer=14
    -> 4891 weight similarity edges
  vision_model.model.layers.15.self_attn.k_proj.weight [1408 x 1408] layer=15
    -> 4699 weight similarity edges
  vision_model.model.layers.16.self_attn.k_proj.weight [1408 x 1408] layer=16
    -> 4814 weight similarity edges
  language_model.model.layers.30.self_attn.k_proj.weight [1024 x 5120] layer=30
    -> 1727 weight similarity edges
  vision_model.model.layers.28.self_attn.k_proj.weight [1408 x 1408] layer=28
    -> 2943 weight similarity edges
  vision_model.model.layers.19.self_attn.k_proj.weight [1408 x 1408] layer=19
    -> 3384 weight similarity edges
  language_model.model.layers.44.self_attn.k_proj.weight [1024 x 5120] layer=44
    -> 1810 weight similarity edges
  vision_model.model.layers.21.self_attn.k_proj.weight [1408 x 1408] layer=21
    -> 2748 weight similarity edges
  language_model.model.layers.38.self_attn.k_proj.weight [1024 x 5120] layer=38
    -> 2544 weight similarity edges
  vision_model.model.layers.23.self_attn.k_proj.weight [1408 x 1408] layer=23
    -> 2577 weight similarity edges
  vision_model.model.layers.27.self_attn.k_proj.weight [1408 x 1408] layer=27
    -> 2847 weight similarity edges
  language_model.model.layers.34.self_attn.k_proj.weight [1024 x 5120] layer=34
    -> 1575 weight similarity edges
  vision_model.model.layers.8.self_attn.k_proj.weight [1408 x 1408] layer=8
    -> 6062 weight similarity edges
  language_model.model.layers.33.self_attn.k_proj.weight [1024 x 5120] layer=33
    -> 1646 weight similarity edges
  vision_model.model.layers.29.self_attn.k_proj.weight [1408 x 1408] layer=29
    -> 2626 weight similarity edges
  vision_model.model.layers.3.self_attn.k_proj.weight [1408 x 1408] layer=3
    -> 7051 weight similarity edges
  language_model.model.layers.29.self_attn.k_proj.weight [1024 x 5120] layer=29
    -> 1851 weight similarity edges
  vision_model.model.layers.30.self_attn.k_proj.weight [1408 x 1408] layer=30
    -> 2703 weight similarity edges
  language_model.model.layers.13.self_attn.k_proj.weight [1024 x 5120] layer=13
    -> 2070 weight similarity edges
  vision_model.model.layers.31.self_attn.k_proj.weight [1408 x 1408] layer=31
    -> 3485 weight similarity edges
  language_model.model.layers.39.self_attn.k_proj.weight [1024 x 5120] layer=39
    -> 406 weight similarity edges
  vision_model.model.layers.32.self_attn.k_proj.weight [1408 x 1408] layer=32
    -> 5605 weight similarity edges
  vision_model.model.layers.33.self_attn.k_proj.weight [1408 x 1408] layer=33
    -> 6698 weight similarity edges
  vision_model.model.layers.4.self_attn.k_proj.weight [1408 x 1408] layer=4
    -> 7147 weight similarity edges
  vision_model.model.layers.6.self_attn.k_proj.weight [1408 x 1408] layer=6
    -> 6771 weight similarity edges
  vision_model.model.layers.7.self_attn.k_proj.weight [1408 x 1408] layer=7
    -> 6765 weight similarity edges
  vision_model.model.layers.9.self_attn.k_proj.weight [1408 x 1408] layer=9
    -> 5874 weight similarity edges
  language_model.model.layers.32.self_attn.k_proj.weight [1024 x 5120] layer=32
    -> 1546 weight similarity edges
  language_model.model.layers.18.self_attn.k_proj.weight [1024 x 5120] layer=18
    -> 886 weight similarity edges
  language_model.model.layers.14.self_attn.k_proj.weight [1024 x 5120] layer=14
    -> 1240 weight similarity edges
  language_model.model.layers.15.self_attn.k_proj.weight [1024 x 5120] layer=15
    -> 182 weight similarity edges
  language_model.model.layers.16.self_attn.k_proj.weight [1024 x 5120] layer=16
    -> 1058 weight similarity edges
  language_model.model.layers.17.self_attn.k_proj.weight [1024 x 5120] layer=17
    -> 1465 weight similarity edges
  language_model.model.layers.21.self_attn.k_proj.weight [1024 x 5120] layer=21
    -> 1585 weight similarity edges
  language_model.model.layers.22.self_attn.k_proj.weight [1024 x 5120] layer=22
    -> 1451 weight similarity edges
  language_model.model.layers.24.self_attn.k_proj.weight [1024 x 5120] layer=24
    -> 1213 weight similarity edges
  language_model.model.layers.25.self_attn.k_proj.weight [1024 x 5120] layer=25
    -> 2081 weight similarity edges
  language_model.model.layers.27.self_attn.k_proj.weight [1024 x 5120] layer=27
    -> 242 weight similarity edges
  language_model.model.layers.31.self_attn.k_proj.weight [1024 x 5120] layer=31
    -> 292 weight similarity edges
  language_model.model.layers.41.self_attn.k_proj.weight [1024 x 5120] layer=41
    -> 2302 weight similarity edges
  language_model.model.layers.35.self_attn.k_proj.weight [1024 x 5120] layer=35
    -> 369 weight similarity edges
  language_model.model.layers.37.self_attn.k_proj.weight [1024 x 5120] layer=37
    -> 2740 weight similarity edges
  language_model.model.layers.40.self_attn.k_proj.weight [1024 x 5120] layer=40
    -> 2585 weight similarity edges
  language_model.model.layers.42.self_attn.k_proj.weight [1024 x 5120] layer=42
    -> 2872 weight similarity edges
  language_model.model.layers.43.self_attn.k_proj.weight [1024 x 5120] layer=43
    -> 566 weight similarity edges
  language_model.model.layers.45.self_attn.k_proj.weight [1024 x 5120] layer=45
    -> 3428 weight similarity edges
  language_model.model.layers.47.self_attn.k_proj.weight [1024 x 5120] layer=47
    -> 5255 weight similarity edges
[ATTN] Processing 82 v_proj tensors
  language_model.model.layers.19.self_attn.v_proj.weight [1024 x 5120] layer=19
    -> 26 weight similarity edges
  vision_model.model.layers.30.self_attn.v_proj.weight [1408 x 1408] layer=30
    -> 1 weight similarity edges
  language_model.model.layers.37.self_attn.v_proj.weight [1024 x 5120] layer=37
    -> 292 weight similarity edges
  language_model.model.layers.11.self_attn.v_proj.weight [1024 x 5120] layer=11
    -> 27 weight similarity edges
  vision_model.model.layers.17.self_attn.v_proj.weight [1408 x 1408] layer=17
    -> 119 weight similarity edges
  vision_model.model.layers.24.self_attn.v_proj.weight [1408 x 1408] layer=24
    -> 17 weight similarity edges
  language_model.model.layers.31.self_attn.v_proj.weight [1024 x 5120] layer=31
    -> 181 weight similarity edges
  language_model.model.layers.3.self_attn.v_proj.weight [1024 x 5120] layer=3
    -> 617 weight similarity edges
  language_model.model.layers.10.self_attn.v_proj.weight [1024 x 5120] layer=10
    -> 38 weight similarity edges
  language_model.model.layers.47.self_attn.v_proj.weight [1024 x 5120] layer=47
    -> 3443 weight similarity edges
  language_model.model.layers.36.self_attn.v_proj.weight [1024 x 5120] layer=36
    -> 10 weight similarity edges
  language_model.model.layers.12.self_attn.v_proj.weight [1024 x 5120] layer=12
    -> 5 weight similarity edges
  vision_model.model.layers.25.self_attn.v_proj.weight [1408 x 1408] layer=25
    -> 2 weight similarity edges
  language_model.model.layers.4.self_attn.v_proj.weight [1024 x 5120] layer=4
    -> 234 weight similarity edges
  language_model.model.layers.27.self_attn.v_proj.weight [1024 x 5120] layer=27
    -> 81 weight similarity edges
  language_model.model.layers.5.self_attn.v_proj.weight [1024 x 5120] layer=5
    -> 302 weight similarity edges
  language_model.model.layers.6.self_attn.v_proj.weight [1024 x 5120] layer=6
    -> 42 weight similarity edges
  language_model.model.layers.7.self_attn.v_proj.weight [1024 x 5120] layer=7
    -> 558 weight similarity edges
  language_model.model.layers.8.self_attn.v_proj.weight [1024 x 5120] layer=8
    -> 166 weight similarity edges
  language_model.model.layers.35.self_attn.v_proj.weight [1024 x 5120] layer=35
    -> 188 weight similarity edges
  language_model.model.layers.9.self_attn.v_proj.weight [1024 x 5120] layer=9
    -> 64 weight similarity edges
  language_model.model.layers.23.self_attn.v_proj.weight [1024 x 5120] layer=23
    -> 261 weight similarity edges
  vision_model.model.layers.23.self_attn.v_proj.weight [1408 x 1408] layer=23
    -> 4 weight similarity edges
  vision_model.model.layers.8.self_attn.v_proj.weight [1408 x 1408] layer=8
    -> 1805 weight similarity edges
  language_model.model.layers.0.self_attn.v_proj.weight [1024 x 5120] layer=0
    -> 70 weight similarity edges
  vision_model.model.layers.32.self_attn.v_proj.weight [1408 x 1408] layer=32
  language_model.model.layers.1.self_attn.v_proj.weight [1024 x 5120] layer=1
    -> 68 weight similarity edges
  language_model.model.layers.2.self_attn.v_proj.weight [1024 x 5120] layer=2
    -> 68 weight similarity edges
  language_model.model.layers.44.self_attn.v_proj.weight [1024 x 5120] layer=44
    -> 31 weight similarity edges
  language_model.model.layers.41.self_attn.v_proj.weight [1024 x 5120] layer=41
    -> 81 weight similarity edges
  vision_model.model.layers.0.self_attn.v_proj.weight [1408 x 1408] layer=0
    -> 4828 weight similarity edges
  vision_model.model.layers.15.self_attn.v_proj.weight [1408 x 1408] layer=15
    -> 195 weight similarity edges
  vision_model.model.layers.12.self_attn.v_proj.weight [1408 x 1408] layer=12
    -> 430 weight similarity edges
  language_model.model.layers.30.self_attn.v_proj.weight [1024 x 5120] layer=30
    -> 9 weight similarity edges
  vision_model.model.layers.1.self_attn.v_proj.weight [1408 x 1408] layer=1
    -> 6291 weight similarity edges
  vision_model.model.layers.10.self_attn.v_proj.weight [1408 x 1408] layer=10
    -> 1296 weight similarity edges
  vision_model.model.layers.11.self_attn.v_proj.weight [1408 x 1408] layer=11
    -> 884 weight similarity edges
  vision_model.model.layers.18.self_attn.v_proj.weight [1408 x 1408] layer=18
    -> 161 weight similarity edges
  vision_model.model.layers.13.self_attn.v_proj.weight [1408 x 1408] layer=13
    -> 630 weight similarity edges
  vision_model.model.layers.14.self_attn.v_proj.weight [1408 x 1408] layer=14
    -> 566 weight similarity edges
  language_model.model.layers.42.self_attn.v_proj.weight [1024 x 5120] layer=42
    -> 85 weight similarity edges
  vision_model.model.layers.9.self_attn.v_proj.weight [1408 x 1408] layer=9
    -> 1768 weight similarity edges
  vision_model.model.layers.16.self_attn.v_proj.weight [1408 x 1408] layer=16
    -> 388 weight similarity edges
  vision_model.model.layers.27.self_attn.v_proj.weight [1408 x 1408] layer=27
    -> 3 weight similarity edges
  vision_model.model.layers.19.self_attn.v_proj.weight [1408 x 1408] layer=19
    -> 166 weight similarity edges
  vision_model.model.layers.2.self_attn.v_proj.weight [1408 x 1408] layer=2
    -> 5186 weight similarity edges
  language_model.model.layers.29.self_attn.v_proj.weight [1024 x 5120] layer=29
    -> 4 weight similarity edges
  vision_model.model.layers.20.self_attn.v_proj.weight [1408 x 1408] layer=20
    -> 31 weight similarity edges
  vision_model.model.layers.21.self_attn.v_proj.weight [1408 x 1408] layer=21
    -> 6 weight similarity edges
  vision_model.model.layers.22.self_attn.v_proj.weight [1408 x 1408] layer=22
    -> 11 weight similarity edges
  language_model.model.layers.16.self_attn.v_proj.weight [1024 x 5120] layer=16
    -> 8 weight similarity edges
  vision_model.model.layers.26.self_attn.v_proj.weight [1408 x 1408] layer=26
    -> 28 weight similarity edges
  vision_model.model.layers.28.self_attn.v_proj.weight [1408 x 1408] layer=28
    -> 7 weight similarity edges
  vision_model.model.layers.29.self_attn.v_proj.weight [1408 x 1408] layer=29
    -> 15 weight similarity edges
  vision_model.model.layers.3.self_attn.v_proj.weight [1408 x 1408] layer=3
    -> 3849 weight similarity edges
  language_model.model.layers.17.self_attn.v_proj.weight [1024 x 5120] layer=17
    -> 1 weight similarity edges
  vision_model.model.layers.31.self_attn.v_proj.weight [1408 x 1408] layer=31
    -> 3 weight similarity edges
  vision_model.model.layers.33.self_attn.v_proj.weight [1408 x 1408] layer=33
    -> 4 weight similarity edges
  language_model.model.layers.43.self_attn.v_proj.weight [1024 x 5120] layer=43
    -> 62 weight similarity edges
  vision_model.model.layers.4.self_attn.v_proj.weight [1408 x 1408] layer=4
    -> 4049 weight similarity edges
  vision_model.model.layers.5.self_attn.v_proj.weight [1408 x 1408] layer=5
    -> 4064 weight similarity edges
  vision_model.model.layers.6.self_attn.v_proj.weight [1408 x 1408] layer=6
    -> 4084 weight similarity edges
  language_model.model.layers.45.self_attn.v_proj.weight [1024 x 5120] layer=45
    -> 486 weight similarity edges
  vision_model.model.layers.7.self_attn.v_proj.weight [1408 x 1408] layer=7
    -> 3780 weight similarity edges
  language_model.model.layers.33.self_attn.v_proj.weight [1024 x 5120] layer=33
    -> 121 weight similarity edges
  language_model.model.layers.13.self_attn.v_proj.weight [1024 x 5120] layer=13
    -> 15 weight similarity edges
  language_model.model.layers.14.self_attn.v_proj.weight [1024 x 5120] layer=14
    -> 10 weight similarity edges
  language_model.model.layers.15.self_attn.v_proj.weight [1024 x 5120] layer=15
    -> 16 weight similarity edges
  language_model.model.layers.18.self_attn.v_proj.weight [1024 x 5120] layer=18
    -> 10 weight similarity edges
  language_model.model.layers.20.self_attn.v_proj.weight [1024 x 5120] layer=20
    -> 14 weight similarity edges
  language_model.model.layers.21.self_attn.v_proj.weight [1024 x 5120] layer=21
    -> 9 weight similarity edges
  language_model.model.layers.22.self_attn.v_proj.weight [1024 x 5120] layer=22
    -> 5 weight similarity edges
  language_model.model.layers.24.self_attn.v_proj.weight [1024 x 5120] layer=24
    -> 14 weight similarity edges
  language_model.model.layers.25.self_attn.v_proj.weight [1024 x 5120] layer=25
    -> 4 weight similarity edges
  language_model.model.layers.26.self_attn.v_proj.weight [1024 x 5120] layer=26
    -> 18 weight similarity edges
  language_model.model.layers.28.self_attn.v_proj.weight [1024 x 5120] layer=28
    -> 12 weight similarity edges
  language_model.model.layers.32.self_attn.v_proj.weight [1024 x 5120] layer=32
    -> 4 weight similarity edges
  language_model.model.layers.34.self_attn.v_proj.weight [1024 x 5120] layer=34
    -> 3 weight similarity edges
  language_model.model.layers.38.self_attn.v_proj.weight [1024 x 5120] layer=38
    -> 272 weight similarity edges
  language_model.model.layers.39.self_attn.v_proj.weight [1024 x 5120] layer=39
    -> 61 weight similarity edges
  language_model.model.layers.40.self_attn.v_proj.weight [1024 x 5120] layer=40
    -> 397 weight similarity edges
  language_model.model.layers.46.self_attn.v_proj.weight [1024 x 5120] layer=46
    -> 469 weight similarity edges
[ATTN] Processing 82 o_proj tensors
  language_model.model.layers.7.self_attn.o_proj.weight [5120 x 5120] layer=7 (sampling every 2 rows)
    -> 101 weight similarity edges
  language_model.model.layers.21.self_attn.o_proj.weight [5120 x 5120] layer=21 (sampling every 2 rows)
    -> 114 weight similarity edges
  language_model.model.layers.30.self_attn.o_proj.weight [5120 x 5120] layer=30 (sampling every 2 rows)
    -> 25 weight similarity edges
  vision_model.model.layers.31.self_attn.o_proj.weight [1408 x 1408] layer=31
    -> 5 weight similarity edges
  language_model.model.layers.36.self_attn.o_proj.weight [5120 x 5120] layer=36 (sampling every 2 rows)
    -> 6 weight similarity edges
  language_model.model.layers.3.self_attn.o_proj.weight [5120 x 5120] layer=3 (sampling every 2 rows)
    -> 1816 weight similarity edges
  language_model.model.layers.10.self_attn.o_proj.weight [5120 x 5120] layer=10 (sampling every 2 rows)
    -> 98 weight similarity edges
  language_model.model.layers.5.self_attn.o_proj.weight [5120 x 5120] layer=5 (sampling every 2 rows)
    -> 96 weight similarity edges
  language_model.model.layers.13.self_attn.o_proj.weight [5120 x 5120] layer=13 (sampling every 2 rows)
    -> 119 weight similarity edges
  language_model.model.layers.11.self_attn.o_proj.weight [5120 x 5120] layer=11 (sampling every 2 rows)
    -> 77 weight similarity edges
  language_model.model.layers.4.self_attn.o_proj.weight [5120 x 5120] layer=4 (sampling every 2 rows)
    -> 111 weight similarity edges
  vision_model.model.layers.11.self_attn.o_proj.weight [1408 x 1408] layer=11
    -> 110 weight similarity edges
  vision_model.model.layers.24.self_attn.o_proj.weight [1408 x 1408] layer=24
    -> 10 weight similarity edges
  language_model.model.layers.6.self_attn.o_proj.weight [5120 x 5120] layer=6 (sampling every 2 rows)
    -> 45 weight similarity edges
  language_model.model.layers.46.self_attn.o_proj.weight [5120 x 5120] layer=46 (sampling every 2 rows)
    -> 28 weight similarity edges
  vision_model.model.layers.18.self_attn.o_proj.weight [1408 x 1408] layer=18
    -> 12 weight similarity edges
  vision_model.model.layers.26.self_attn.o_proj.weight [1408 x 1408] layer=26
    -> 13 weight similarity edges
  language_model.model.layers.8.self_attn.o_proj.weight [5120 x 5120] layer=8 (sampling every 2 rows)
    -> 72 weight similarity edges
  vision_model.model.layers.13.self_attn.o_proj.weight [1408 x 1408] layer=13
    -> 70 weight similarity edges
  language_model.model.layers.9.self_attn.o_proj.weight [5120 x 5120] layer=9 (sampling every 2 rows)
    -> 147 weight similarity edges
  language_model.model.layers.17.self_attn.o_proj.weight [5120 x 5120] layer=17 (sampling every 2 rows)
    -> 111 weight similarity edges
  language_model.model.layers.2.self_attn.o_proj.weight [5120 x 5120] layer=2 (sampling every 2 rows)
    -> 262 weight similarity edges
  language_model.model.layers.0.self_attn.o_proj.weight [5120 x 5120] layer=0 (sampling every 2 rows)
    -> 447 weight similarity edges
  language_model.model.layers.37.self_attn.o_proj.weight [5120 x 5120] layer=37 (sampling every 2 rows)
    -> 28 weight similarity edges
  language_model.model.layers.1.self_attn.o_proj.weight [5120 x 5120] layer=1 (sampling every 2 rows)
    -> 115 weight similarity edges
  vision_model.model.layers.23.self_attn.o_proj.weight [1408 x 1408] layer=23
    -> 13 weight similarity edges
  vision_model.model.layers.0.self_attn.o_proj.weight [1408 x 1408] layer=0
    -> 4907 weight similarity edges
  vision_model.model.layers.1.self_attn.o_proj.weight [1408 x 1408] layer=1
    -> 3598 weight similarity edges
  vision_model.model.layers.10.self_attn.o_proj.weight [1408 x 1408] layer=10
    -> 108 weight similarity edges
  vision_model.model.layers.12.self_attn.o_proj.weight [1408 x 1408] layer=12
    -> 73 weight similarity edges
  language_model.model.layers.20.self_attn.o_proj.weight [5120 x 5120] layer=20 (sampling every 2 rows)
    -> 86 weight similarity edges
  vision_model.model.layers.14.self_attn.o_proj.weight [1408 x 1408] layer=14
    -> 101 weight similarity edges
  vision_model.model.layers.9.self_attn.o_proj.weight [1408 x 1408] layer=9
    -> 135 weight similarity edges
  vision_model.model.layers.15.self_attn.o_proj.weight [1408 x 1408] layer=15
    -> 33 weight similarity edges
  vision_model.model.layers.16.self_attn.o_proj.weight [1408 x 1408] layer=16
    -> 40 weight similarity edges
  vision_model.model.layers.17.self_attn.o_proj.weight [1408 x 1408] layer=17
    -> 29 weight similarity edges
  language_model.model.layers.47.self_attn.o_proj.weight [5120 x 5120] layer=47 (sampling every 2 rows)
    -> 10264 weight similarity edges
  vision_model.model.layers.27.self_attn.o_proj.weight [1408 x 1408] layer=27
    -> 8 weight similarity edges
  language_model.model.layers.44.self_attn.o_proj.weight [5120 x 5120] layer=44 (sampling every 2 rows)
    -> 30 weight similarity edges
  vision_model.model.layers.19.self_attn.o_proj.weight [1408 x 1408] layer=19
    -> 17 weight similarity edges
  vision_model.model.layers.20.self_attn.o_proj.weight [1408 x 1408] layer=20
    -> 13 weight similarity edges
  language_model.model.layers.39.self_attn.o_proj.weight [5120 x 5120] layer=39 (sampling every 2 rows)
    -> 27 weight similarity edges
  vision_model.model.layers.2.self_attn.o_proj.weight [1408 x 1408] layer=2
    -> 2080 weight similarity edges
  vision_model.model.layers.22.self_attn.o_proj.weight [1408 x 1408] layer=22
    -> 10 weight similarity edges
  vision_model.model.layers.7.self_attn.o_proj.weight [1408 x 1408] layer=7
    -> 297 weight similarity edges
  language_model.model.layers.38.self_attn.o_proj.weight [5120 x 5120] layer=38 (sampling every 2 rows)
    -> 27 weight similarity edges
  vision_model.model.layers.21.self_attn.o_proj.weight [1408 x 1408] layer=21
    -> 12 weight similarity edges
  language_model.model.layers.24.self_attn.o_proj.weight [5120 x 5120] layer=24 (sampling every 2 rows)
    -> 48 weight similarity edges
  vision_model.model.layers.25.self_attn.o_proj.weight [1408 x 1408] layer=25
    -> 11 weight similarity edges
  language_model.model.layers.33.self_attn.o_proj.weight [5120 x 5120] layer=33 (sampling every 2 rows)
    -> 37 weight similarity edges
  vision_model.model.layers.28.self_attn.o_proj.weight [1408 x 1408] layer=28
    -> 4 weight similarity edges
  vision_model.model.layers.32.self_attn.o_proj.weight [1408 x 1408] layer=32
    -> 10 weight similarity edges
  vision_model.model.layers.29.self_attn.o_proj.weight [1408 x 1408] layer=29
    -> 2 weight similarity edges
  vision_model.model.layers.3.self_attn.o_proj.weight [1408 x 1408] layer=3
    -> 1382 weight similarity edges
  vision_model.model.layers.30.self_attn.o_proj.weight [1408 x 1408] layer=30
    -> 3 weight similarity edges
  language_model.model.layers.41.self_attn.o_proj.weight [5120 x 5120] layer=41 (sampling every 2 rows)
    -> 18 weight similarity edges
  vision_model.model.layers.33.self_attn.o_proj.weight [1408 x 1408] layer=33
    -> 3 weight similarity edges
  vision_model.model.layers.4.self_attn.o_proj.weight [1408 x 1408] layer=4
    -> 691 weight similarity edges
  language_model.model.layers.43.self_attn.o_proj.weight [5120 x 5120] layer=43 (sampling every 2 rows)
    -> 65 weight similarity edges
  vision_model.model.layers.5.self_attn.o_proj.weight [1408 x 1408] layer=5
    -> 896 weight similarity edges
  vision_model.model.layers.6.self_attn.o_proj.weight [1408 x 1408] layer=6
    -> 645 weight similarity edges
  vision_model.model.layers.8.self_attn.o_proj.weight [1408 x 1408] layer=8
    -> 168 weight similarity edges
  language_model.model.layers.12.self_attn.o_proj.weight [5120 x 5120] layer=12 (sampling every 2 rows)
    -> 72 weight similarity edges
  language_model.model.layers.14.self_attn.o_proj.weight [5120 x 5120] layer=14 (sampling every 2 rows)
    -> 110 weight similarity edges
  language_model.model.layers.15.self_attn.o_proj.weight [5120 x 5120] layer=15 (sampling every 2 rows)
    -> 148 weight similarity edges
  language_model.model.layers.16.self_attn.o_proj.weight [5120 x 5120] layer=16 (sampling every 2 rows)
    -> 85 weight similarity edges
  language_model.model.layers.27.self_attn.o_proj.weight [5120 x 5120] layer=27 (sampling every 2 rows)
    -> 142 weight similarity edges
  language_model.model.layers.18.self_attn.o_proj.weight [5120 x 5120] layer=18 (sampling every 2 rows)
    -> 103 weight similarity edges
  language_model.model.layers.19.self_attn.o_proj.weight [5120 x 5120] layer=19 (sampling every 2 rows)
    -> 127 weight similarity edges
  language_model.model.layers.40.self_attn.o_proj.weight [5120 x 5120] layer=40 (sampling every 2 rows)
    -> 21 weight similarity edges
  language_model.model.layers.22.self_attn.o_proj.weight [5120 x 5120] layer=22 (sampling every 2 rows)
    -> 77 weight similarity edges
  language_model.model.layers.23.self_attn.o_proj.weight [5120 x 5120] layer=23 (sampling every 2 rows)
    -> 152 weight similarity edges
  language_model.model.layers.25.self_attn.o_proj.weight [5120 x 5120] layer=25 (sampling every 2 rows)
    -> 73 weight similarity edges
  language_model.model.layers.31.self_attn.o_proj.weight [5120 x 5120] layer=31 (sampling every 2 rows)
    -> 45 weight similarity edges
  language_model.model.layers.26.self_attn.o_proj.weight [5120 x 5120] layer=26 (sampling every 2 rows)
    -> 48 weight similarity edges
  language_model.model.layers.28.self_attn.o_proj.weight [5120 x 5120] layer=28 (sampling every 2 rows)
    -> 8 weight similarity edges
  language_model.model.layers.29.self_attn.o_proj.weight [5120 x 5120] layer=29 (sampling every 2 rows)
    -> 39 weight similarity edges
  language_model.model.layers.32.self_attn.o_proj.weight [5120 x 5120] layer=32 (sampling every 2 rows)
    -> 8 weight similarity edges
  language_model.model.layers.34.self_attn.o_proj.weight [5120 x 5120] layer=34 (sampling every 2 rows)
    -> 17 weight similarity edges
  language_model.model.layers.35.self_attn.o_proj.weight [5120 x 5120] layer=35 (sampling every 2 rows)
    -> 10 weight similarity edges
  language_model.model.layers.42.self_attn.o_proj.weight [5120 x 5120] layer=42 (sampling every 2 rows)
    -> 13 weight similarity edges
  language_model.model.layers.45.self_attn.o_proj.weight [5120 x 5120] layer=45 (sampling every 2 rows)
    -> 46 weight similarity edges
[ATTN] Processing 48 gate_proj tensors
  language_model.model.layers.10.feed_forward.gate_proj.weight [16384 x 5120] layer=10 (sampling every 8 rows)
    -> 579 weight similarity edges
  language_model.model.layers.6.feed_forward.gate_proj.weight [16384 x 5120] layer=6 (sampling every 8 rows)
    -> 796 weight similarity edges
  language_model.model.layers.2.feed_forward.gate_proj.weight [16384 x 5120] layer=2 (sampling every 8 rows)
    -> 975 weight similarity edges
  language_model.model.layers.32.feed_forward.gate_proj.weight [16384 x 5120] layer=32 (sampling every 8 rows)
    -> 1743 weight similarity edges
  language_model.model.layers.47.feed_forward.shared_expert.gate_proj.weight [8192 x 5120] layer=47 (sampling every 4 rows)
    -> 7411 weight similarity edges
  language_model.model.layers.11.feed_forward.shared_expert.gate_proj.weight [8192 x 5120] layer=11 (sampling every 4 rows)
    -> 1762 weight similarity edges
  language_model.model.layers.4.feed_forward.gate_proj.weight [16384 x 5120] layer=4 (sampling every 8 rows)
    -> 926 weight similarity edges
  language_model.model.layers.3.feed_forward.shared_expert.gate_proj.weight [8192 x 5120] layer=3 (sampling every 4 rows)
    -> 1007 weight similarity edges
  language_model.model.layers.35.feed_forward.shared_expert.gate_proj.weight [8192 x 5120] layer=35 (sampling every 4 rows)
    -> 10006 weight similarity edges
  language_model.model.layers.39.feed_forward.shared_expert.gate_proj.weight [8192 x 5120] layer=39 (sampling every 4 rows)
    -> 9576 weight similarity edges
  language_model.model.layers.5.feed_forward.shared_expert.gate_proj.weight [8192 x 5120] layer=5 (sampling every 4 rows)
    -> 875 weight similarity edges
  language_model.model.layers.43.feed_forward.shared_expert.gate_proj.weight [8192 x 5120] layer=43 (sampling every 4 rows)
    -> 9792 weight similarity edges
  language_model.model.layers.7.feed_forward.shared_expert.gate_proj.weight [8192 x 5120] layer=7 (sampling every 4 rows)
    -> 1191 weight similarity edges
  language_model.model.layers.14.feed_forward.gate_proj.weight [16384 x 5120] layer=14 (sampling every 8 rows)
    -> 670 weight similarity edges
  language_model.model.layers.9.feed_forward.shared_expert.gate_proj.weight [8192 x 5120] layer=9 (sampling every 4 rows)
    -> 1314 weight similarity edges
  language_model.model.layers.8.feed_forward.gate_proj.weight [16384 x 5120] layer=8 (sampling every 8 rows)
    -> 769 weight similarity edges
  language_model.model.layers.34.feed_forward.gate_proj.weight [16384 x 5120] layer=34 (sampling every 8 rows)
    -> 1888 weight similarity edges
  language_model.model.layers.0.feed_forward.gate_proj.weight [16384 x 5120] layer=0 (sampling every 8 rows)
    -> 1261 weight similarity edges
  language_model.model.layers.1.feed_forward.shared_expert.gate_proj.weight [8192 x 5120] layer=1 (sampling every 4 rows)
    -> 1065 weight similarity edges
  language_model.model.layers.13.feed_forward.shared_expert.gate_proj.weight [8192 x 5120] layer=13 (sampling every 4 rows)
    -> 2016 weight similarity edges
  language_model.model.layers.42.feed_forward.gate_proj.weight [16384 x 5120] layer=42 (sampling every 8 rows)
    -> 2462 weight similarity edges
  language_model.model.layers.33.feed_forward.shared_expert.gate_proj.weight [8192 x 5120] layer=33 (sampling every 4 rows)
    -> 9072 weight similarity edges
  language_model.model.layers.40.feed_forward.gate_proj.weight [16384 x 5120] layer=40 (sampling every 8 rows)
    -> 2280 weight similarity edges
  language_model.model.layers.29.feed_forward.shared_expert.gate_proj.weight [8192 x 5120] layer=29 (sampling every 4 rows)
    -> 7893 weight similarity edges
  language_model.model.layers.44.feed_forward.gate_proj.weight [16384 x 5120] layer=44 (sampling every 8 rows)
    -> 2776 weight similarity edges
  language_model.model.layers.27.feed_forward.shared_expert.gate_proj.weight [8192 x 5120] layer=27 (sampling every 4 rows)
    -> 8775 weight similarity edges
  language_model.model.layers.26.feed_forward.gate_proj.weight [16384 x 5120] layer=26 (sampling every 8 rows)
    -> 1519 weight similarity edges
  language_model.model.layers.30.feed_forward.gate_proj.weight [16384 x 5120] layer=30 (sampling every 8 rows)
    -> 1496 weight similarity edges
  language_model.model.layers.12.feed_forward.gate_proj.weight [16384 x 5120] layer=12 (sampling every 8 rows)
    -> 858 weight similarity edges
  language_model.model.layers.15.feed_forward.shared_expert.gate_proj.weight [8192 x 5120] layer=15 (sampling every 4 rows)
    -> 4838 weight similarity edges
  language_model.model.layers.28.feed_forward.gate_proj.weight [16384 x 5120] layer=28 (sampling every 8 rows)
    -> 1722 weight similarity edges
  language_model.model.layers.16.feed_forward.gate_proj.weight [16384 x 5120] layer=16 (sampling every 8 rows)
    -> 984 weight similarity edges
  language_model.model.layers.36.feed_forward.gate_proj.weight [16384 x 5120] layer=36 (sampling every 8 rows)
    -> 1650 weight similarity edges
  language_model.model.layers.17.feed_forward.shared_expert.gate_proj.weight [8192 x 5120] layer=17 (sampling every 4 rows)
    -> 6038 weight similarity edges
  language_model.model.layers.18.feed_forward.gate_proj.weight [16384 x 5120] layer=18 (sampling every 8 rows)
    -> 1011 weight similarity edges
  language_model.model.layers.19.feed_forward.shared_expert.gate_proj.weight [8192 x 5120] layer=19 (sampling every 4 rows)
    -> 6159 weight similarity edges
  language_model.model.layers.20.feed_forward.gate_proj.weight [16384 x 5120] layer=20 (sampling every 8 rows)
    -> 1343 weight similarity edges
  language_model.model.layers.21.feed_forward.shared_expert.gate_proj.weight [8192 x 5120] layer=21 (sampling every 4 rows)
    -> 6483 weight similarity edges
  language_model.model.layers.22.feed_forward.gate_proj.weight [16384 x 5120] layer=22 (sampling every 8 rows)
    -> 1523 weight similarity edges
  language_model.model.layers.23.feed_forward.shared_expert.gate_proj.weight [8192 x 5120] layer=23 (sampling every 4 rows)
    -> 7526 weight similarity edges
  language_model.model.layers.24.feed_forward.gate_proj.weight [16384 x 5120] layer=24 (sampling every 8 rows)
    -> 1470 weight similarity edges
  language_model.model.layers.25.feed_forward.shared_expert.gate_proj.weight [8192 x 5120] layer=25 (sampling every 4 rows)
    -> 7847 weight similarity edges
  language_model.model.layers.37.feed_forward.shared_expert.gate_proj.weight [8192 x 5120] layer=37 (sampling every 4 rows)
    -> 9366 weight similarity edges
  language_model.model.layers.31.feed_forward.shared_expert.gate_proj.weight [8192 x 5120] layer=31 (sampling every 4 rows)
    -> 9081 weight similarity edges
  language_model.model.layers.38.feed_forward.gate_proj.weight [16384 x 5120] layer=38 (sampling every 8 rows)
    -> 1824 weight similarity edges
  language_model.model.layers.41.feed_forward.shared_expert.gate_proj.weight [8192 x 5120] layer=41 (sampling every 4 rows)
    -> 9916 weight similarity edges
  language_model.model.layers.45.feed_forward.shared_expert.gate_proj.weight [8192 x 5120] layer=45 (sampling every 4 rows)
    -> 7839 weight similarity edges
  language_model.model.layers.46.feed_forward.gate_proj.weight [16384 x 5120] layer=46 (sampling every 8 rows)
    -> 2577 weight similarity edges
[ATTN] Processing 48 up_proj tensors
  language_model.model.layers.41.feed_forward.shared_expert.up_proj.weight [8192 x 5120] layer=41 (sampling every 4 rows)
    -> 1826 weight similarity edges
  language_model.model.layers.38.feed_forward.up_proj.weight [16384 x 5120] layer=38 (sampling every 8 rows)
    -> 431 weight similarity edges
  language_model.model.layers.10.feed_forward.up_proj.weight [16384 x 5120] layer=10 (sampling every 8 rows)
    -> 228 weight similarity edges
  language_model.model.layers.5.feed_forward.shared_expert.up_proj.weight [8192 x 5120] layer=5 (sampling every 4 rows)
    -> 182 weight similarity edges
  language_model.model.layers.11.feed_forward.shared_expert.up_proj.weight [8192 x 5120] layer=11 (sampling every 4 rows)
    -> 124 weight similarity edges
  language_model.model.layers.37.feed_forward.shared_expert.up_proj.weight [8192 x 5120] layer=37 (sampling every 4 rows)
    -> 626 weight similarity edges
  language_model.model.layers.2.feed_forward.up_proj.weight [16384 x 5120] layer=2 (sampling every 8 rows)
    -> 273 weight similarity edges
  language_model.model.layers.3.feed_forward.shared_expert.up_proj.weight [8192 x 5120] layer=3 (sampling every 4 rows)
    -> 139 weight similarity edges
  language_model.model.layers.4.feed_forward.up_proj.weight [16384 x 5120] layer=4 (sampling every 8 rows)
    -> 138 weight similarity edges
  language_model.model.layers.46.feed_forward.up_proj.weight [16384 x 5120] layer=46 (sampling every 8 rows)
    -> 5077 weight similarity edges
  language_model.model.layers.32.feed_forward.up_proj.weight [16384 x 5120] layer=32 (sampling every 8 rows)
    -> 459 weight similarity edges
  language_model.model.layers.6.feed_forward.up_proj.weight [16384 x 5120] layer=6 (sampling every 8 rows)
    -> 161 weight similarity edges
  language_model.model.layers.7.feed_forward.shared_expert.up_proj.weight [8192 x 5120] layer=7 (sampling every 4 rows)
    -> 182 weight similarity edges
  language_model.model.layers.14.feed_forward.up_proj.weight [16384 x 5120] layer=14 (sampling every 8 rows)
    -> 223 weight similarity edges
  language_model.model.layers.8.feed_forward.up_proj.weight [16384 x 5120] layer=8 (sampling every 8 rows)
    -> 225 weight similarity edges
  language_model.model.layers.19.feed_forward.shared_expert.up_proj.weight [8192 x 5120] layer=19 (sampling every 4 rows)
    -> 804 weight similarity edges
  language_model.model.layers.9.feed_forward.shared_expert.up_proj.weight [8192 x 5120] layer=9 (sampling every 4 rows)
    -> 151 weight similarity edges
  language_model.model.layers.0.feed_forward.up_proj.weight [16384 x 5120] layer=0 (sampling every 8 rows)
    -> 263 weight similarity edges
  language_model.model.layers.1.feed_forward.shared_expert.up_proj.weight [8192 x 5120] layer=1 (sampling every 4 rows)
    -> 334 weight similarity edges
  language_model.model.layers.13.feed_forward.shared_expert.up_proj.weight [8192 x 5120] layer=13 (sampling every 4 rows)
    -> 129 weight similarity edges
  language_model.model.layers.26.feed_forward.up_proj.weight [16384 x 5120] layer=26 (sampling every 8 rows)
    -> 297 weight similarity edges
  language_model.model.layers.25.feed_forward.shared_expert.up_proj.weight [8192 x 5120] layer=25 (sampling every 4 rows)
    -> 650 weight similarity edges
  language_model.model.layers.27.feed_forward.shared_expert.up_proj.weight [8192 x 5120] layer=27 (sampling every 4 rows)
    -> 771 weight similarity edges
  language_model.model.layers.36.feed_forward.up_proj.weight [16384 x 5120] layer=36 (sampling every 8 rows)
    -> 471 weight similarity edges
  language_model.model.layers.31.feed_forward.shared_expert.up_proj.weight [8192 x 5120] layer=31 (sampling every 4 rows)
    -> 839 weight similarity edges
  language_model.model.layers.43.feed_forward.shared_expert.up_proj.weight [8192 x 5120] layer=43 (sampling every 4 rows)
    -> 2380 weight similarity edges
  language_model.model.layers.12.feed_forward.up_proj.weight [16384 x 5120] layer=12 (sampling every 8 rows)
    -> 151 weight similarity edges
  language_model.model.layers.28.feed_forward.up_proj.weight [16384 x 5120] layer=28 (sampling every 8 rows)
    -> 403 weight similarity edges
  language_model.model.layers.15.feed_forward.shared_expert.up_proj.weight [8192 x 5120] layer=15 (sampling every 4 rows)
    -> 174 weight similarity edges
  language_model.model.layers.16.feed_forward.up_proj.weight [16384 x 5120] layer=16 (sampling every 8 rows)
    -> 303 weight similarity edges
  language_model.model.layers.17.feed_forward.shared_expert.up_proj.weight [8192 x 5120] layer=17 (sampling every 4 rows)
    -> 291 weight similarity edges
  language_model.model.layers.18.feed_forward.up_proj.weight [16384 x 5120] layer=18 (sampling every 8 rows)
    -> 245 weight similarity edges
  language_model.model.layers.20.feed_forward.up_proj.weight [16384 x 5120] layer=20 (sampling every 8 rows)
    -> 460 weight similarity edges
  language_model.model.layers.21.feed_forward.shared_expert.up_proj.weight [8192 x 5120] layer=21 (sampling every 4 rows)
    -> 479 weight similarity edges
  language_model.model.layers.22.feed_forward.up_proj.weight [16384 x 5120] layer=22 (sampling every 8 rows)
    -> 354 weight similarity edges
  language_model.model.layers.23.feed_forward.shared_expert.up_proj.weight [8192 x 5120] layer=23 (sampling every 4 rows)
    -> 844 weight similarity edges
  language_model.model.layers.24.feed_forward.up_proj.weight [16384 x 5120] layer=24 (sampling every 8 rows)
    -> 491 weight similarity edges
  language_model.model.layers.30.feed_forward.up_proj.weight [16384 x 5120] layer=30 (sampling every 8 rows)
    -> 390 weight similarity edges
  language_model.model.layers.33.feed_forward.shared_expert.up_proj.weight [8192 x 5120] layer=33 (sampling every 4 rows)
    -> 752 weight similarity edges
  language_model.model.layers.29.feed_forward.shared_expert.up_proj.weight [8192 x 5120] layer=29 (sampling every 4 rows)
    -> 682 weight similarity edges
  language_model.model.layers.34.feed_forward.up_proj.weight [16384 x 5120] layer=34 (sampling every 8 rows)
    -> 545 weight similarity edges
  language_model.model.layers.35.feed_forward.shared_expert.up_proj.weight [8192 x 5120] layer=35 (sampling every 4 rows)
    -> 865 weight similarity edges
  language_model.model.layers.39.feed_forward.shared_expert.up_proj.weight [8192 x 5120] layer=39 (sampling every 4 rows)
    -> 1161 weight similarity edges
  language_model.model.layers.40.feed_forward.up_proj.weight [16384 x 5120] layer=40 (sampling every 8 rows)
    -> 661 weight similarity edges
  language_model.model.layers.42.feed_forward.up_proj.weight [16384 x 5120] layer=42 (sampling every 8 rows)
    -> 1046 weight similarity edges
  language_model.model.layers.44.feed_forward.up_proj.weight [16384 x 5120] layer=44 (sampling every 8 rows)
    -> 1514 weight similarity edges
  language_model.model.layers.45.feed_forward.shared_expert.up_proj.weight [8192 x 5120] layer=45 (sampling every 4 rows)
    -> 4096 weight similarity edges
  language_model.model.layers.47.feed_forward.shared_expert.up_proj.weight [8192 x 5120] layer=47 (sampling every 4 rows)
    -> 8755 weight similarity edges
[ATTN] Processing 48 down_proj tensors
  language_model.model.layers.6.feed_forward.down_proj.weight [5120 x 16384] layer=6 (sampling every 2 rows)
    -> 23 weight similarity edges
  language_model.model.layers.10.feed_forward.down_proj.weight [5120 x 16384] layer=10 (sampling every 2 rows)
    -> 21 weight similarity edges
  language_model.model.layers.2.feed_forward.down_proj.weight [5120 x 16384] layer=2 (sampling every 2 rows)
    -> 83 weight similarity edges
  language_model.model.layers.43.feed_forward.shared_expert.down_proj.weight [5120 x 8192] layer=43 (sampling every 2 rows)
    -> 26 weight similarity edges
  language_model.model.layers.11.feed_forward.shared_expert.down_proj.weight [5120 x 8192] layer=11 (sampling every 2 rows)
    -> 38 weight similarity edges
  language_model.model.layers.3.feed_forward.shared_expert.down_proj.weight [5120 x 8192] layer=3 (sampling every 2 rows)
    -> 35 weight similarity edges
  language_model.model.layers.4.feed_forward.down_proj.weight [5120 x 16384] layer=4 (sampling every 2 rows)
    -> 23 weight similarity edges
  language_model.model.layers.5.feed_forward.shared_expert.down_proj.weight [5120 x 8192] layer=5 (sampling every 2 rows)
    -> 41 weight similarity edges
  language_model.model.layers.7.feed_forward.shared_expert.down_proj.weight [5120 x 8192] layer=7 (sampling every 2 rows)
    -> 24 weight similarity edges
  language_model.model.layers.8.feed_forward.down_proj.weight [5120 x 16384] layer=8 (sampling every 2 rows)
    -> 22 weight similarity edges
  language_model.model.layers.36.feed_forward.down_proj.weight [5120 x 16384] layer=36 (sampling every 2 rows)
    -> 1 weight similarity edges
  language_model.model.layers.31.feed_forward.shared_expert.down_proj.weight [5120 x 8192] layer=31 (sampling every 2 rows)
    -> 8 weight similarity edges
  language_model.model.layers.9.feed_forward.shared_expert.down_proj.weight [5120 x 8192] layer=9 (sampling every 2 rows)
    -> 31 weight similarity edges
  language_model.model.layers.0.feed_forward.down_proj.weight [5120 x 16384] layer=0 (sampling every 2 rows)
    -> 103 weight similarity edges
  language_model.model.layers.1.feed_forward.shared_expert.down_proj.weight [5120 x 8192] layer=1 (sampling every 2 rows)
    -> 77 weight similarity edges
  language_model.model.layers.45.feed_forward.shared_expert.down_proj.weight [5120 x 8192] layer=45 (sampling every 2 rows)
    -> 99 weight similarity edges
  language_model.model.layers.39.feed_forward.shared_expert.down_proj.weight [5120 x 8192] layer=39 (sampling every 2 rows)
    -> 9 weight similarity edges
  language_model.model.layers.16.feed_forward.down_proj.weight [5120 x 16384] layer=16 (sampling every 2 rows)
    -> 20 weight similarity edges
  language_model.model.layers.17.feed_forward.shared_expert.down_proj.weight [5120 x 8192] layer=17 (sampling every 2 rows)
    -> 155 weight similarity edges
  language_model.model.layers.20.feed_forward.down_proj.weight [5120 x 16384] layer=20 (sampling every 2 rows)
    -> 37 weight similarity edges
  language_model.model.layers.14.feed_forward.down_proj.weight [5120 x 16384] layer=14 (sampling every 2 rows)
    -> 38 weight similarity edges
  language_model.model.layers.19.feed_forward.shared_expert.down_proj.weight [5120 x 8192] layer=19 (sampling every 2 rows)
    -> 133 weight similarity edges
  language_model.model.layers.24.feed_forward.down_proj.weight [5120 x 16384] layer=24 (sampling every 2 rows)
    -> 8 weight similarity edges
  language_model.model.layers.23.feed_forward.shared_expert.down_proj.weight [5120 x 8192] layer=23 (sampling every 2 rows)
    -> 66 weight similarity edges
  language_model.model.layers.34.feed_forward.down_proj.weight [5120 x 16384] layer=34 (sampling every 2 rows)
    -> 6 weight similarity edges
  language_model.model.layers.44.feed_forward.down_proj.weight [5120 x 16384] layer=44 (sampling every 2 rows)
    -> 25 weight similarity edges
  language_model.model.layers.12.feed_forward.down_proj.weight [5120 x 16384] layer=12 (sampling every 2 rows)
    -> 21 weight similarity edges
  language_model.model.layers.13.feed_forward.shared_expert.down_proj.weight [5120 x 8192] layer=13 (sampling every 2 rows)
    -> 86 weight similarity edges
  language_model.model.layers.15.feed_forward.shared_expert.down_proj.weight [5120 x 8192] layer=15 (sampling every 2 rows)
    -> 83 weight similarity edges
  language_model.model.layers.26.feed_forward.down_proj.weight [5120 x 16384] layer=26 (sampling every 2 rows)
    -> 8 weight similarity edges
  language_model.model.layers.18.feed_forward.down_proj.weight [5120 x 16384] layer=18 (sampling every 2 rows)
    -> 46 weight similarity edges
  language_model.model.layers.32.feed_forward.down_proj.weight [5120 x 16384] layer=32 (sampling every 2 rows)
    -> 3 weight similarity edges
  language_model.model.layers.21.feed_forward.shared_expert.down_proj.weight [5120 x 8192] layer=21 (sampling every 2 rows)
    -> 126 weight similarity edges
  language_model.model.layers.22.feed_forward.down_proj.weight [5120 x 16384] layer=22 (sampling every 2 rows)
    -> 21 weight similarity edges
  language_model.model.layers.38.feed_forward.down_proj.weight [5120 x 16384] layer=38 (sampling every 2 rows)
  language_model.model.layers.25.feed_forward.shared_expert.down_proj.weight [5120 x 8192] layer=25 (sampling every 2 rows)
    -> 44 weight similarity edges
  language_model.model.layers.27.feed_forward.shared_expert.down_proj.weight [5120 x 8192] layer=27 (sampling every 2 rows)
    -> 31 weight similarity edges
  language_model.model.layers.28.feed_forward.down_proj.weight [5120 x 16384] layer=28 (sampling every 2 rows)
    -> 5 weight similarity edges
  language_model.model.layers.29.feed_forward.shared_expert.down_proj.weight [5120 x 8192] layer=29 (sampling every 2 rows)
    -> 23 weight similarity edges
  language_model.model.layers.30.feed_forward.down_proj.weight [5120 x 16384] layer=30 (sampling every 2 rows)
    -> 2 weight similarity edges
  language_model.model.layers.37.feed_forward.shared_expert.down_proj.weight [5120 x 8192] layer=37 (sampling every 2 rows)
    -> 5 weight similarity edges
  language_model.model.layers.33.feed_forward.shared_expert.down_proj.weight [5120 x 8192] layer=33 (sampling every 2 rows)
    -> 18 weight similarity edges
  language_model.model.layers.35.feed_forward.shared_expert.down_proj.weight [5120 x 8192] layer=35 (sampling every 2 rows)
    -> 4 weight similarity edges
  language_model.model.layers.40.feed_forward.down_proj.weight [5120 x 16384] layer=40 (sampling every 2 rows)
    -> 2 weight similarity edges
  language_model.model.layers.41.feed_forward.shared_expert.down_proj.weight [5120 x 8192] layer=41 (sampling every 2 rows)
    -> 6 weight similarity edges
  language_model.model.layers.42.feed_forward.down_proj.weight [5120 x 16384] layer=42 (sampling every 2 rows)
    -> 4 weight similarity edges
  language_model.model.layers.46.feed_forward.down_proj.weight [5120 x 16384] layer=46 (sampling every 2 rows)
    -> 85 weight similarity edges
  language_model.model.layers.47.feed_forward.shared_expert.down_proj.weight [5120 x 8192] layer=47 (sampling every 2 rows)
    -> 3801 weight similarity edges
[ATTN] Processing 35 fc1 tensors
  vision_model.model.layers.10.mlp.fc1.weight [5632 x 1408] layer=10 (sampling every 2 rows)
    -> 8610 weight similarity edges
  vision_model.model.layers.14.mlp.fc1.weight [5632 x 1408] layer=14 (sampling every 2 rows)
    -> 6860 weight similarity edges
  vision_model.model.layers.13.mlp.fc1.weight [5632 x 1408] layer=13 (sampling every 2 rows)
    -> 7009 weight similarity edges
  vision_model.model.layers.6.mlp.fc1.weight [5632 x 1408] layer=6 (sampling every 2 rows)
    -> 13086 weight similarity edges
  vision_model.model.layers.31.mlp.fc1.weight [5632 x 1408] layer=31 (sampling every 2 rows)
    -> 1403 weight similarity edges
  vision_model.model.layers.15.mlp.fc1.weight [5632 x 1408] layer=15 (sampling every 2 rows)
    -> 5987 weight similarity edges
  vision_model.model.layers.24.mlp.fc1.weight [5632 x 1408] layer=24 (sampling every 2 rows)
    -> 517 weight similarity edges
  vision_model.model.layers.3.mlp.fc1.weight [5632 x 1408] layer=3 (sampling every 2 rows)
    -> 14088 weight similarity edges
  vision_model.model.layers.26.mlp.fc1.weight [5632 x 1408] layer=26 (sampling every 2 rows)
    -> 693 weight similarity edges
  vision_model.model.layers.0.mlp.fc1.weight [5632 x 1408] layer=0 (sampling every 2 rows)
    -> 14047 weight similarity edges
  vision_model.model.layers.1.mlp.fc1.weight [5632 x 1408] layer=1 (sampling every 2 rows)
    -> 13853 weight similarity edges
  vision_model.model.layers.29.mlp.fc1.weight [5632 x 1408] layer=29 (sampling every 2 rows)
    -> 1387 weight similarity edges
  vision_model.model.layers.11.mlp.fc1.weight [5632 x 1408] layer=11 (sampling every 2 rows)
    -> 7588 weight similarity edges
  vision_model.model.layers.12.mlp.fc1.weight [5632 x 1408] layer=12 (sampling every 2 rows)
    -> 6866 weight similarity edges
  vision_model.model.layers.27.mlp.fc1.weight [5632 x 1408] layer=27 (sampling every 2 rows)
    -> 798 weight similarity edges
  vision_model.model.layers.19.mlp.fc1.weight [5632 x 1408] layer=19 (sampling every 2 rows)
    -> 4199 weight similarity edges
  vision_model.model.layers.16.mlp.fc1.weight [5632 x 1408] layer=16 (sampling every 2 rows)
    -> 6259 weight similarity edges
  vision_model.model.layers.17.mlp.fc1.weight [5632 x 1408] layer=17 (sampling every 2 rows)
    -> 5520 weight similarity edges
  vision_model.model.layers.23.mlp.fc1.weight [5632 x 1408] layer=23 (sampling every 2 rows)
    -> 770 weight similarity edges
  vision_model.model.layers.18.mlp.fc1.weight [5632 x 1408] layer=18 (sampling every 2 rows)
    -> 4674 weight similarity edges
  vision_model.model.layers.20.mlp.fc1.weight [5632 x 1408] layer=20 (sampling every 2 rows)
    -> 3092 weight similarity edges
  vision_model.model.layers.2.mlp.fc1.weight [5632 x 1408] layer=2 (sampling every 2 rows)
    -> 14004 weight similarity edges
  vision_model.model.layers.21.mlp.fc1.weight [5632 x 1408] layer=21 (sampling every 2 rows)
    -> 2113 weight similarity edges
  vision_model.model.layers.22.mlp.fc1.weight [5632 x 1408] layer=22 (sampling every 2 rows)
    -> 1362 weight similarity edges
  vision_model.model.layers.25.mlp.fc1.weight [5632 x 1408] layer=25 (sampling every 2 rows)
    -> 561 weight similarity edges
  vision_model.model.layers.8.mlp.fc1.weight [5632 x 1408] layer=8 (sampling every 2 rows)
    -> 10699 weight similarity edges
  vision_model.model.layers.28.mlp.fc1.weight [5632 x 1408] layer=28 (sampling every 2 rows)
    -> 977 weight similarity edges
  vision_model.model.layers.30.mlp.fc1.weight [5632 x 1408] layer=30 (sampling every 2 rows)
    -> 1602 weight similarity edges
  vision_model.model.layers.32.mlp.fc1.weight [5632 x 1408] layer=32 (sampling every 2 rows)
    -> 1402 weight similarity edges
  vision_model.model.layers.33.mlp.fc1.weight [5632 x 1408] layer=33 (sampling every 2 rows)
    -> 1378 weight similarity edges
  vision_model.model.layers.4.mlp.fc1.weight [5632 x 1408] layer=4 (sampling every 2 rows)
    -> 13903 weight similarity edges
  vision_model.model.layers.5.mlp.fc1.weight [5632 x 1408] layer=5 (sampling every 2 rows)
    -> 13714 weight similarity edges
  vision_model.model.layers.7.mlp.fc1.weight [5632 x 1408] layer=7 (sampling every 2 rows)
    -> 12737 weight similarity edges
  vision_model.model.layers.9.mlp.fc1.weight [5632 x 1408] layer=9 (sampling every 2 rows)
    -> 8888 weight similarity edges
  vision_model.vision_adapter.mlp.fc1.weight [4096 x 5632] layer=-1 (sampling every 2 rows)
    -> 21 weight similarity edges
[ATTN] Processing 35 fc2 tensors
  vision_model.model.layers.3.mlp.fc2.weight [1408 x 5632] layer=3
    -> 922 weight similarity edges
  vision_model.model.layers.17.mlp.fc2.weight [1408 x 5632] layer=17
    -> 7 weight similarity edges
  vision_model.model.layers.9.mlp.fc2.weight [1408 x 5632] layer=9
    -> 89 weight similarity edges
  vision_model.model.layers.1.mlp.fc2.weight [1408 x 5632] layer=1
    -> 3988 weight similarity edges
  vision_model.model.layers.24.mlp.fc2.weight [1408 x 5632] layer=24
    -> 8 weight similarity edges
  vision_model.model.layers.6.mlp.fc2.weight [1408 x 5632] layer=6
    -> 196 weight similarity edges
  vision_model.model.layers.14.mlp.fc2.weight [1408 x 5632] layer=14
    -> 21 weight similarity edges
  vision_model.model.layers.15.mlp.fc2.weight [1408 x 5632] layer=15
    -> 22 weight similarity edges
  vision_model.model.layers.19.mlp.fc2.weight [1408 x 5632] layer=19
    -> 6 weight similarity edges
  vision_model.model.layers.13.mlp.fc2.weight [1408 x 5632] layer=13
    -> 39 weight similarity edges
  vision_model.model.layers.0.mlp.fc2.weight [1408 x 5632] layer=0
    -> 2886 weight similarity edges
  vision_model.model.layers.10.mlp.fc2.weight [1408 x 5632] layer=10
    -> 63 weight similarity edges
  vision_model.model.layers.11.mlp.fc2.weight [1408 x 5632] layer=11
    -> 69 weight similarity edges
  vision_model.model.layers.28.mlp.fc2.weight [1408 x 5632] layer=28
    -> 4 weight similarity edges
  vision_model.model.layers.12.mlp.fc2.weight [1408 x 5632] layer=12
    -> 53 weight similarity edges
  vision_model.model.layers.2.mlp.fc2.weight [1408 x 5632] layer=2
    -> 2301 weight similarity edges
  vision_model.model.layers.16.mlp.fc2.weight [1408 x 5632] layer=16
    -> 8 weight similarity edges
  vision_model.model.layers.31.mlp.fc2.weight [1408 x 5632] layer=31
    -> 6 weight similarity edges
  vision_model.model.layers.18.mlp.fc2.weight [1408 x 5632] layer=18
    -> 4 weight similarity edges
  vision_model.model.layers.21.mlp.fc2.weight [1408 x 5632] layer=21
    -> 5 weight similarity edges
  vision_model.model.layers.23.mlp.fc2.weight [1408 x 5632] layer=23
    -> 8 weight similarity edges
  vision_model.model.layers.26.mlp.fc2.weight [1408 x 5632] layer=26
    -> 9 weight similarity edges
  vision_model.model.layers.20.mlp.fc2.weight [1408 x 5632] layer=20
    -> 3 weight similarity edges
  vision_model.model.layers.22.mlp.fc2.weight [1408 x 5632] layer=22
    -> 9 weight similarity edges
  vision_model.model.layers.27.mlp.fc2.weight [1408 x 5632] layer=27
    -> 7 weight similarity edges
  vision_model.model.layers.25.mlp.fc2.weight [1408 x 5632] layer=25
    -> 7 weight similarity edges
  vision_model.model.layers.29.mlp.fc2.weight [1408 x 5632] layer=29
    -> 3 weight similarity edges
  vision_model.model.layers.7.mlp.fc2.weight [1408 x 5632] layer=7
    -> 142 weight similarity edges
  vision_model.model.layers.30.mlp.fc2.weight [1408 x 5632] layer=30
    -> 1 weight similarity edges
  vision_model.model.layers.32.mlp.fc2.weight [1408 x 5632] layer=32
  vision_model.model.layers.33.mlp.fc2.weight [1408 x 5632] layer=33
    -> 1 weight similarity edges
  vision_model.model.layers.4.mlp.fc2.weight [1408 x 5632] layer=4
    -> 454 weight similarity edges
  vision_model.model.layers.5.mlp.fc2.weight [1408 x 5632] layer=5
    -> 256 weight similarity edges
  vision_model.model.layers.8.mlp.fc2.weight [1408 x 5632] layer=8
    -> 94 weight similarity edges
  vision_model.vision_adapter.mlp.fc2.weight [4096 x 4096] layer=-1 (sampling every 2 rows)
    -> 9 weight similarity edges
[ATTN] Processing 1 lm_head tensors
  language_model.lm_head.weight [202048 x 5120] layer=-1 (sampling every 98 rows)
    -> 1913 weight similarity edges

[TOKEN-DIM] Extracting token->dimension activation patterns...

[EXTRACT] Total: 1304970 relation edges from model weights

=== Complete ===
Total time: 1153 seconds
Tensors: 1061
BPE merges: 0
Vocab: 0 tokens
=== Universal Safetensor Ingester ===
Directory: D:\Models\embedding_models\models--sentence-transformers--all-MiniLM-L6-v2\snapshots\c9745ed1d9f207416be6d2e6f8de32d1f16199bf
Model: sentence-transformers/all-MiniLM-L6-v2
Threshold: 0.5

[1] Parsing tokenizer: "D:\\Models\\embedding_models\\models--sentence-transformers--all-MiniLM-L6-v2\\snapshots\\c9745ed1d9f207416be6d2e6f8de32d1f16199bf\\tokenizer.json"
[TOKENIZER] Loaded 0 BPE merges, 30522 vocab entries
[2] Parsing vocab: "D:\\Models\\embedding_models\\models--sentence-transformers--all-MiniLM-L6-v2\\snapshots\\c9745ed1d9f207416be6d2e6f8de32d1f16199bf\\vocab.txt"

[VOCAB] Loaded 30522 tokens in 506ms using 16 threads
[3] Parsing 1 safetensor files...
  Parsing: "D:\\Models\\embedding_models\\models--sentence-transformers--all-MiniLM-L6-v2\\snapshots\\c9745ed1d9f207416be6d2e6f8de32d1f16199bf\\model.safetensors"
[INFO] Found 104 tensors

[4] Building tensor name hierarchy...
[HIER] Building tensor hierarchy from 104 tensors
[HIER] Found 197 unique hierarchy nodes
[HIER] Built 197 compositions with atom children
[HIER] Built 194 composition->composition edges
[HIER] Inserted/updated 197 hierarchy compositions
[HIER] Inserted 6904 atom children
[HIER] Inserted 194 composition->composition edges

[5] Inserting token compositions...
[COMP] Inserting 30522 token compositions...
[COMP] 29525 multi-char compositions to insert
[COMP] Building batch strings with 16 threads...
  [BUILD] 30522/30522 tokens (58923/s)

[COMP] Built 18997KB compositions + 26895KB children in 518ms
[COMP] Streaming to database...
[COMP] Creating temp tables...
[COMP] Copying compositions to temp table...
  [COPY] Batch 1/16 (1113KB)
  [COPY] Batch 2/16 (918KB)
  [COPY] Batch 3/16 (1284KB)
  [COPY] Batch 4/16 (1612KB)
  [COPY] Batch 5/16 (1609KB)
  [COPY] Batch 6/16 (1024KB)
  [COPY] Batch 7/16 (1209KB)
  [COPY] Batch 8/16 (1372KB)
  [COPY] Batch 9/16 (1653KB)
  [COPY] Batch 10/16 (1072KB)
  [COPY] Batch 11/16 (1536KB)
  [COPY] Batch 12/16 (1536KB)
  [COPY] Batch 13/16 (1078KB)
  [COPY] Batch 14/16 (726KB)
  [COPY] Batch 15/16 (652KB)
  [COPY] Batch 16/16 (596KB)

[COMP] Copying composition children to temp table...
  [COPY] Batch 1/16 (1579KB)
  [COPY] Batch 2/16 (1278KB)
  [COPY] Batch 3/16 (1798KB)
  [COPY] Batch 4/16 (2304KB)
  [COPY] Batch 5/16 (2304KB)
  [COPY] Batch 6/16 (1465KB)
  [COPY] Batch 7/16 (1708KB)
  [COPY] Batch 8/16 (1931KB)
  [COPY] Batch 9/16 (2346KB)
  [COPY] Batch 10/16 (1536KB)
  [COPY] Batch 11/16 (2195KB)
  [COPY] Batch 12/16 (2170KB)
  [COPY] Batch 13/16 (1508KB)
  [COPY] Batch 14/16 (1024KB)
  [COPY] Batch 15/16 (903KB)
  [COPY] Batch 16/16 (839KB)

[COMP] Inserting into composition table...
[COMP] Inserted 0 compositions
[COMP] Inserting into composition_child table...
[COMP] Inserted 0 children
[COMP] Inserted 0 compositions, 0 children in 1071ms

[6] Computing composition centroids hierarchically...
[CENTROID] Updated 36662 composition centroids from atoms

[7] Extracting embedding k-NN similarity as relations...
[EMBED] Found 2 embedding tensor(s)
[EMBED] Processing embeddings.word_embeddings.weight [token, thresh=0]: 30522 x 384 dims
[EMBED] Read embeddings in 104ms
[EMBED] Built k-NN graph: 54002 edges in 1048ms
[EMBED] Processing embeddings.position_embeddings.weight [position, thresh=0]: 512 x 384 dims
[EMBED] Read embeddings in 2ms
[EMBED] Built k-NN graph: 3933 edges in 5ms
[EMBED] Processed all tensors in 1239ms, 57935 edges
[EMBED] Bulk inserted 57935 relations in 820ms
[EMBED] Total: 57935 embedding similarity relations

[8] Extracting weight-based relations (router, attention, MLP)...
[ROUTER] No router tensors found (not an MoE model)

[ATTN] Extracting attention projection similarities...
[ATTN] Processing 6 query tensors
  encoder.layer.0.attention.self.query.weight [384 x 384] layer=-1
    -> 1406 weight similarity edges
  encoder.layer.3.attention.self.query.weight [384 x 384] layer=-1
    -> 1459 weight similarity edges
  encoder.layer.5.attention.self.query.weight [384 x 384] layer=-1
    -> 1408 weight similarity edges
  encoder.layer.1.attention.self.query.weight [384 x 384] layer=-1
    -> 1338 weight similarity edges
  encoder.layer.2.attention.self.query.weight [384 x 384] layer=-1
    -> 1467 weight similarity edges
  encoder.layer.4.attention.self.query.weight [384 x 384] layer=-1
    -> 1547 weight similarity edges
[ATTN] Processing 6 key tensors
  encoder.layer.1.attention.self.key.weight [384 x 384] layer=-1
    -> 1481 weight similarity edges
  encoder.layer.0.attention.self.key.weight [384 x 384] layer=-1
    -> 1502 weight similarity edges
  encoder.layer.3.attention.self.key.weight [384 x 384] layer=-1
    -> 1389 weight similarity edges
  encoder.layer.2.attention.self.key.weight [384 x 384] layer=-1
    -> 1476 weight similarity edges
  encoder.layer.4.attention.self.key.weight [384 x 384] layer=-1
    -> 1482 weight similarity edges
  encoder.layer.5.attention.self.key.weight [384 x 384] layer=-1
    -> 928 weight similarity edges
[ATTN] Processing 6 value tensors
  encoder.layer.1.attention.self.value.weight [384 x 384] layer=-1
    -> 1204 weight similarity edges
  encoder.layer.0.attention.self.value.weight [384 x 384] layer=-1
    -> 1153 weight similarity edges
  encoder.layer.2.attention.self.value.weight [384 x 384] layer=-1
    -> 1176 weight similarity edges
  encoder.layer.3.attention.self.value.weight [384 x 384] layer=-1
    -> 1469 weight similarity edges
  encoder.layer.4.attention.self.value.weight [384 x 384] layer=-1
    -> 1383 weight similarity edges
  encoder.layer.5.attention.self.value.weight [384 x 384] layer=-1
    -> 513 weight similarity edges

[TOKEN-DIM] Extracting token->dimension activation patterns...
[TOKEN-DIM] Processing 30522 tokens x 384 dims
[TOKEN-DIM] Created 117 token->dimension edges

[EXTRACT] Total: 23898 relation edges from model weights

=== Complete ===
Total time: 6 seconds
Tensors: 104
BPE merges: 0
Vocab: 30522 tokens
=== Universal Safetensor Ingester ===
Directory: D:\Models\generation_models\models--black-forest-labs--FLUX.2-dev\snapshots\6aab690f8379b70adc89edfa6bb99b3537ba52a3\text_encoder
Model: black-forest-labs/FLUX.2-dev
Threshold: 0.5

[3] Parsing sharded model index: "D:\\Models\\generation_models\\models--black-forest-labs--FLUX.2-dev\\snapshots\\6aab690f8379b70adc89edfa6bb99b3537ba52a3\\text_encoder\\model.safetensors.index.json"
  Parsing shard: model-00007-of-00010.safetensors
  Parsing shard: model-00010-of-00010.safetensors
  Parsing shard: model-00001-of-00010.safetensors
  Parsing shard: model-00003-of-00010.safetensors
  Parsing shard: model-00004-of-00010.safetensors
  Parsing shard: model-00005-of-00010.safetensors
  Parsing shard: model-00006-of-00010.safetensors
  Parsing shard: model-00002-of-00010.safetensors
  Parsing shard: model-00008-of-00010.safetensors
  Parsing shard: model-00009-of-00010.safetensors
[INDEX] Parsed 10 shards, 585 tensors
[INFO] Found 585 tensors

[4] Building tensor name hierarchy...
[HIER] Building tensor hierarchy from 585 tensors
[HIER] Found 1370 unique hierarchy nodes
[HIER] Built 1370 compositions with atom children
[HIER] Built 1367 composition->composition edges
[HIER] Inserted/updated 1370 hierarchy compositions
[HIER] Inserted 39580 atom children
[HIER] Inserted 757 composition->composition edges

[6] Computing composition centroids hierarchically...
[CENTROID] Updated 37460 composition centroids from atoms

[7] Extracting embedding k-NN similarity as relations...
[EMBED] Found 1 embedding tensor(s)
[EMBED] Processing language_model.model.embed_tokens.weight [token, thresh=0.45]: 131072 x 5120 dims
[EMBED] Read embeddings in 1735ms
[EMBED] Built k-NN graph: 28599 edges in 370457ms
[EMBED] Processed all tensors in 372948ms, 28599 edges
[EMBED] Bulk inserted 28599 relations in 923ms
[EMBED] Total: 28599 embedding similarity relations

[8] Extracting weight-based relations (router, attention, MLP)...
[ROUTER] No router tensors found (not an MoE model)

[ATTN] Extracting attention projection similarities...
[ATTN] Processing 64 q_proj tensors
  vision_tower.transformer.layers.5.attention.q_proj.weight [1024 x 1024] layer=5
    -> 5126 weight similarity edges
  vision_tower.transformer.layers.23.attention.q_proj.weight [1024 x 1024] layer=23
    -> 2527 weight similarity edges
  language_model.model.layers.29.self_attn.q_proj.weight [4096 x 5120] layer=29 (sampling every 2 rows)
    -> 3410 weight similarity edges
  language_model.model.layers.26.self_attn.q_proj.weight [4096 x 5120] layer=26 (sampling every 2 rows)
    -> 3760 weight similarity edges
  vision_tower.transformer.layers.7.attention.q_proj.weight [1024 x 1024] layer=7
    -> 4790 weight similarity edges
  vision_tower.transformer.layers.21.attention.q_proj.weight [1024 x 1024] layer=21
    -> 2032 weight similarity edges
  language_model.model.layers.25.self_attn.q_proj.weight [4096 x 5120] layer=25 (sampling every 2 rows)
    -> 4557 weight similarity edges
  language_model.model.layers.28.self_attn.q_proj.weight [4096 x 5120] layer=28 (sampling every 2 rows)
    -> 4994 weight similarity edges
  language_model.model.layers.12.self_attn.q_proj.weight [4096 x 5120] layer=12 (sampling every 2 rows)
    -> 4751 weight similarity edges
  language_model.model.layers.27.self_attn.q_proj.weight [4096 x 5120] layer=27 (sampling every 2 rows)
    -> 3582 weight similarity edges
  vision_tower.transformer.layers.19.attention.q_proj.weight [1024 x 1024] layer=19
    -> 2235 weight similarity edges
  language_model.model.layers.38.self_attn.q_proj.weight [4096 x 5120] layer=38 (sampling every 2 rows)
    -> 6719 weight similarity edges
  language_model.model.layers.2.self_attn.q_proj.weight [4096 x 5120] layer=2 (sampling every 2 rows)
    -> 8375 weight similarity edges
  language_model.model.layers.39.self_attn.q_proj.weight [4096 x 5120] layer=39 (sampling every 2 rows)
    -> 6295 weight similarity edges
  language_model.model.layers.0.self_attn.q_proj.weight [4096 x 5120] layer=0 (sampling every 2 rows)
    -> 10079 weight similarity edges
  vision_tower.transformer.layers.3.attention.q_proj.weight [1024 x 1024] layer=3
    -> 5124 weight similarity edges
  language_model.model.layers.1.self_attn.q_proj.weight [4096 x 5120] layer=1 (sampling every 2 rows)
    -> 9110 weight similarity edges
  language_model.model.layers.31.self_attn.q_proj.weight [4096 x 5120] layer=31 (sampling every 2 rows)
    -> 3357 weight similarity edges
  vision_tower.transformer.layers.0.attention.q_proj.weight [1024 x 1024] layer=0
    -> 5135 weight similarity edges
  vision_tower.transformer.layers.1.attention.q_proj.weight [1024 x 1024] layer=1
    -> 5271 weight similarity edges
  vision_tower.transformer.layers.10.attention.q_proj.weight [1024 x 1024] layer=10
    -> 4302 weight similarity edges
  vision_tower.transformer.layers.11.attention.q_proj.weight [1024 x 1024] layer=11
    -> 3206 weight similarity edges
  vision_tower.transformer.layers.12.attention.q_proj.weight [1024 x 1024] layer=12
    -> 3392 weight similarity edges
  vision_tower.transformer.layers.18.attention.q_proj.weight [1024 x 1024] layer=18
    -> 2123 weight similarity edges
  language_model.model.layers.16.self_attn.q_proj.weight [4096 x 5120] layer=16 (sampling every 2 rows)
    -> 4453 weight similarity edges
  language_model.model.layers.9.self_attn.q_proj.weight [4096 x 5120] layer=9 (sampling every 2 rows)
    -> 4036 weight similarity edges
  language_model.model.layers.17.self_attn.q_proj.weight [4096 x 5120] layer=17 (sampling every 2 rows)
    -> 6182 weight similarity edges
  vision_tower.transformer.layers.13.attention.q_proj.weight [1024 x 1024] layer=13
    -> 3177 weight similarity edges
  vision_tower.transformer.layers.14.attention.q_proj.weight [1024 x 1024] layer=14
    -> 3117 weight similarity edges
  language_model.model.layers.7.self_attn.q_proj.weight [4096 x 5120] layer=7 (sampling every 2 rows)
    -> 5048 weight similarity edges
  vision_tower.transformer.layers.15.attention.q_proj.weight [1024 x 1024] layer=15
    -> 2378 weight similarity edges
  vision_tower.transformer.layers.16.attention.q_proj.weight [1024 x 1024] layer=16
    -> 2550 weight similarity edges
  vision_tower.transformer.layers.17.attention.q_proj.weight [1024 x 1024] layer=17
    -> 2295 weight similarity edges
  language_model.model.layers.22.self_attn.q_proj.weight [4096 x 5120] layer=22 (sampling every 2 rows)
    -> 3813 weight similarity edges
  vision_tower.transformer.layers.8.attention.q_proj.weight [1024 x 1024] layer=8
    -> 4946 weight similarity edges
  vision_tower.transformer.layers.2.attention.q_proj.weight [1024 x 1024] layer=2
    -> 5018 weight similarity edges
  vision_tower.transformer.layers.6.attention.q_proj.weight [1024 x 1024] layer=6
    -> 5032 weight similarity edges
  vision_tower.transformer.layers.20.attention.q_proj.weight [1024 x 1024] layer=20
    -> 1732 weight similarity edges
  language_model.model.layers.11.self_attn.q_proj.weight [4096 x 5120] layer=11 (sampling every 2 rows)
    -> 4266 weight similarity edges
  vision_tower.transformer.layers.4.attention.q_proj.weight [1024 x 1024] layer=4
    -> 4998 weight similarity edges
  vision_tower.transformer.layers.22.attention.q_proj.weight [1024 x 1024] layer=22
    -> 1763 weight similarity edges
  language_model.model.layers.35.self_attn.q_proj.weight [4096 x 5120] layer=35 (sampling every 2 rows)
    -> 6722 weight similarity edges
  vision_tower.transformer.layers.9.attention.q_proj.weight [1024 x 1024] layer=9
    -> 4490 weight similarity edges
  language_model.model.layers.10.self_attn.q_proj.weight [4096 x 5120] layer=10 (sampling every 2 rows)
    -> 4618 weight similarity edges
  language_model.model.layers.8.self_attn.q_proj.weight [4096 x 5120] layer=8 (sampling every 2 rows)
    -> 4420 weight similarity edges
  language_model.model.layers.6.self_attn.q_proj.weight [4096 x 5120] layer=6 (sampling every 2 rows)
    -> 4350 weight similarity edges
  language_model.model.layers.4.self_attn.q_proj.weight [4096 x 5120] layer=4 (sampling every 2 rows)
    -> 4656 weight similarity edges
  language_model.model.layers.19.self_attn.q_proj.weight [4096 x 5120] layer=19 (sampling every 2 rows)
    -> 4873 weight similarity edges
  language_model.model.layers.30.self_attn.q_proj.weight [4096 x 5120] layer=30 (sampling every 2 rows)
    -> 5267 weight similarity edges
  language_model.model.layers.13.self_attn.q_proj.weight [4096 x 5120] layer=13 (sampling every 2 rows)
    -> 4976 weight similarity edges
  language_model.model.layers.14.self_attn.q_proj.weight [4096 x 5120] layer=14 (sampling every 2 rows)
    -> 6285 weight similarity edges
  language_model.model.layers.15.self_attn.q_proj.weight [4096 x 5120] layer=15 (sampling every 2 rows)
    -> 5196 weight similarity edges
  language_model.model.layers.23.self_attn.q_proj.weight [4096 x 5120] layer=23 (sampling every 2 rows)
    -> 4681 weight similarity edges
  language_model.model.layers.18.self_attn.q_proj.weight [4096 x 5120] layer=18 (sampling every 2 rows)
    -> 5597 weight similarity edges
  language_model.model.layers.20.self_attn.q_proj.weight [4096 x 5120] layer=20 (sampling every 2 rows)
    -> 4684 weight similarity edges
  language_model.model.layers.24.self_attn.q_proj.weight [4096 x 5120] layer=24 (sampling every 2 rows)
    -> 3947 weight similarity edges
  language_model.model.layers.21.self_attn.q_proj.weight [4096 x 5120] layer=21 (sampling every 2 rows)
    -> 4408 weight similarity edges
  language_model.model.layers.3.self_attn.q_proj.weight [4096 x 5120] layer=3 (sampling every 2 rows)
    -> 4782 weight similarity edges
  language_model.model.layers.36.self_attn.q_proj.weight [4096 x 5120] layer=36 (sampling every 2 rows)
    -> 5864 weight similarity edges
  language_model.model.layers.5.self_attn.q_proj.weight [4096 x 5120] layer=5 (sampling every 2 rows)
    -> 4398 weight similarity edges
  language_model.model.layers.32.self_attn.q_proj.weight [4096 x 5120] layer=32 (sampling every 2 rows)
    -> 5138 weight similarity edges
  language_model.model.layers.33.self_attn.q_proj.weight [4096 x 5120] layer=33 (sampling every 2 rows)
    -> 4446 weight similarity edges
  language_model.model.layers.34.self_attn.q_proj.weight [4096 x 5120] layer=34 (sampling every 2 rows)
    -> 5598 weight similarity edges
  language_model.model.layers.37.self_attn.q_proj.weight [4096 x 5120] layer=37 (sampling every 2 rows)
    -> 6575 weight similarity edges
[ATTN] Processing 64 k_proj tensors
  vision_tower.transformer.layers.8.attention.k_proj.weight [1024 x 1024] layer=8
    -> 5028 weight similarity edges
  language_model.model.layers.25.self_attn.k_proj.weight [1024 x 5120] layer=25
    -> 1715 weight similarity edges
  language_model.model.layers.26.self_attn.k_proj.weight [1024 x 5120] layer=26
    -> 1277 weight similarity edges
  language_model.model.layers.27.self_attn.k_proj.weight [1024 x 5120] layer=27
    -> 1330 weight similarity edges
  language_model.model.layers.22.self_attn.k_proj.weight [1024 x 5120] layer=22
    -> 1320 weight similarity edges
  language_model.model.layers.38.self_attn.k_proj.weight [1024 x 5120] layer=38
    -> 2058 weight similarity edges
  language_model.model.layers.28.self_attn.k_proj.weight [1024 x 5120] layer=28
    -> 1932 weight similarity edges
  vision_tower.transformer.layers.2.attention.k_proj.weight [1024 x 1024] layer=2
    -> 4986 weight similarity edges
  vision_tower.transformer.layers.17.attention.k_proj.weight [1024 x 1024] layer=17
    -> 2074 weight similarity edges
  language_model.model.layers.39.self_attn.k_proj.weight [1024 x 5120] layer=39
    -> 2196 weight similarity edges
  language_model.model.layers.21.self_attn.k_proj.weight [1024 x 5120] layer=21
    -> 1487 weight similarity edges
  language_model.model.layers.0.self_attn.k_proj.weight [1024 x 5120] layer=0
    -> 4983 weight similarity edges
  vision_tower.transformer.layers.3.attention.k_proj.weight [1024 x 1024] layer=3
    -> 5147 weight similarity edges
  language_model.model.layers.1.self_attn.k_proj.weight [1024 x 5120] layer=1
    -> 4250 weight similarity edges
  language_model.model.layers.2.self_attn.k_proj.weight [1024 x 5120] layer=2
    -> 3802 weight similarity edges
  vision_tower.transformer.layers.0.attention.k_proj.weight [1024 x 1024] layer=0
    -> 5169 weight similarity edges
  language_model.model.layers.31.self_attn.k_proj.weight [1024 x 5120] layer=31
    -> 1472 weight similarity edges
  language_model.model.layers.10.self_attn.k_proj.weight [1024 x 5120] layer=10
    -> 1829 weight similarity edges
  language_model.model.layers.34.self_attn.k_proj.weight [1024 x 5120] layer=34
    -> 2745 weight similarity edges
  vision_tower.transformer.layers.1.attention.k_proj.weight [1024 x 1024] layer=1
    -> 5152 weight similarity edges
  vision_tower.transformer.layers.15.attention.k_proj.weight [1024 x 1024] layer=15
    -> 2218 weight similarity edges
  vision_tower.transformer.layers.10.attention.k_proj.weight [1024 x 1024] layer=10
    -> 3834 weight similarity edges
  vision_tower.transformer.layers.11.attention.k_proj.weight [1024 x 1024] layer=11
    -> 2980 weight similarity edges
  vision_tower.transformer.layers.12.attention.k_proj.weight [1024 x 1024] layer=12
    -> 2979 weight similarity edges
  vision_tower.transformer.layers.13.attention.k_proj.weight [1024 x 1024] layer=13
    -> 2708 weight similarity edges
  vision_tower.transformer.layers.14.attention.k_proj.weight [1024 x 1024] layer=14
    -> 2639 weight similarity edges
  vision_tower.transformer.layers.4.attention.k_proj.weight [1024 x 1024] layer=4
    -> 4973 weight similarity edges
  vision_tower.transformer.layers.22.attention.k_proj.weight [1024 x 1024] layer=22
    -> 1653 weight similarity edges
  vision_tower.transformer.layers.21.attention.k_proj.weight [1024 x 1024] layer=21
    -> 2035 weight similarity edges
  vision_tower.transformer.layers.7.attention.k_proj.weight [1024 x 1024] layer=7
    -> 4691 weight similarity edges
  vision_tower.transformer.layers.16.attention.k_proj.weight [1024 x 1024] layer=16
    -> 2512 weight similarity edges
  language_model.model.layers.6.self_attn.k_proj.weight [1024 x 5120] layer=6
    -> 1789 weight similarity edges
  vision_tower.transformer.layers.18.attention.k_proj.weight [1024 x 1024] layer=18
    -> 2054 weight similarity edges
  vision_tower.transformer.layers.19.attention.k_proj.weight [1024 x 1024] layer=19
    -> 1910 weight similarity edges
  language_model.model.layers.4.self_attn.k_proj.weight [1024 x 5120] layer=4
    -> 1673 weight similarity edges
  vision_tower.transformer.layers.6.attention.k_proj.weight [1024 x 1024] layer=6
    -> 5049 weight similarity edges
  vision_tower.transformer.layers.20.attention.k_proj.weight [1024 x 1024] layer=20
    -> 1680 weight similarity edges
  vision_tower.transformer.layers.5.attention.k_proj.weight [1024 x 1024] layer=5
    -> 5144 weight similarity edges
  vision_tower.transformer.layers.23.attention.k_proj.weight [1024 x 1024] layer=23
    -> 2811 weight similarity edges
  language_model.model.layers.18.self_attn.k_proj.weight [1024 x 5120] layer=18
    -> 1956 weight similarity edges
  vision_tower.transformer.layers.9.attention.k_proj.weight [1024 x 1024] layer=9
    -> 4012 weight similarity edges
  language_model.model.layers.9.self_attn.k_proj.weight [1024 x 5120] layer=9
    -> 1589 weight similarity edges
  language_model.model.layers.11.self_attn.k_proj.weight [1024 x 5120] layer=11
    -> 1725 weight similarity edges
  language_model.model.layers.7.self_attn.k_proj.weight [1024 x 5120] layer=7
    -> 1838 weight similarity edges
  language_model.model.layers.8.self_attn.k_proj.weight [1024 x 5120] layer=8
    -> 1439 weight similarity edges
  language_model.model.layers.12.self_attn.k_proj.weight [1024 x 5120] layer=12
    -> 1811 weight similarity edges
  language_model.model.layers.13.self_attn.k_proj.weight [1024 x 5120] layer=13
    -> 1801 weight similarity edges
  language_model.model.layers.14.self_attn.k_proj.weight [1024 x 5120] layer=14
    -> 1922 weight similarity edges
  language_model.model.layers.15.self_attn.k_proj.weight [1024 x 5120] layer=15
    -> 1806 weight similarity edges
  language_model.model.layers.16.self_attn.k_proj.weight [1024 x 5120] layer=16
    -> 1382 weight similarity edges
  language_model.model.layers.17.self_attn.k_proj.weight [1024 x 5120] layer=17
    -> 2028 weight similarity edges
  language_model.model.layers.19.self_attn.k_proj.weight [1024 x 5120] layer=19
    -> 1581 weight similarity edges
  language_model.model.layers.20.self_attn.k_proj.weight [1024 x 5120] layer=20
    -> 1603 weight similarity edges
  language_model.model.layers.23.self_attn.k_proj.weight [1024 x 5120] layer=23
    -> 1718 weight similarity edges
  language_model.model.layers.24.self_attn.k_proj.weight [1024 x 5120] layer=24
    -> 1260 weight similarity edges
  language_model.model.layers.3.self_attn.k_proj.weight [1024 x 5120] layer=3
    -> 1680 weight similarity edges
  language_model.model.layers.5.self_attn.k_proj.weight [1024 x 5120] layer=5
    -> 1460 weight similarity edges
  language_model.model.layers.36.self_attn.k_proj.weight [1024 x 5120] layer=36
    -> 1991 weight similarity edges
  language_model.model.layers.29.self_attn.k_proj.weight [1024 x 5120] layer=29
    -> 1559 weight similarity edges
  language_model.model.layers.30.self_attn.k_proj.weight [1024 x 5120] layer=30
    -> 2842 weight similarity edges
  language_model.model.layers.32.self_attn.k_proj.weight [1024 x 5120] layer=32
    -> 2585 weight similarity edges
  language_model.model.layers.33.self_attn.k_proj.weight [1024 x 5120] layer=33
    -> 1826 weight similarity edges
  language_model.model.layers.35.self_attn.k_proj.weight [1024 x 5120] layer=35
    -> 3301 weight similarity edges
  language_model.model.layers.37.self_attn.k_proj.weight [1024 x 5120] layer=37
    -> 2684 weight similarity edges
[ATTN] Processing 64 v_proj tensors
  language_model.model.layers.23.self_attn.v_proj.weight [1024 x 5120] layer=23
    -> 19 weight similarity edges
  language_model.model.layers.28.self_attn.v_proj.weight [1024 x 5120] layer=28
    -> 57 weight similarity edges
  language_model.model.layers.25.self_attn.v_proj.weight [1024 x 5120] layer=25
    -> 21 weight similarity edges
  language_model.model.layers.4.self_attn.v_proj.weight [1024 x 5120] layer=4
    -> 9 weight similarity edges
  language_model.model.layers.27.self_attn.v_proj.weight [1024 x 5120] layer=27
    -> 118 weight similarity edges
  vision_tower.transformer.layers.7.attention.v_proj.weight [1024 x 1024] layer=7
    -> 3848 weight similarity edges
  vision_tower.transformer.layers.21.attention.v_proj.weight [1024 x 1024] layer=21
    -> 1832 weight similarity edges
  language_model.model.layers.26.self_attn.v_proj.weight [1024 x 5120] layer=26
    -> 19 weight similarity edges
  language_model.model.layers.19.self_attn.v_proj.weight [1024 x 5120] layer=19
    -> 7 weight similarity edges
  vision_tower.transformer.layers.13.attention.v_proj.weight [1024 x 1024] layer=13
    -> 638 weight similarity edges
  vision_tower.transformer.layers.2.attention.v_proj.weight [1024 x 1024] layer=2
    -> 3540 weight similarity edges
  language_model.model.layers.38.self_attn.v_proj.weight [1024 x 5120] layer=38
    -> 93 weight similarity edges
  language_model.model.layers.24.self_attn.v_proj.weight [1024 x 5120] layer=24
    -> 9 weight similarity edges
  language_model.model.layers.39.self_attn.v_proj.weight [1024 x 5120] layer=39
    -> 748 weight similarity edges
  language_model.model.layers.0.self_attn.v_proj.weight [1024 x 5120] layer=0
    -> 551 weight similarity edges
  vision_tower.transformer.layers.3.attention.v_proj.weight [1024 x 1024] layer=3
    -> 3736 weight similarity edges
  language_model.model.layers.1.self_attn.v_proj.weight [1024 x 5120] layer=1
    -> 38 weight similarity edges
  language_model.model.layers.2.self_attn.v_proj.weight [1024 x 5120] layer=2
    -> 29 weight similarity edges
  language_model.model.layers.10.self_attn.v_proj.weight [1024 x 5120] layer=10
    -> 9 weight similarity edges
  vision_tower.transformer.layers.0.attention.v_proj.weight [1024 x 1024] layer=0
    -> 1263 weight similarity edges
  vision_tower.transformer.layers.15.attention.v_proj.weight [1024 x 1024] layer=15
    -> 593 weight similarity edges
  vision_tower.transformer.layers.4.attention.v_proj.weight [1024 x 1024] layer=4
    -> 3639 weight similarity edges
  vision_tower.transformer.layers.22.attention.v_proj.weight [1024 x 1024] layer=22
    -> 2497 weight similarity edges
  vision_tower.transformer.layers.1.attention.v_proj.weight [1024 x 1024] layer=1
    -> 3631 weight similarity edges
  language_model.model.layers.34.self_attn.v_proj.weight [1024 x 5120] layer=34
    -> 105 weight similarity edges
  vision_tower.transformer.layers.10.attention.v_proj.weight [1024 x 1024] layer=10
    -> 1476 weight similarity edges
  vision_tower.transformer.layers.11.attention.v_proj.weight [1024 x 1024] layer=11
    -> 1378 weight similarity edges
  language_model.model.layers.7.self_attn.v_proj.weight [1024 x 5120] layer=7
    -> 20 weight similarity edges
  vision_tower.transformer.layers.12.attention.v_proj.weight [1024 x 1024] layer=12
    -> 958 weight similarity edges
  vision_tower.transformer.layers.14.attention.v_proj.weight [1024 x 1024] layer=14
    -> 637 weight similarity edges
  language_model.model.layers.6.self_attn.v_proj.weight [1024 x 5120] layer=6
    -> 15 weight similarity edges
  vision_tower.transformer.layers.16.attention.v_proj.weight [1024 x 1024] layer=16
    -> 1034 weight similarity edges
  vision_tower.transformer.layers.17.attention.v_proj.weight [1024 x 1024] layer=17
    -> 195 weight similarity edges
  language_model.model.layers.22.self_attn.v_proj.weight [1024 x 5120] layer=22
    -> 17 weight similarity edges
  vision_tower.transformer.layers.18.attention.v_proj.weight [1024 x 1024] layer=18
    -> 756 weight similarity edges
  vision_tower.transformer.layers.19.attention.v_proj.weight [1024 x 1024] layer=19
    -> 869 weight similarity edges
  vision_tower.transformer.layers.6.attention.v_proj.weight [1024 x 1024] layer=6
    -> 3908 weight similarity edges
  vision_tower.transformer.layers.20.attention.v_proj.weight [1024 x 1024] layer=20
    -> 691 weight similarity edges
  vision_tower.transformer.layers.5.attention.v_proj.weight [1024 x 1024] layer=5
    -> 3801 weight similarity edges
  vision_tower.transformer.layers.23.attention.v_proj.weight [1024 x 1024] layer=23
    -> 2138 weight similarity edges
  language_model.model.layers.35.self_attn.v_proj.weight [1024 x 5120] layer=35
    -> 217 weight similarity edges
  language_model.model.layers.15.self_attn.v_proj.weight [1024 x 5120] layer=15
    -> 31 weight similarity edges
  vision_tower.transformer.layers.8.attention.v_proj.weight [1024 x 1024] layer=8
    -> 2853 weight similarity edges
  vision_tower.transformer.layers.9.attention.v_proj.weight [1024 x 1024] layer=9
    -> 1745 weight similarity edges
  language_model.model.layers.31.self_attn.v_proj.weight [1024 x 5120] layer=31
    -> 22 weight similarity edges
  language_model.model.layers.36.self_attn.v_proj.weight [1024 x 5120] layer=36
    -> 158 weight similarity edges
  language_model.model.layers.11.self_attn.v_proj.weight [1024 x 5120] layer=11
    -> 13 weight similarity edges
  language_model.model.layers.8.self_attn.v_proj.weight [1024 x 5120] layer=8
    -> 16 weight similarity edges
  language_model.model.layers.5.self_attn.v_proj.weight [1024 x 5120] layer=5
    -> 6 weight similarity edges
  language_model.model.layers.9.self_attn.v_proj.weight [1024 x 5120] layer=9
    -> 8 weight similarity edges
  language_model.model.layers.12.self_attn.v_proj.weight [1024 x 5120] layer=12
    -> 57 weight similarity edges
  language_model.model.layers.13.self_attn.v_proj.weight [1024 x 5120] layer=13
    -> 37 weight similarity edges
  language_model.model.layers.14.self_attn.v_proj.weight [1024 x 5120] layer=14
    -> 57 weight similarity edges
  language_model.model.layers.16.self_attn.v_proj.weight [1024 x 5120] layer=16
    -> 8 weight similarity edges
  language_model.model.layers.17.self_attn.v_proj.weight [1024 x 5120] layer=17
    -> 15 weight similarity edges
  language_model.model.layers.18.self_attn.v_proj.weight [1024 x 5120] layer=18
    -> 18 weight similarity edges
  language_model.model.layers.20.self_attn.v_proj.weight [1024 x 5120] layer=20
    -> 6 weight similarity edges
  language_model.model.layers.21.self_attn.v_proj.weight [1024 x 5120] layer=21
    -> 2 weight similarity edges
  language_model.model.layers.37.self_attn.v_proj.weight [1024 x 5120] layer=37
    -> 158 weight similarity edges
  language_model.model.layers.3.self_attn.v_proj.weight [1024 x 5120] layer=3
    -> 30 weight similarity edges
  language_model.model.layers.29.self_attn.v_proj.weight [1024 x 5120] layer=29
    -> 23 weight similarity edges
  language_model.model.layers.30.self_attn.v_proj.weight [1024 x 5120] layer=30
    -> 247 weight similarity edges
  language_model.model.layers.32.self_attn.v_proj.weight [1024 x 5120] layer=32
    -> 100 weight similarity edges
  language_model.model.layers.33.self_attn.v_proj.weight [1024 x 5120] layer=33
    -> 83 weight similarity edges
[ATTN] Processing 64 o_proj tensors
  language_model.model.layers.28.self_attn.o_proj.weight [5120 x 4096] layer=28 (sampling every 2 rows)
    -> 19 weight similarity edges
  language_model.model.layers.2.self_attn.o_proj.weight [5120 x 4096] layer=2 (sampling every 2 rows)
    -> 66 weight similarity edges
  language_model.model.layers.25.self_attn.o_proj.weight [5120 x 4096] layer=25 (sampling every 2 rows)
    -> 12 weight similarity edges
  language_model.model.layers.27.self_attn.o_proj.weight [5120 x 4096] layer=27 (sampling every 2 rows)
    -> 15 weight similarity edges
  language_model.model.layers.31.self_attn.o_proj.weight [5120 x 4096] layer=31 (sampling every 2 rows)
    -> 13 weight similarity edges
  language_model.model.layers.26.self_attn.o_proj.weight [5120 x 4096] layer=26 (sampling every 2 rows)
    -> 33 weight similarity edges
  language_model.model.layers.39.self_attn.o_proj.weight [5120 x 4096] layer=39 (sampling every 2 rows)
    -> 4301 weight similarity edges
  vision_tower.transformer.layers.8.attention.o_proj.weight [1024 x 1024] layer=8
    -> 730 weight similarity edges
  language_model.model.layers.38.self_attn.o_proj.weight [5120 x 4096] layer=38 (sampling every 2 rows)
    -> 606 weight similarity edges
  language_model.model.layers.0.self_attn.o_proj.weight [5120 x 4096] layer=0 (sampling every 2 rows)
    -> 471 weight similarity edges
  vision_tower.transformer.layers.7.attention.o_proj.weight [1024 x 1024] layer=7
    -> 1033 weight similarity edges
  vision_tower.transformer.layers.21.attention.o_proj.weight [1024 x 1024] layer=21
    -> 483 weight similarity edges
  vision_tower.transformer.layers.3.attention.o_proj.weight [1024 x 1024] layer=3
    -> 3254 weight similarity edges
  language_model.model.layers.1.self_attn.o_proj.weight [5120 x 4096] layer=1 (sampling every 2 rows)
    -> 61 weight similarity edges
  vision_tower.transformer.layers.0.attention.o_proj.weight [1024 x 1024] layer=0
    -> 317 weight similarity edges
  vision_tower.transformer.layers.1.attention.o_proj.weight [1024 x 1024] layer=1
    -> 4794 weight similarity edges
  vision_tower.transformer.layers.4.attention.o_proj.weight [1024 x 1024] layer=4
    -> 2506 weight similarity edges
  vision_tower.transformer.layers.22.attention.o_proj.weight [1024 x 1024] layer=22
    -> 742 weight similarity edges
  vision_tower.transformer.layers.10.attention.o_proj.weight [1024 x 1024] layer=10
    -> 182 weight similarity edges
  language_model.model.layers.5.self_attn.o_proj.weight [5120 x 4096] layer=5 (sampling every 2 rows)
    -> 28 weight similarity edges
  vision_tower.transformer.layers.11.attention.o_proj.weight [1024 x 1024] layer=11
    -> 236 weight similarity edges
  vision_tower.transformer.layers.12.attention.o_proj.weight [1024 x 1024] layer=12
    -> 99 weight similarity edges
  vision_tower.transformer.layers.13.attention.o_proj.weight [1024 x 1024] layer=13
    -> 61 weight similarity edges
  language_model.model.layers.17.self_attn.o_proj.weight [5120 x 4096] layer=17 (sampling every 2 rows)
    -> 25 weight similarity edges
  vision_tower.transformer.layers.14.attention.o_proj.weight [1024 x 1024] layer=14
    -> 61 weight similarity edges
  vision_tower.transformer.layers.15.attention.o_proj.weight [1024 x 1024] layer=15
    -> 37 weight similarity edges
  vision_tower.transformer.layers.9.attention.o_proj.weight [1024 x 1024] layer=9
    -> 339 weight similarity edges
  language_model.model.layers.4.self_attn.o_proj.weight [5120 x 4096] layer=4 (sampling every 2 rows)
    -> 55 weight similarity edges
  vision_tower.transformer.layers.16.attention.o_proj.weight [1024 x 1024] layer=16
    -> 64 weight similarity edges
  language_model.model.layers.10.self_attn.o_proj.weight [5120 x 4096] layer=10 (sampling every 2 rows)
    -> 48 weight similarity edges
  vision_tower.transformer.layers.17.attention.o_proj.weight [1024 x 1024] layer=17
    -> 34 weight similarity edges
  vision_tower.transformer.layers.18.attention.o_proj.weight [1024 x 1024] layer=18
    -> 68 weight similarity edges
  language_model.model.layers.22.self_attn.o_proj.weight [5120 x 4096] layer=22 (sampling every 2 rows)
    -> 7 weight similarity edges
  vision_tower.transformer.layers.19.attention.o_proj.weight [1024 x 1024] layer=19
    -> 126 weight similarity edges
  vision_tower.transformer.layers.2.attention.o_proj.weight [1024 x 1024] layer=2
    -> 4347 weight similarity edges
  vision_tower.transformer.layers.6.attention.o_proj.weight [1024 x 1024] layer=6
    -> 2378 weight similarity edges
  vision_tower.transformer.layers.20.attention.o_proj.weight [1024 x 1024] layer=20
    -> 68 weight similarity edges
  language_model.model.layers.18.self_attn.o_proj.weight [5120 x 4096] layer=18 (sampling every 2 rows)
    -> 46 weight similarity edges
  vision_tower.transformer.layers.5.attention.o_proj.weight [1024 x 1024] layer=5
    -> 3170 weight similarity edges
  vision_tower.transformer.layers.23.attention.o_proj.weight [1024 x 1024] layer=23
    -> 534 weight similarity edges
  language_model.model.layers.9.self_attn.o_proj.weight [5120 x 4096] layer=9 (sampling every 2 rows)
    -> 48 weight similarity edges
  language_model.model.layers.11.self_attn.o_proj.weight [5120 x 4096] layer=11 (sampling every 2 rows)
    -> 42 weight similarity edges
  language_model.model.layers.36.self_attn.o_proj.weight [5120 x 4096] layer=36 (sampling every 2 rows)
    -> 1526 weight similarity edges
  language_model.model.layers.12.self_attn.o_proj.weight [5120 x 4096] layer=12 (sampling every 2 rows)
    -> 54 weight similarity edges
  language_model.model.layers.7.self_attn.o_proj.weight [5120 x 4096] layer=7 (sampling every 2 rows)
    -> 34 weight similarity edges
  language_model.model.layers.8.self_attn.o_proj.weight [5120 x 4096] layer=8 (sampling every 2 rows)
    -> 53 weight similarity edges
  language_model.model.layers.13.self_attn.o_proj.weight [5120 x 4096] layer=13 (sampling every 2 rows)
    -> 82 weight similarity edges
  language_model.model.layers.14.self_attn.o_proj.weight [5120 x 4096] layer=14 (sampling every 2 rows)
    -> 30 weight similarity edges
  language_model.model.layers.15.self_attn.o_proj.weight [5120 x 4096] layer=15 (sampling every 2 rows)
    -> 23 weight similarity edges
  language_model.model.layers.16.self_attn.o_proj.weight [5120 x 4096] layer=16 (sampling every 2 rows)
    -> 16 weight similarity edges
  language_model.model.layers.19.self_attn.o_proj.weight [5120 x 4096] layer=19 (sampling every 2 rows)
    -> 25 weight similarity edges
  language_model.model.layers.20.self_attn.o_proj.weight [5120 x 4096] layer=20 (sampling every 2 rows)
    -> 31 weight similarity edges
  language_model.model.layers.21.self_attn.o_proj.weight [5120 x 4096] layer=21 (sampling every 2 rows)
    -> 21 weight similarity edges
  language_model.model.layers.23.self_attn.o_proj.weight [5120 x 4096] layer=23 (sampling every 2 rows)
    -> 39 weight similarity edges
  language_model.model.layers.24.self_attn.o_proj.weight [5120 x 4096] layer=24 (sampling every 2 rows)
    -> 7 weight similarity edges
  language_model.model.layers.3.self_attn.o_proj.weight [5120 x 4096] layer=3 (sampling every 2 rows)
    -> 95 weight similarity edges
  language_model.model.layers.6.self_attn.o_proj.weight [5120 x 4096] layer=6 (sampling every 2 rows)
    -> 54 weight similarity edges
  language_model.model.layers.29.self_attn.o_proj.weight [5120 x 4096] layer=29 (sampling every 2 rows)
    -> 14 weight similarity edges
  language_model.model.layers.30.self_attn.o_proj.weight [5120 x 4096] layer=30 (sampling every 2 rows)
    -> 11 weight similarity edges
  language_model.model.layers.32.self_attn.o_proj.weight [5120 x 4096] layer=32 (sampling every 2 rows)
    -> 18 weight similarity edges
  language_model.model.layers.33.self_attn.o_proj.weight [5120 x 4096] layer=33 (sampling every 2 rows)
    -> 14 weight similarity edges
  language_model.model.layers.34.self_attn.o_proj.weight [5120 x 4096] layer=34 (sampling every 2 rows)
    -> 24 weight similarity edges
  language_model.model.layers.35.self_attn.o_proj.weight [5120 x 4096] layer=35 (sampling every 2 rows)
    -> 233 weight similarity edges
  language_model.model.layers.37.self_attn.o_proj.weight [5120 x 4096] layer=37 (sampling every 2 rows)
    -> 961 weight similarity edges
[ATTN] Processing 64 gate_proj tensors
  language_model.model.layers.30.mlp.gate_proj.weight [32768 x 5120] layer=30 (sampling every 16 rows)
    -> 27 weight similarity edges
  language_model.model.layers.24.mlp.gate_proj.weight [32768 x 5120] layer=24 (sampling every 16 rows)
    -> 174 weight similarity edges
  language_model.model.layers.25.mlp.gate_proj.weight [32768 x 5120] layer=25 (sampling every 16 rows)
    -> 93 weight similarity edges
  language_model.model.layers.12.mlp.gate_proj.weight [32768 x 5120] layer=12 (sampling every 16 rows)
    -> 407 weight similarity edges
  language_model.model.layers.28.mlp.gate_proj.weight [32768 x 5120] layer=28 (sampling every 16 rows)
    -> 38 weight similarity edges
  language_model.model.layers.16.mlp.gate_proj.weight [32768 x 5120] layer=16 (sampling every 16 rows)
    -> 1038 weight similarity edges
  language_model.model.layers.26.mlp.gate_proj.weight [32768 x 5120] layer=26 (sampling every 16 rows)
    -> 94 weight similarity edges
  language_model.model.layers.29.mlp.gate_proj.weight [32768 x 5120] layer=29 (sampling every 16 rows)
    -> 57 weight similarity edges
  vision_tower.transformer.layers.17.feed_forward.gate_proj.weight [4096 x 1024] layer=17 (sampling every 2 rows)
    -> 6488 weight similarity edges
  language_model.model.layers.32.mlp.gate_proj.weight [32768 x 5120] layer=32 (sampling every 16 rows)
    -> 99 weight similarity edges
  language_model.model.layers.27.mlp.gate_proj.weight [32768 x 5120] layer=27 (sampling every 16 rows)
    -> 179 weight similarity edges
  vision_tower.transformer.layers.8.feed_forward.gate_proj.weight [4096 x 1024] layer=8 (sampling every 2 rows)
    -> 5645 weight similarity edges
  language_model.model.layers.37.mlp.gate_proj.weight [32768 x 5120] layer=37 (sampling every 16 rows)
    -> 1117 weight similarity edges
  language_model.model.layers.38.mlp.gate_proj.weight [32768 x 5120] layer=38 (sampling every 16 rows)
    -> 1516 weight similarity edges
  language_model.model.layers.7.mlp.gate_proj.weight [32768 x 5120] layer=7 (sampling every 16 rows)
    -> 303 weight similarity edges
  language_model.model.layers.39.mlp.gate_proj.weight [32768 x 5120] layer=39 (sampling every 16 rows)
    -> 1307 weight similarity edges
  vision_tower.transformer.layers.0.feed_forward.gate_proj.weight [4096 x 1024] layer=0 (sampling every 2 rows)
    -> 6605 weight similarity edges
  language_model.model.layers.0.mlp.gate_proj.weight [32768 x 5120] layer=0 (sampling every 16 rows)
    -> 957 weight similarity edges
  language_model.model.layers.1.mlp.gate_proj.weight [32768 x 5120] layer=1 (sampling every 16 rows)
    -> 1763 weight similarity edges
  language_model.model.layers.2.mlp.gate_proj.weight [32768 x 5120] layer=2 (sampling every 16 rows)
    -> 192 weight similarity edges
  vision_tower.transformer.layers.15.feed_forward.gate_proj.weight [4096 x 1024] layer=15 (sampling every 2 rows)
    -> 6553 weight similarity edges
  language_model.model.layers.5.mlp.gate_proj.weight [32768 x 5120] layer=5 (sampling every 16 rows)
    -> 176 weight similarity edges
  vision_tower.transformer.layers.1.feed_forward.gate_proj.weight [4096 x 1024] layer=1 (sampling every 2 rows)
    -> 8240 weight similarity edges
  vision_tower.transformer.layers.10.feed_forward.gate_proj.weight [4096 x 1024] layer=10 (sampling every 2 rows)
    -> 7299 weight similarity edges
  vision_tower.transformer.layers.11.feed_forward.gate_proj.weight [4096 x 1024] layer=11 (sampling every 2 rows)
    -> 7419 weight similarity edges
  vision_tower.transformer.layers.12.feed_forward.gate_proj.weight [4096 x 1024] layer=12 (sampling every 2 rows)
    -> 7323 weight similarity edges
  vision_tower.transformer.layers.13.feed_forward.gate_proj.weight [4096 x 1024] layer=13 (sampling every 2 rows)
    -> 7052 weight similarity edges
  language_model.model.layers.13.mlp.gate_proj.weight [32768 x 5120] layer=13 (sampling every 16 rows)
    -> 514 weight similarity edges
  vision_tower.transformer.layers.14.feed_forward.gate_proj.weight [4096 x 1024] layer=14 (sampling every 2 rows)
    -> 6526 weight similarity edges
  vision_tower.transformer.layers.16.feed_forward.gate_proj.weight [4096 x 1024] layer=16 (sampling every 2 rows)
    -> 6167 weight similarity edges
  vision_tower.transformer.layers.18.feed_forward.gate_proj.weight [4096 x 1024] layer=18 (sampling every 2 rows)
    -> 7886 weight similarity edges
  language_model.model.layers.35.mlp.gate_proj.weight [32768 x 5120] layer=35 (sampling every 16 rows)
    -> 632 weight similarity edges
  vision_tower.transformer.layers.19.feed_forward.gate_proj.weight [4096 x 1024] layer=19 (sampling every 2 rows)
    -> 8263 weight similarity edges
  vision_tower.transformer.layers.7.feed_forward.gate_proj.weight [4096 x 1024] layer=7 (sampling every 2 rows)
    -> 4373 weight similarity edges
  vision_tower.transformer.layers.21.feed_forward.gate_proj.weight [4096 x 1024] layer=21 (sampling every 2 rows)
    -> 10412 weight similarity edges
  vision_tower.transformer.layers.2.feed_forward.gate_proj.weight [4096 x 1024] layer=2 (sampling every 2 rows)
    -> 6966 weight similarity edges
  language_model.model.layers.8.mlp.gate_proj.weight [32768 x 5120] layer=8 (sampling every 16 rows)
    -> 463 weight similarity edges
  vision_tower.transformer.layers.6.feed_forward.gate_proj.weight [4096 x 1024] layer=6 (sampling every 2 rows)
    -> 4075 weight similarity edges
  vision_tower.transformer.layers.20.feed_forward.gate_proj.weight [4096 x 1024] layer=20 (sampling every 2 rows)
    -> 9221 weight similarity edges
  language_model.model.layers.14.mlp.gate_proj.weight [32768 x 5120] layer=14 (sampling every 16 rows)
    -> 650 weight similarity edges
  language_model.model.layers.18.mlp.gate_proj.weight [32768 x 5120] layer=18 (sampling every 16 rows)
    -> 731 weight similarity edges
  vision_tower.transformer.layers.22.feed_forward.gate_proj.weight [4096 x 1024] layer=22 (sampling every 2 rows)
    -> 8195 weight similarity edges
  language_model.model.layers.3.mlp.gate_proj.weight [32768 x 5120] layer=3 (sampling every 16 rows)
    -> 489 weight similarity edges
  vision_tower.transformer.layers.4.feed_forward.gate_proj.weight [4096 x 1024] layer=4 (sampling every 2 rows)
    -> 3661 weight similarity edges
  vision_tower.transformer.layers.5.feed_forward.gate_proj.weight [4096 x 1024] layer=5 (sampling every 2 rows)
    -> 4442 weight similarity edges
  vision_tower.transformer.layers.23.feed_forward.gate_proj.weight [4096 x 1024] layer=23 (sampling every 2 rows)
    -> 2911 weight similarity edges
  language_model.model.layers.6.mlp.gate_proj.weight [32768 x 5120] layer=6 (sampling every 16 rows)
    -> 152 weight similarity edges
  vision_tower.transformer.layers.3.feed_forward.gate_proj.weight [4096 x 1024] layer=3 (sampling every 2 rows)
    -> 5379 weight similarity edges
  vision_tower.transformer.layers.9.feed_forward.gate_proj.weight [4096 x 1024] layer=9 (sampling every 2 rows)
    -> 7345 weight similarity edges
  language_model.model.layers.22.mlp.gate_proj.weight [32768 x 5120] layer=22 (sampling every 16 rows)
    -> 240 weight similarity edges
  language_model.model.layers.10.mlp.gate_proj.weight [32768 x 5120] layer=10 (sampling every 16 rows)
    -> 287 weight similarity edges
  language_model.model.layers.4.mlp.gate_proj.weight [32768 x 5120] layer=4 (sampling every 16 rows)
    -> 200 weight similarity edges
  language_model.model.layers.9.mlp.gate_proj.weight [32768 x 5120] layer=9 (sampling every 16 rows)
    -> 192 weight similarity edges
  language_model.model.layers.11.mlp.gate_proj.weight [32768 x 5120] layer=11 (sampling every 16 rows)
    -> 313 weight similarity edges
  language_model.model.layers.15.mlp.gate_proj.weight [32768 x 5120] layer=15 (sampling every 16 rows)
    -> 1179 weight similarity edges
  language_model.model.layers.17.mlp.gate_proj.weight [32768 x 5120] layer=17 (sampling every 16 rows)
    -> 1027 weight similarity edges
  language_model.model.layers.19.mlp.gate_proj.weight [32768 x 5120] layer=19 (sampling every 16 rows)
    -> 499 weight similarity edges
  language_model.model.layers.20.mlp.gate_proj.weight [32768 x 5120] layer=20 (sampling every 16 rows)
    -> 298 weight similarity edges
  language_model.model.layers.21.mlp.gate_proj.weight [32768 x 5120] layer=21 (sampling every 16 rows)
    -> 275 weight similarity edges
  language_model.model.layers.23.mlp.gate_proj.weight [32768 x 5120] layer=23 (sampling every 16 rows)
    -> 201 weight similarity edges
  language_model.model.layers.31.mlp.gate_proj.weight [32768 x 5120] layer=31 (sampling every 16 rows)
    -> 54 weight similarity edges
  language_model.model.layers.33.mlp.gate_proj.weight [32768 x 5120] layer=33 (sampling every 16 rows)
    -> 112 weight similarity edges
  language_model.model.layers.34.mlp.gate_proj.weight [32768 x 5120] layer=34 (sampling every 16 rows)
    -> 287 weight similarity edges
  language_model.model.layers.36.mlp.gate_proj.weight [32768 x 5120] layer=36 (sampling every 16 rows)
    -> 1113 weight similarity edges
[ATTN] Processing 64 up_proj tensors
  language_model.model.layers.24.mlp.up_proj.weight [32768 x 5120] layer=24 (sampling every 16 rows)
    -> 30 weight similarity edges
  vision_tower.transformer.layers.10.feed_forward.up_proj.weight [4096 x 1024] layer=10 (sampling every 2 rows)
    -> 2968 weight similarity edges
  language_model.model.layers.25.mlp.up_proj.weight [32768 x 5120] layer=25 (sampling every 16 rows)
    -> 10 weight similarity edges
  language_model.model.layers.26.mlp.up_proj.weight [32768 x 5120] layer=26 (sampling every 16 rows)
    -> 20 weight similarity edges
  language_model.model.layers.1.mlp.up_proj.weight [32768 x 5120] layer=1 (sampling every 16 rows)
    -> 26 weight similarity edges
  language_model.model.layers.28.mlp.up_proj.weight [32768 x 5120] layer=28 (sampling every 16 rows)
    -> 13 weight similarity edges
  language_model.model.layers.27.mlp.up_proj.weight [32768 x 5120] layer=27 (sampling every 16 rows)
    -> 46 weight similarity edges
  language_model.model.layers.10.mlp.up_proj.weight [32768 x 5120] layer=10 (sampling every 16 rows)
    -> 29 weight similarity edges
  language_model.model.layers.37.mlp.up_proj.weight [32768 x 5120] layer=37 (sampling every 16 rows)
    -> 460 weight similarity edges
  language_model.model.layers.31.mlp.up_proj.weight [32768 x 5120] layer=31 (sampling every 16 rows)
    -> 12 weight similarity edges
  language_model.model.layers.38.mlp.up_proj.weight [32768 x 5120] layer=38 (sampling every 16 rows)
    -> 1253 weight similarity edges
  vision_tower.transformer.layers.18.feed_forward.up_proj.weight [4096 x 1024] layer=18 (sampling every 2 rows)
    -> 237 weight similarity edges
  language_model.model.layers.39.mlp.up_proj.weight [32768 x 5120] layer=39 (sampling every 16 rows)
    -> 1861 weight similarity edges
  vision_tower.transformer.layers.11.feed_forward.up_proj.weight [4096 x 1024] layer=11 (sampling every 2 rows)
    -> 2649 weight similarity edges
  language_model.model.layers.36.mlp.up_proj.weight [32768 x 5120] layer=36 (sampling every 16 rows)
    -> 444 weight similarity edges
  language_model.model.layers.11.mlp.up_proj.weight [32768 x 5120] layer=11 (sampling every 16 rows)
    -> 27 weight similarity edges
  language_model.model.layers.0.mlp.up_proj.weight [32768 x 5120] layer=0 (sampling every 16 rows)
    -> 294 weight similarity edges
  language_model.model.layers.8.mlp.up_proj.weight [32768 x 5120] layer=8 (sampling every 16 rows)
    -> 33 weight similarity edges
  language_model.model.layers.14.mlp.up_proj.weight [32768 x 5120] layer=14 (sampling every 16 rows)
    -> 71 weight similarity edges
  vision_tower.transformer.layers.0.feed_forward.up_proj.weight [4096 x 1024] layer=0 (sampling every 2 rows)
    -> 6907 weight similarity edges
  vision_tower.transformer.layers.5.feed_forward.up_proj.weight [4096 x 1024] layer=5 (sampling every 2 rows)
    -> 3507 weight similarity edges
  vision_tower.transformer.layers.23.feed_forward.up_proj.weight [4096 x 1024] layer=23 (sampling every 2 rows)
    -> 674 weight similarity edges
  vision_tower.transformer.layers.1.feed_forward.up_proj.weight [4096 x 1024] layer=1 (sampling every 2 rows)
    -> 7799 weight similarity edges
  language_model.model.layers.4.mlp.up_proj.weight [32768 x 5120] layer=4 (sampling every 16 rows)
    -> 25 weight similarity edges
  vision_tower.transformer.layers.12.feed_forward.up_proj.weight [4096 x 1024] layer=12 (sampling every 2 rows)
    -> 2167 weight similarity edges
  vision_tower.transformer.layers.13.feed_forward.up_proj.weight [4096 x 1024] layer=13 (sampling every 2 rows)
    -> 1709 weight similarity edges
  language_model.model.layers.18.mlp.up_proj.weight [32768 x 5120] layer=18 (sampling every 16 rows)
    -> 120 weight similarity edges
  vision_tower.transformer.layers.14.feed_forward.up_proj.weight [4096 x 1024] layer=14 (sampling every 2 rows)
    -> 1565 weight similarity edges
  vision_tower.transformer.layers.15.feed_forward.up_proj.weight [4096 x 1024] layer=15 (sampling every 2 rows)
    -> 1234 weight similarity edges
  language_model.model.layers.5.mlp.up_proj.weight [32768 x 5120] layer=5 (sampling every 16 rows)
    -> 32 weight similarity edges
  vision_tower.transformer.layers.16.feed_forward.up_proj.weight [4096 x 1024] layer=16 (sampling every 2 rows)
    -> 671 weight similarity edges
  language_model.model.layers.32.mlp.up_proj.weight [32768 x 5120] layer=32 (sampling every 16 rows)
    -> 38 weight similarity edges
  vision_tower.transformer.layers.17.feed_forward.up_proj.weight [4096 x 1024] layer=17 (sampling every 2 rows)
    -> 269 weight similarity edges
  vision_tower.transformer.layers.3.feed_forward.up_proj.weight [4096 x 1024] layer=3 (sampling every 2 rows)
    -> 4646 weight similarity edges
  vision_tower.transformer.layers.19.feed_forward.up_proj.weight [4096 x 1024] layer=19 (sampling every 2 rows)
    -> 282 weight similarity edges
  vision_tower.transformer.layers.2.feed_forward.up_proj.weight [4096 x 1024] layer=2 (sampling every 2 rows)
    -> 6334 weight similarity edges
  language_model.model.layers.16.mlp.up_proj.weight [32768 x 5120] layer=16 (sampling every 16 rows)
    -> 194 weight similarity edges
  language_model.model.layers.34.mlp.up_proj.weight [32768 x 5120] layer=34 (sampling every 16 rows)
    -> 89 weight similarity edges
  language_model.model.layers.19.mlp.up_proj.weight [32768 x 5120] layer=19 (sampling every 16 rows)
    -> 48 weight similarity edges
  vision_tower.transformer.layers.20.feed_forward.up_proj.weight [4096 x 1024] layer=20 (sampling every 2 rows)
    -> 139 weight similarity edges
  vision_tower.transformer.layers.6.feed_forward.up_proj.weight [4096 x 1024] layer=6 (sampling every 2 rows)
    -> 3236 weight similarity edges
  language_model.model.layers.33.mlp.up_proj.weight [32768 x 5120] layer=33 (sampling every 16 rows)
    -> 18 weight similarity edges
  vision_tower.transformer.layers.7.feed_forward.up_proj.weight [4096 x 1024] layer=7 (sampling every 2 rows)
    -> 2927 weight similarity edges
  vision_tower.transformer.layers.21.feed_forward.up_proj.weight [4096 x 1024] layer=21 (sampling every 2 rows)
    -> 264 weight similarity edges
  vision_tower.transformer.layers.22.feed_forward.up_proj.weight [4096 x 1024] layer=22 (sampling every 2 rows)
    -> 378 weight similarity edges
  language_model.model.layers.3.mlp.up_proj.weight [32768 x 5120] layer=3 (sampling every 16 rows)
    -> 26 weight similarity edges
  vision_tower.transformer.layers.4.feed_forward.up_proj.weight [4096 x 1024] layer=4 (sampling every 2 rows)
    -> 2958 weight similarity edges
  vision_tower.transformer.layers.8.feed_forward.up_proj.weight [4096 x 1024] layer=8 (sampling every 2 rows)
    -> 3545 weight similarity edges
  language_model.model.layers.7.mlp.up_proj.weight [32768 x 5120] layer=7 (sampling every 16 rows)
    -> 34 weight similarity edges
  vision_tower.transformer.layers.9.feed_forward.up_proj.weight [4096 x 1024] layer=9 (sampling every 2 rows)
    -> 4417 weight similarity edges
  language_model.model.layers.22.mlp.up_proj.weight [32768 x 5120] layer=22 (sampling every 16 rows)
    -> 50 weight similarity edges
  language_model.model.layers.6.mlp.up_proj.weight [32768 x 5120] layer=6 (sampling every 16 rows)
    -> 21 weight similarity edges
  language_model.model.layers.9.mlp.up_proj.weight [32768 x 5120] layer=9 (sampling every 16 rows)
    -> 12 weight similarity edges
  language_model.model.layers.12.mlp.up_proj.weight [32768 x 5120] layer=12 (sampling every 16 rows)
    -> 37 weight similarity edges
  language_model.model.layers.13.mlp.up_proj.weight [32768 x 5120] layer=13 (sampling every 16 rows)
    -> 85 weight similarity edges
  language_model.model.layers.15.mlp.up_proj.weight [32768 x 5120] layer=15 (sampling every 16 rows)
    -> 102 weight similarity edges
  language_model.model.layers.17.mlp.up_proj.weight [32768 x 5120] layer=17 (sampling every 16 rows)
    -> 147 weight similarity edges
  language_model.model.layers.20.mlp.up_proj.weight [32768 x 5120] layer=20 (sampling every 16 rows)
    -> 20 weight similarity edges
  language_model.model.layers.21.mlp.up_proj.weight [32768 x 5120] layer=21 (sampling every 16 rows)
    -> 29 weight similarity edges
  language_model.model.layers.23.mlp.up_proj.weight [32768 x 5120] layer=23 (sampling every 16 rows)
    -> 39 weight similarity edges
  language_model.model.layers.2.mlp.up_proj.weight [32768 x 5120] layer=2 (sampling every 16 rows)
    -> 40 weight similarity edges
  language_model.model.layers.29.mlp.up_proj.weight [32768 x 5120] layer=29 (sampling every 16 rows)
    -> 30 weight similarity edges
  language_model.model.layers.30.mlp.up_proj.weight [32768 x 5120] layer=30 (sampling every 16 rows)
    -> 6 weight similarity edges
  language_model.model.layers.35.mlp.up_proj.weight [32768 x 5120] layer=35 (sampling every 16 rows)
    -> 170 weight similarity edges
[ATTN] Processing 64 down_proj tensors
  language_model.model.layers.24.mlp.down_proj.weight [5120 x 32768] layer=24 (sampling every 2 rows)
    -> 14 weight similarity edges
  vision_tower.transformer.layers.18.feed_forward.down_proj.weight [1024 x 4096] layer=18
    -> 9 weight similarity edges
  language_model.model.layers.25.mlp.down_proj.weight [5120 x 32768] layer=25 (sampling every 2 rows)
    -> 18 weight similarity edges
  language_model.model.layers.26.mlp.down_proj.weight [5120 x 32768] layer=26 (sampling every 2 rows)
    -> 20 weight similarity edges
  vision_tower.transformer.layers.9.feed_forward.down_proj.weight [1024 x 4096] layer=9
    -> 56 weight similarity edges
  language_model.model.layers.22.mlp.down_proj.weight [5120 x 32768] layer=22 (sampling every 2 rows)
    -> 22 weight similarity edges
  language_model.model.layers.27.mlp.down_proj.weight [5120 x 32768] layer=27 (sampling every 2 rows)
    -> 12 weight similarity edges
  language_model.model.layers.38.mlp.down_proj.weight [5120 x 32768] layer=38 (sampling every 2 rows)
    -> 185 weight similarity edges
  language_model.model.layers.37.mlp.down_proj.weight [5120 x 32768] layer=37 (sampling every 2 rows)
    -> 82 weight similarity edges
  language_model.model.layers.39.mlp.down_proj.weight [5120 x 32768] layer=39 (sampling every 2 rows)
    -> 56 weight similarity edges
  language_model.model.layers.18.mlp.down_proj.weight [5120 x 32768] layer=18 (sampling every 2 rows)
    -> 68 weight similarity edges
  language_model.model.layers.0.mlp.down_proj.weight [5120 x 32768] layer=0 (sampling every 2 rows)
    -> 25 weight similarity edges
  language_model.model.layers.1.mlp.down_proj.weight [5120 x 32768] layer=1 (sampling every 2 rows)
    -> 9 weight similarity edges
  language_model.model.layers.19.mlp.down_proj.weight [5120 x 32768] layer=19 (sampling every 2 rows)
    -> 77 weight similarity edges
  vision_tower.transformer.layers.6.feed_forward.down_proj.weight [1024 x 4096] layer=6
    -> 114 weight similarity edges
  vision_tower.transformer.layers.20.feed_forward.down_proj.weight [1024 x 4096] layer=20
    -> 13 weight similarity edges
  language_model.model.layers.9.mlp.down_proj.weight [5120 x 32768] layer=9 (sampling every 2 rows)
    -> 14 weight similarity edges
  language_model.model.layers.20.mlp.down_proj.weight [5120 x 32768] layer=20 (sampling every 2 rows)
    -> 69 weight similarity edges
  vision_tower.transformer.layers.0.feed_forward.down_proj.weight [1024 x 4096] layer=0
    -> 2246 weight similarity edges
  vision_tower.transformer.layers.1.feed_forward.down_proj.weight [1024 x 4096] layer=1
    -> 577 weight similarity edges
  vision_tower.transformer.layers.10.feed_forward.down_proj.weight [1024 x 4096] layer=10
    -> 47 weight similarity edges
  vision_tower.transformer.layers.11.feed_forward.down_proj.weight [1024 x 4096] layer=11
    -> 36 weight similarity edges
  vision_tower.transformer.layers.12.feed_forward.down_proj.weight [1024 x 4096] layer=12
    -> 28 weight similarity edges
  language_model.model.layers.23.mlp.down_proj.weight [5120 x 32768] layer=23 (sampling every 2 rows)
    -> 13 weight similarity edges
  vision_tower.transformer.layers.13.feed_forward.down_proj.weight [1024 x 4096] layer=13
    -> 12 weight similarity edges
  vision_tower.transformer.layers.14.feed_forward.down_proj.weight [1024 x 4096] layer=14
    -> 12 weight similarity edges
  vision_tower.transformer.layers.15.feed_forward.down_proj.weight [1024 x 4096] layer=15
    -> 7 weight similarity edges
  language_model.model.layers.5.mlp.down_proj.weight [5120 x 32768] layer=5 (sampling every 2 rows)
    -> 5 weight similarity edges
  vision_tower.transformer.layers.16.feed_forward.down_proj.weight [1024 x 4096] layer=16
    -> 13 weight similarity edges
  language_model.model.layers.21.mlp.down_proj.weight [5120 x 32768] layer=21 (sampling every 2 rows)
    -> 19 weight similarity edges
  language_model.model.layers.11.mlp.down_proj.weight [5120 x 32768] layer=11 (sampling every 2 rows)
    -> 20 weight similarity edges
  vision_tower.transformer.layers.17.feed_forward.down_proj.weight [1024 x 4096] layer=17
    -> 9 weight similarity edges
  vision_tower.transformer.layers.19.feed_forward.down_proj.weight [1024 x 4096] layer=19
    -> 10 weight similarity edges
  vision_tower.transformer.layers.2.feed_forward.down_proj.weight [1024 x 4096] layer=2
    -> 297 weight similarity edges
  vision_tower.transformer.layers.21.feed_forward.down_proj.weight [1024 x 4096] layer=21
    -> 26 weight similarity edges
  vision_tower.transformer.layers.7.feed_forward.down_proj.weight [1024 x 4096] layer=7
    -> 106 weight similarity edges
  vision_tower.transformer.layers.22.feed_forward.down_proj.weight [1024 x 4096] layer=22
    -> 51 weight similarity edges
  language_model.model.layers.3.mlp.down_proj.weight [5120 x 32768] layer=3 (sampling every 2 rows)
    -> 4 weight similarity edges
  vision_tower.transformer.layers.4.feed_forward.down_proj.weight [1024 x 4096] layer=4
    -> 150 weight similarity edges
  language_model.model.layers.12.mlp.down_proj.weight [5120 x 32768] layer=12 (sampling every 2 rows)
    -> 11 weight similarity edges
  vision_tower.transformer.layers.5.feed_forward.down_proj.weight [1024 x 4096] layer=5
    -> 151 weight similarity edges
  vision_tower.transformer.layers.23.feed_forward.down_proj.weight [1024 x 4096] layer=23
    -> 185 weight similarity edges
  language_model.model.layers.29.mlp.down_proj.weight [5120 x 32768] layer=29 (sampling every 2 rows)
    -> 10 weight similarity edges
  vision_tower.transformer.layers.3.feed_forward.down_proj.weight [1024 x 4096] layer=3
    -> 283 weight similarity edges
  vision_tower.transformer.layers.8.feed_forward.down_proj.weight [1024 x 4096] layer=8
    -> 79 weight similarity edges
  language_model.model.layers.10.mlp.down_proj.weight [5120 x 32768] layer=10 (sampling every 2 rows)
    -> 22 weight similarity edges
  language_model.model.layers.6.mlp.down_proj.weight [5120 x 32768] layer=6 (sampling every 2 rows)
    -> 4 weight similarity edges
  language_model.model.layers.7.mlp.down_proj.weight [5120 x 32768] layer=7 (sampling every 2 rows)
    -> 7 weight similarity edges
  language_model.model.layers.8.mlp.down_proj.weight [5120 x 32768] layer=8 (sampling every 2 rows)
    -> 9 weight similarity edges
  language_model.model.layers.13.mlp.down_proj.weight [5120 x 32768] layer=13 (sampling every 2 rows)
    -> 14 weight similarity edges
  language_model.model.layers.14.mlp.down_proj.weight [5120 x 32768] layer=14 (sampling every 2 rows)
    -> 25 weight similarity edges
  language_model.model.layers.2.mlp.down_proj.weight [5120 x 32768] layer=2 (sampling every 2 rows)
    -> 35 weight similarity edges
  language_model.model.layers.15.mlp.down_proj.weight [5120 x 32768] layer=15 (sampling every 2 rows)
    -> 39 weight similarity edges
  language_model.model.layers.16.mlp.down_proj.weight [5120 x 32768] layer=16 (sampling every 2 rows)
    -> 74 weight similarity edges
  language_model.model.layers.17.mlp.down_proj.weight [5120 x 32768] layer=17 (sampling every 2 rows)
    -> 88 weight similarity edges
  language_model.model.layers.4.mlp.down_proj.weight [5120 x 32768] layer=4 (sampling every 2 rows)
    -> 4 weight similarity edges
  language_model.model.layers.28.mlp.down_proj.weight [5120 x 32768] layer=28 (sampling every 2 rows)
    -> 20 weight similarity edges
  language_model.model.layers.30.mlp.down_proj.weight [5120 x 32768] layer=30 (sampling every 2 rows)
    -> 18 weight similarity edges
  language_model.model.layers.31.mlp.down_proj.weight [5120 x 32768] layer=31 (sampling every 2 rows)
    -> 10 weight similarity edges
  language_model.model.layers.32.mlp.down_proj.weight [5120 x 32768] layer=32 (sampling every 2 rows)
    -> 12 weight similarity edges
  language_model.model.layers.33.mlp.down_proj.weight [5120 x 32768] layer=33 (sampling every 2 rows)
    -> 32 weight similarity edges
  language_model.model.layers.34.mlp.down_proj.weight [5120 x 32768] layer=34 (sampling every 2 rows)
    -> 73 weight similarity edges
  language_model.model.layers.35.mlp.down_proj.weight [5120 x 32768] layer=35 (sampling every 2 rows)
    -> 198 weight similarity edges
  language_model.model.layers.36.mlp.down_proj.weight [5120 x 32768] layer=36 (sampling every 2 rows)
    -> 194 weight similarity edges
[ATTN] Processing 1 lm_head tensors
  language_model.lm_head.weight [131072 x 5120] layer=-1 (sampling every 64 rows)
    -> 802 weight similarity edges

[TOKEN-DIM] Extracting token->dimension activation patterns...

[EXTRACT] Total: 797850 relation edges from model weights

=== Complete ===
Total time: 1005 seconds
Tensors: 585
BPE merges: 0
Vocab: 0 tokens
