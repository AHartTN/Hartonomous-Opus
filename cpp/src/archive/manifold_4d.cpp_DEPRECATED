// =============================================================================
// Manifold Projection: N-Dimensional Embeddings -> 4D Hypercube Coordinates
// =============================================================================
// Implements Laplacian Eigenmaps with Gram-Schmidt orthonormalization
// to project high-dimensional embeddings (384D from MiniLM, etc.) into the
// 4D hypercube coordinate space.
//
// Algorithm:
// 1. Build k-NN similarity graph from embeddings (adjacency matrix W)
// 2. Compute degree matrix D and graph Laplacian L = D - W
// 3. Use power iteration to find the 4 smallest non-trivial eigenvectors
// 4. Apply Gram-Schmidt to orthonormalize the eigenvectors
// 5. Project each embedding onto these 4 basis vectors
// 6. Scale to integer coordinates for Hilbert indexing
//
// References:
// - Belkin & Niyogi, "Laplacian Eigenmaps for Dimensionality Reduction", 2003
// - Johnson-Lindenstrauss lemma for theoretical bounds
// =============================================================================

#include <iostream>
#include <fstream>
#include <sstream>
#include <vector>
#include <array>
#include <cmath>
#include <algorithm>
#include <random>
#include <chrono>
#include <thread>
#include <atomic>
#include <mutex>
#include <queue>
#include <unordered_map>
#include <cstring>

#ifdef _WIN32
#define NOMINMAX
#include <winsock2.h>
#pragma comment(lib, "ws2_32.lib")
#endif

#include <libpq-fe.h>

// =============================================================================
// Configuration
// =============================================================================

struct Config {
    std::string db_conn = "host=hart-server port=5432 dbname=hypercube user=postgres password=postgres";
    std::string model_name = "minilm";
    int k_neighbors = 15;           // k for k-NN graph
    int target_dims = 4;            // Output dimensionality (4D)
    int power_iterations = 100;     // Iterations for power method
    int batch_size = 1000;
    int num_threads = 0;            // 0 = auto
    double similarity_threshold = 0.3;  // Min similarity for edge
    int32_t coord_scale = 2147483647;   // Scale to int32 range
};

// =============================================================================
// Data Structures  
// =============================================================================

struct Embedding {
    std::vector<uint8_t> entity_id;  // BYTEA
    std::vector<float> values;
};

struct Edge {
    size_t from;
    size_t to;
    float weight;
};

struct Projection4D {
    int32_t x, y, z, m;
};

// =============================================================================
// SIMD-Optimized Vector Math Utilities
// =============================================================================
// Uses AVX2/AVX-512 when available, falls back to scalar

#if defined(__AVX512F__)
#include <immintrin.h>
#define SIMD_WIDTH 16
#define SIMD_ENABLED 1
#elif defined(__AVX2__) || defined(__AVX__)
#include <immintrin.h>
#define SIMD_WIDTH 8
#define SIMD_ENABLED 1
#elif defined(_MSC_VER) && (defined(_M_X64) || defined(_M_IX86))
#include <intrin.h>
#define SIMD_WIDTH 8
#define SIMD_ENABLED 1
#else
#define SIMD_WIDTH 1
#define SIMD_ENABLED 0
#endif

// SIMD dot product - processes 8 floats at a time with AVX
static float dot_product_simd(const float* a, const float* b, size_t n) {
#if SIMD_ENABLED && SIMD_WIDTH >= 8
    __m256 sum_vec = _mm256_setzero_ps();
    size_t i = 0;
    
    // Process 8 elements at a time
    for (; i + 8 <= n; i += 8) {
        __m256 va = _mm256_loadu_ps(a + i);
        __m256 vb = _mm256_loadu_ps(b + i);
        sum_vec = _mm256_fmadd_ps(va, vb, sum_vec);
    }
    
    // Horizontal sum of 8 floats
    __m128 hi = _mm256_extractf128_ps(sum_vec, 1);
    __m128 lo = _mm256_castps256_ps128(sum_vec);
    __m128 sum128 = _mm_add_ps(hi, lo);
    sum128 = _mm_hadd_ps(sum128, sum128);
    sum128 = _mm_hadd_ps(sum128, sum128);
    float sum = _mm_cvtss_f32(sum128);
    
    // Handle remaining elements
    for (; i < n; ++i) {
        sum += a[i] * b[i];
    }
    return sum;
#else
    float sum = 0.0f;
    for (size_t i = 0; i < n; ++i) {
        sum += a[i] * b[i];
    }
    return sum;
#endif
}

static float dot_product(const std::vector<float>& a, const std::vector<float>& b) {
    size_t n = std::min(a.size(), b.size());
    return dot_product_simd(a.data(), b.data(), n);
}

static float vector_norm(const std::vector<float>& v) {
    return std::sqrt(dot_product_simd(v.data(), v.data(), v.size()));
}

static void vector_normalize(std::vector<float>& v) {
    float norm = vector_norm(v);
    if (norm > 1e-10f) {
        float inv_norm = 1.0f / norm;
#if SIMD_ENABLED && SIMD_WIDTH >= 8
        __m256 inv_vec = _mm256_set1_ps(inv_norm);
        size_t i = 0;
        for (; i + 8 <= v.size(); i += 8) {
            __m256 vv = _mm256_loadu_ps(&v[i]);
            vv = _mm256_mul_ps(vv, inv_vec);
            _mm256_storeu_ps(&v[i], vv);
        }
        for (; i < v.size(); ++i) v[i] *= inv_norm;
#else
        for (auto& x : v) x *= inv_norm;
#endif
    }
}

static void vector_subtract(std::vector<float>& a, const std::vector<float>& b, float scale) {
#if SIMD_ENABLED && SIMD_WIDTH >= 8
    __m256 scale_vec = _mm256_set1_ps(scale);
    size_t i = 0;
    size_t n = std::min(a.size(), b.size());
    for (; i + 8 <= n; i += 8) {
        __m256 va = _mm256_loadu_ps(&a[i]);
        __m256 vb = _mm256_loadu_ps(&b[i]);
        va = _mm256_fnmadd_ps(vb, scale_vec, va);  // a - scale*b
        _mm256_storeu_ps(&a[i], va);
    }
    for (; i < n; ++i) a[i] -= scale * b[i];
#else
    for (size_t i = 0; i < a.size() && i < b.size(); ++i) {
        a[i] -= scale * b[i];
    }
#endif
}

// Optimized cosine similarity using SIMD
static float cosine_similarity(const std::vector<float>& a, const std::vector<float>& b) {
    size_t n = std::min(a.size(), b.size());
    
#if SIMD_ENABLED && SIMD_WIDTH >= 8
    __m256 dot_vec = _mm256_setzero_ps();
    __m256 na_vec = _mm256_setzero_ps();
    __m256 nb_vec = _mm256_setzero_ps();
    size_t i = 0;
    
    for (; i + 8 <= n; i += 8) {
        __m256 va = _mm256_loadu_ps(&a[i]);
        __m256 vb = _mm256_loadu_ps(&b[i]);
        dot_vec = _mm256_fmadd_ps(va, vb, dot_vec);
        na_vec = _mm256_fmadd_ps(va, va, na_vec);
        nb_vec = _mm256_fmadd_ps(vb, vb, nb_vec);
    }
    
    // Horizontal sums
    auto hsum = [](__m256 v) {
        __m128 hi = _mm256_extractf128_ps(v, 1);
        __m128 lo = _mm256_castps256_ps128(v);
        __m128 sum = _mm_add_ps(hi, lo);
        sum = _mm_hadd_ps(sum, sum);
        sum = _mm_hadd_ps(sum, sum);
        return _mm_cvtss_f32(sum);
    };
    
    float dot = hsum(dot_vec);
    float na = hsum(na_vec);
    float nb = hsum(nb_vec);
    
    // Handle remaining elements
    for (; i < n; ++i) {
        dot += a[i] * b[i];
        na += a[i] * a[i];
        nb += b[i] * b[i];
    }
#else
    float dot = 0.0f, na = 0.0f, nb = 0.0f;
    for (size_t i = 0; i < n; ++i) {
        dot += a[i] * b[i];
        na += a[i] * a[i];
        nb += b[i] * b[i];
    }
#endif
    
    float denom = std::sqrt(na) * std::sqrt(nb);
    return (denom > 1e-10f) ? (dot / denom) : 0.0f;
}

// =============================================================================
// Gram-Schmidt Orthonormalization
// =============================================================================
// Given a set of vectors, make them orthonormal
// Each vector is projected onto the span of previous vectors and subtracted

static void gram_schmidt(std::vector<std::vector<float>>& vectors) {
    for (size_t i = 0; i < vectors.size(); ++i) {
        // Subtract projections onto all previous vectors
        for (size_t j = 0; j < i; ++j) {
            float proj = dot_product(vectors[i], vectors[j]);
            vector_subtract(vectors[i], vectors[j], proj);
        }
        // Normalize
        vector_normalize(vectors[i]);
    }
}

// =============================================================================
// Power Iteration for Eigenvector Computation
// =============================================================================
// Finds the largest eigenvector of a matrix defined by the Laplacian
// We use the inverse power method to find smallest eigenvalues (skip first)

class LaplacianEigensolver {
public:
    LaplacianEigensolver(const std::vector<Embedding>& embeddings, 
                         const std::vector<Edge>& edges,
                         size_t n_nodes)
        : n(n_nodes), degree(n, 0.0f) 
    {
        // Build adjacency list
        adj.resize(n);
        for (const auto& e : edges) {
            if (e.from < n && e.to < n) {
                adj[e.from].push_back({e.to, e.weight});
                adj[e.to].push_back({e.from, e.weight});
                degree[e.from] += e.weight;
                degree[e.to] += e.weight;
            }
        }
        
        // Compute D^(-1/2)
        d_inv_sqrt.resize(n);
        for (size_t i = 0; i < n; ++i) {
            d_inv_sqrt[i] = (degree[i] > 1e-10f) ? (1.0f / std::sqrt(degree[i])) : 0.0f;
        }
    }
    
    // Compute L_norm * v where L_norm = I - D^(-1/2) * W * D^(-1/2)
    std::vector<float> apply_normalized_laplacian(const std::vector<float>& v) {
        std::vector<float> result(n, 0.0f);
        
        for (size_t i = 0; i < n; ++i) {
            // Diagonal: v[i]
            result[i] = v[i];
            
            // Off-diagonal: -D^(-1/2) * W_ij * D^(-1/2) * v[j]
            for (const auto& [j, w] : adj[i]) {
                result[i] -= d_inv_sqrt[i] * w * d_inv_sqrt[j] * v[j];
            }
        }
        
        return result;
    }
    
    // Power iteration to find eigenvector for largest eigenvalue of (I - L_norm)
    // which corresponds to smallest eigenvalue of L_norm
    std::vector<float> power_iteration(int iterations, std::mt19937& rng) {
        std::vector<float> v(n);
        std::uniform_real_distribution<float> dist(-1.0f, 1.0f);
        for (auto& x : v) x = dist(rng);
        vector_normalize(v);
        
        for (int iter = 0; iter < iterations; ++iter) {
            // v = (I - L_norm) * v = D^(-1/2) * W * D^(-1/2) * v
            std::vector<float> new_v(n, 0.0f);
            for (size_t i = 0; i < n; ++i) {
                for (const auto& [j, w] : adj[i]) {
                    new_v[i] += d_inv_sqrt[i] * w * d_inv_sqrt[j] * v[j];
                }
            }
            vector_normalize(new_v);
            v = std::move(new_v);
        }
        
        return v;
    }
    
    // Find k smallest eigenvectors (skip the first trivial one)
    std::vector<std::vector<float>> find_eigenvectors(int k, int iterations) {
        std::vector<std::vector<float>> eigenvectors;
        std::mt19937 rng(42);
        
        std::cerr << "[EIGEN] Finding " << k << " eigenvectors with " << iterations << " iterations each...\n";
        
        // Find k+1 eigenvectors (we'll skip the first trivial one)
        for (int i = 0; i <= k; ++i) {
            std::vector<float> v = power_iteration(iterations, rng);
            
            // Deflate: remove projection onto previous eigenvectors
            for (const auto& ev : eigenvectors) {
                float proj = dot_product(v, ev);
                vector_subtract(v, ev, proj);
            }
            vector_normalize(v);
            
            eigenvectors.push_back(v);
            std::cerr << "  Eigenvector " << i << " computed\n";
        }
        
        // Skip first (trivial constant eigenvector) and return the rest
        return std::vector<std::vector<float>>(eigenvectors.begin() + 1, eigenvectors.end());
    }
    
private:
    size_t n;
    std::vector<std::vector<std::pair<size_t, float>>> adj;  // adjacency list
    std::vector<float> degree;
    std::vector<float> d_inv_sqrt;
};

// =============================================================================
// Database Operations
// =============================================================================

static std::string bytes_to_hex(const std::vector<uint8_t>& bytes) {
    static const char hex[] = "0123456789abcdef";
    std::string result = "\\x";
    for (uint8_t b : bytes) {
        result += hex[b >> 4];
        result += hex[b & 0xf];
    }
    return result;
}

static std::vector<uint8_t> hex_to_bytes(const char* hex) {
    std::vector<uint8_t> result;
    if (hex[0] == '\\' && hex[1] == 'x') hex += 2;
    size_t len = strlen(hex);
    for (size_t i = 0; i + 1 < len; i += 2) {
        uint8_t b = 0;
        for (int j = 0; j < 2; ++j) {
            char c = hex[i + j];
            b <<= 4;
            if (c >= '0' && c <= '9') b |= (c - '0');
            else if (c >= 'a' && c <= 'f') b |= (c - 'a' + 10);
            else if (c >= 'A' && c <= 'F') b |= (c - 'A' + 10);
        }
        result.push_back(b);
    }
    return result;
}

// Parse PostGIS LineStringZM (EWKB) to float array
// Format: X=dim_index, Y=value, Z=0, M=0 per point
static std::vector<float> parse_linestring_embedding(const uint8_t* data, size_t len) {
    std::vector<float> result;
    
    if (len < 21) return result;  // Minimum EWKB header
    
    // EWKB Header parsing
    bool little_endian = data[0] == 0x01;
    size_t offset = 1 + 4;  // byte order + type
    
    // Check for SRID flag (0x20 in second byte of type for LE)
    if (little_endian && (data[1] & 0x20)) {
        offset += 4;  // Skip SRID
    }
    
    // Number of points (4 bytes)
    uint32_t num_points = 0;
    if (little_endian) {
        num_points = data[offset] | (data[offset+1] << 8) | 
                     (data[offset+2] << 16) | (data[offset+3] << 24);
    } else {
        num_points = (data[offset] << 24) | (data[offset+1] << 16) |
                     (data[offset+2] << 8) | data[offset+3];
    }
    offset += 4;
    
    result.reserve(num_points);
    
    // Each point is 4 doubles (X, Y, Z, M) = 32 bytes
    // X = dimension index, Y = VALUE (what we want), Z = 0, M = 0
    for (uint32_t i = 0; i < num_points && offset + 32 <= len; ++i) {
        // Skip X (dimension index) - 8 bytes
        offset += 8;
        
        // Read Y (the actual embedding value) - 8 bytes
        double y;
        memcpy(&y, data + offset, 8);
        result.push_back(static_cast<float>(y));
        offset += 8;
        
        // Skip Z and M - 16 bytes
        offset += 16;
    }
    
    return result;
}

static std::vector<Embedding> load_embeddings(PGconn* conn, const std::string& model_name) {
    std::vector<Embedding> result;
    
    // Use ST_AsBinary to get raw binary WKB, and encode to hex for safe transfer
    std::string query = 
        "SELECT encode(entity_id, 'hex'), encode(ST_AsBinary(embedding), 'hex'), dim_count "
        "FROM shape "
        "WHERE model_name ILIKE '%" + model_name + "%' "
        "AND dim_count >= 4";
    
    PGresult* res = PQexec(conn, query.c_str());
    if (PQresultStatus(res) != PGRES_TUPLES_OK) {
        std::cerr << "Query failed: " << PQerrorMessage(conn) << "\n";
        PQclear(res);
        return result;
    }
    
    int rows = PQntuples(res);
    std::cerr << "[LOAD] Found " << rows << " embeddings for model '" << model_name << "'\n";
    
    int parsed_count = 0;
    int failed_count = 0;
    
    for (int i = 0; i < rows; ++i) {
        Embedding e;
        
        // Entity ID (already hex-encoded, no \x prefix)
        char* id_hex = PQgetvalue(res, i, 0);
        e.entity_id = hex_to_bytes(id_hex);
        
        // Embedding (hex-encoded WKB, no \x prefix)
        char* geom_hex = PQgetvalue(res, i, 1);
        int dim_count = atoi(PQgetvalue(res, i, 2));
        
        // Parse hex to binary
        std::vector<uint8_t> wkb = hex_to_bytes(geom_hex);
        if (!wkb.empty()) {
            e.values = parse_linestring_embedding(wkb.data(), wkb.size());
        }
        
        if (!e.values.empty()) {
            if (i == 0) {
                std::cerr << "[DEBUG] First embedding: dim_count=" << dim_count 
                          << ", parsed=" << e.values.size() << " values\n";
                std::cerr << "[DEBUG] First 5 values: ";
                for (size_t j = 0; j < 5 && j < e.values.size(); ++j) {
                    std::cerr << e.values[j] << " ";
                }
                std::cerr << "\n";
            }
            result.push_back(std::move(e));
            parsed_count++;
        } else {
            failed_count++;
            if (failed_count <= 3) {
                std::cerr << "[WARN] Failed to parse embedding " << i << ", WKB size=" << wkb.size() << "\n";
            }
        }
    }
    
    std::cerr << "[LOAD] Successfully parsed " << parsed_count << " embeddings, " << failed_count << " failed\n";
    
    PQclear(res);
    return result;
}

// =============================================================================
// k-NN Graph Construction
// =============================================================================

static std::vector<Edge> build_knn_graph(const std::vector<Embedding>& embeddings, 
                                          int k, float threshold, int num_threads) {
    std::vector<Edge> edges;
    std::mutex edge_mutex;
    std::atomic<size_t> progress{0};
    size_t n = embeddings.size();
    
    if (num_threads <= 0) {
        num_threads = std::thread::hardware_concurrency();
        if (num_threads == 0) num_threads = 4;
    }
    
    std::cerr << "[KNN] Building k=" << k << " nearest neighbor graph for " << n << " nodes using " << num_threads << " threads...\n";
    
    auto worker = [&](size_t thread_id) {
        std::vector<Edge> local_edges;
        
        for (size_t i = thread_id; i < n; i += num_threads) {
            // Compute similarity to all other nodes
            std::vector<std::pair<float, size_t>> sims;
            sims.reserve(n);
            
            for (size_t j = 0; j < n; ++j) {
                if (i != j) {
                    float sim = cosine_similarity(embeddings[i].values, embeddings[j].values);
                    if (sim >= threshold) {
                        sims.push_back({sim, j});
                    }
                }
            }
            
            // Keep top k
            if (sims.size() > static_cast<size_t>(k)) {
                std::partial_sort(sims.begin(), sims.begin() + k, sims.end(),
                                  [](const auto& a, const auto& b) { return a.first > b.first; });
                sims.resize(k);
            }
            
            // Add edges
            for (const auto& [sim, j] : sims) {
                local_edges.push_back({i, j, sim});
            }
            
            size_t p = progress.fetch_add(1) + 1;
            if (p % 1000 == 0 || p == n) {
                std::cerr << "\r  Processed " << p << "/" << n << " nodes...";
            }
        }
        
        // Merge local edges
        std::lock_guard<std::mutex> lock(edge_mutex);
        edges.insert(edges.end(), local_edges.begin(), local_edges.end());
    };
    
    std::vector<std::thread> threads;
    for (int t = 0; t < num_threads; ++t) {
        threads.emplace_back(worker, t);
    }
    for (auto& t : threads) {
        t.join();
    }
    
    std::cerr << "\n[KNN] Built graph with " << edges.size() << " edges\n";
    return edges;
}

// =============================================================================
// Project to 4D and Update Database - Optimized with COPY
// =============================================================================

static bool update_projections(PGconn* conn, 
                                const std::vector<Embedding>& embeddings,
                                const std::vector<std::vector<float>>& basis,
                                int num_threads) {
    std::cerr << "[PROJECT] Projecting " << embeddings.size() << " embeddings to 4D...\n";
    
    if (num_threads <= 0) {
        num_threads = std::thread::hardware_concurrency();
        if (num_threads == 0) num_threads = 4;
    }
    
    // Parallel projection computation
    std::vector<std::array<float, 4>> raw_coords(embeddings.size());
    std::atomic<float> min_val[4], max_val[4];
    for (int d = 0; d < 4; ++d) {
        min_val[d].store(1e30f);
        max_val[d].store(-1e30f);
    }
    
    std::vector<std::thread> threads;
    std::atomic<size_t> idx{0};
    
    auto project_worker = [&]() {
        float local_min[4] = {1e30f, 1e30f, 1e30f, 1e30f};
        float local_max[4] = {-1e30f, -1e30f, -1e30f, -1e30f};
        
        while (true) {
            size_t i = idx.fetch_add(1);
            if (i >= embeddings.size()) break;
            
            for (int d = 0; d < 4 && d < static_cast<int>(basis.size()); ++d) {
                float v = dot_product(embeddings[i].values, basis[d]);
                raw_coords[i][d] = v;
                if (v < local_min[d]) local_min[d] = v;
                if (v > local_max[d]) local_max[d] = v;
            }
        }
        
        // Merge local min/max
        for (int d = 0; d < 4; ++d) {
            float expected = min_val[d].load();
            while (local_min[d] < expected && !min_val[d].compare_exchange_weak(expected, local_min[d]));
            expected = max_val[d].load();
            while (local_max[d] > expected && !max_val[d].compare_exchange_weak(expected, local_max[d]));
        }
    };
    
    for (int t = 0; t < num_threads; ++t) {
        threads.emplace_back(project_worker);
    }
    for (auto& t : threads) t.join();
    threads.clear();
    
    std::cerr << "  Coordinate ranges:\n";
    for (int d = 0; d < 4; ++d) {
        std::cerr << "    dim " << d << ": [" << min_val[d].load() << ", " << max_val[d].load() << "]\n";
    }
    
    // COORDINATE CONVENTION: uint32 with CENTER at 2^31 = 2147483648
    // Normalize projection values to unit sphere, then map to uint32 coords
    // Center of coordinate space is at 2147483648 (NOT at 0)
    constexpr double CENTER = 2147483648.0;  // 2^31 - origin of hypercube
    constexpr double SCALE = 2147483647.0;   // radius to reach [1, 2^32-1]
    
    std::vector<std::array<uint32_t, 4>> coords(embeddings.size());
    
    for (size_t i = 0; i < embeddings.size(); ++i) {
        // First normalize each dimension to [-1, 1]
        double unit[4];
        for (int d = 0; d < 4; ++d) {
            float range = max_val[d].load() - min_val[d].load();
            double normalized = (range > 1e-10f) 
                ? (raw_coords[i][d] - min_val[d].load()) / range 
                : 0.5;
            // Convert from [0, 1] to [-1, 1]
            unit[d] = normalized * 2.0 - 1.0;
        }
        
        // Map unit sphere to uint32 coords with CENTER at 2^31
        for (int d = 0; d < 4; ++d) {
            double scaled = CENTER + unit[d] * SCALE;
            if (scaled < 0.0) scaled = 0.0;
            if (scaled > 4294967295.0) scaled = 4294967295.0;
            coords[i][d] = static_cast<uint32_t>(std::round(scaled));
        }
    }
    
    // Use COPY for fast bulk update via temp table
    PGresult* res = PQexec(conn, "BEGIN");
    PQclear(res);
    
    res = PQexec(conn,
        "CREATE TEMP TABLE tmp_proj ("
        "  entity_id BYTEA PRIMARY KEY,"
        "  x BIGINT, y BIGINT, z BIGINT, m BIGINT"
        ") ON COMMIT DROP");
    PQclear(res);
    
    res = PQexec(conn, "COPY tmp_proj FROM STDIN WITH (FORMAT text, DELIMITER E'\\t')");
    PQclear(res);
    
    std::string batch;
    batch.reserve(1 << 20);
    
    for (size_t i = 0; i < embeddings.size(); ++i) {
        batch += "\\\\x";
        for (uint8_t b : embeddings[i].entity_id) {
            static const char hex[] = "0123456789abcdef";
            batch += hex[b >> 4];
            batch += hex[b & 0xf];
        }
        batch += "\t";
        batch += std::to_string(coords[i][0]) + "\t";
        batch += std::to_string(coords[i][1]) + "\t";
        batch += std::to_string(coords[i][2]) + "\t";
        batch += std::to_string(coords[i][3]) + "\n";
        
        if (batch.size() > (1 << 20)) {
            PQputCopyData(conn, batch.c_str(), static_cast<int>(batch.size()));
            batch.clear();
        }
    }
    
    if (!batch.empty()) {
        PQputCopyData(conn, batch.c_str(), static_cast<int>(batch.size()));
    }
    PQputCopyEnd(conn, nullptr);
    res = PQgetResult(conn);
    PQclear(res);
    
    std::cerr << "  Bulk loaded " << embeddings.size() << " projections to temp table\n";
    
    // Batch update composition table from temp table
    res = PQexec(conn,
        "UPDATE composition c SET "
        "  centroid = ST_SetSRID(ST_MakePoint(t.x, t.y, t.z, t.m), 0),"
        "  hilbert_lo = (hypercube_coords_to_hilbert(t.x::int, t.y::int, t.z::int, t.m::int)).lo,"
        "  hilbert_hi = (hypercube_coords_to_hilbert(t.x::int, t.y::int, t.z::int, t.m::int)).hi "
        "FROM tmp_proj t WHERE c.id = t.entity_id");
    
    int updated = 0;
    if (PQresultStatus(res) == PGRES_COMMAND_OK) {
        updated = atoi(PQcmdTuples(res));
    } else {
        std::cerr << "[ERROR] Update failed: " << PQerrorMessage(conn) << "\n";
    }
    PQclear(res);
    
    res = PQexec(conn, "COMMIT");
    PQclear(res);
    
    std::cerr << "[PROJECT] Updated " << updated << " compositions with 4D projections + Hilbert indices\n";
    return updated > 0;
}

// =============================================================================
// Main
// =============================================================================

int main(int argc, char* argv[]) {
    Config config;
    
    // Parse args
    for (int i = 1; i < argc; ++i) {
        std::string arg = argv[i];
        if (arg == "--db" && i + 1 < argc) {
            config.db_conn = argv[++i];
        } else if (arg == "--model" && i + 1 < argc) {
            config.model_name = argv[++i];
        } else if (arg == "--k" && i + 1 < argc) {
            config.k_neighbors = std::stoi(argv[++i]);
        } else if (arg == "--iterations" && i + 1 < argc) {
            config.power_iterations = std::stoi(argv[++i]);
        } else if (arg == "--threads" && i + 1 < argc) {
            config.num_threads = std::stoi(argv[++i]);
        } else if (arg == "--help" || arg == "-h") {
            std::cerr << "Usage: manifold_4d [options]\n"
                      << "  --db CONN         Database connection string\n"
                      << "  --model NAME      Model name to filter (default: minilm)\n"
                      << "  --k N             k for k-NN graph (default: 15)\n"
                      << "  --iterations N    Power iteration count (default: 100)\n"
                      << "  --threads N       Number of threads (default: auto)\n";
            return 0;
        }
    }
    
    std::cerr << "=== Manifold Projection: " << config.model_name << " -> 4D ===\n";
    std::cerr << "Using Laplacian Eigenmaps with Gram-Schmidt orthonormalization\n\n";
    
    auto start = std::chrono::steady_clock::now();
    
    // Connect to database
    PGconn* conn = PQconnectdb(config.db_conn.c_str());
    if (PQstatus(conn) != CONNECTION_OK) {
        std::cerr << "Connection failed: " << PQerrorMessage(conn) << "\n";
        PQfinish(conn);
        return 1;
    }
    
    // Step 1: Load embeddings from shape table
    std::cerr << "[1] Loading embeddings from shape table...\n";
    auto embeddings = load_embeddings(conn, config.model_name);
    
    if (embeddings.empty()) {
        std::cerr << "No embeddings found! Run ingest_safetensor first.\n";
        PQfinish(conn);
        return 1;
    }
    
    std::cerr << "Loaded " << embeddings.size() << " embeddings, dim=" << embeddings[0].values.size() << "\n\n";
    
    // Step 2: Build k-NN similarity graph
    std::cerr << "[2] Building k-NN graph...\n";
    auto edges = build_knn_graph(embeddings, config.k_neighbors, 
                                  config.similarity_threshold, config.num_threads);
    
    // Step 3: Compute Laplacian eigenvectors
    std::cerr << "\n[3] Computing Laplacian eigenvectors...\n";
    LaplacianEigensolver solver(embeddings, edges, embeddings.size());
    auto eigenvectors = solver.find_eigenvectors(config.target_dims, config.power_iterations);
    
    // Step 4: Gram-Schmidt orthonormalization
    std::cerr << "\n[4] Gram-Schmidt orthonormalization...\n";
    gram_schmidt(eigenvectors);
    std::cerr << "  Produced " << eigenvectors.size() << " orthonormal basis vectors\n";
    
    // Step 5: Project and update database
    std::cerr << "\n[5] Projecting embeddings and updating database...\n";
    update_projections(conn, embeddings, eigenvectors, config.num_threads);
    
    PQfinish(conn);
    
    auto end = std::chrono::steady_clock::now();
    auto secs = std::chrono::duration_cast<std::chrono::seconds>(end - start).count();
    
    std::cerr << "\n=== Complete in " << secs << " seconds ===\n";
    
    return 0;
}
